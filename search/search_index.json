{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Warning</p> <p>Saki-lang is currently in a very early stage of design and development, with substantial work required before it reaches a mature state. The prototype interpreter and REPL are still under active development, and many features are not yet implemented or fully supported. The language design and syntax are subject to change based on ongoing research and experimentation.</p> <p>Saki is a dependently-typed, pure functional programming language that supports algebraic subtyping and ad-hoc polymorphism. It prioritizes simplicity in design, using a Scala-inspired syntax while leveraging a type system grounded in Martin-L\u00f6f Type Theory. Saki introduces novel features like constraint universes and superposition types, serving as a research platform for exploring advanced type systems and verified program synthesis.</p>"},{"location":"#playground","title":"Playground","text":"<p>This interactive code playground allows you to write and run Saki code snippets directly in this website. Select a sample program from the dropdown menu or write your own code to experiment with the Saki language.</p> Example Code: Hello World Example Code: Martin-L\u00f6f Type Theory Type Checker Example Code: Red-Black Tree Example Code: Formal Proof of Peano Number <pre><code>/**\n * This code implements a simple type checker and evaluator for Martin-L\u00f6f Type Theory (MLTT).\n *\n * MLTT is a constructive type theory foundational to many proof assistants and dependently\n * typed programming languages, such as Agda (MLTT) and Coq (CIC).\n *\n * In MLTT, types depend on values, leading to a system where functions can accept types\n * as parameters and return types as results. Key concepts include:\n * - Dependent Function Types (Pi Types): Generalizations of function types where the\n *   return type depends on the input value.\n * - Lambda Abstractions: Anonymous functions defined by specifying parameters and body.\n * - Universes: A hierarchy of types (e.g., `Type(0)`, `Type(1)`, etc.).\n *\n * This implementation models core constructs of MLTT, including terms, values, environments,\n * evaluation, type inference, and normalization.\n */\n\n/**\n * Extracts the value from an `Option[A]`. Throws an error if the option is `None`.\n * @param &lt;A&gt; Type of the value.\n * @param option The `Option` instance.\n * @return The extracted value of type `A`.\n */\ntype Option[A: 'Type] = inductive {\n    None        // Represents the absence of a value.\n    Some(A)     // Wraps a value of type A.\n}\n\n/**\n * Extracts the value from an `Option[A]`. Throws an error if the option is `None`.\n * @param &lt;A&gt; Type of the value.\n * @param option The `Option` instance.\n * @return The extracted value of type `A`.\n */\ndef unwrap[A: 'Type](option: Option[A]): A = match option {\n    case Option[A]::None =&gt; panic(\"Unwrapping a none option type\")\n    case Option[A]::Some(value) =&gt; value\n}\n\n/**\n * `Term` represents the syntax of expressions in MLTT. Each constructor corresponds\n * to a syntactic category.\n */\ntype Term = inductive {\n    // Variable: Represents a variable identified by its name.\n    Var(String)\n    // Universe Level: Represents types at a certain universe level.\n    Type(Int)\n    // Dependent Pi Type: `\u03a0(x : A). B`, where `B` may depend on `x`.\n    Pi(String, Term, Term)\n    // Lambda Term: `\u03bb(x : A). t`.\n    Lambda(String, Term, Term)\n    // Application: Applying a function to an argument.\n    Apply(Term, Term)\n    // Sigma Type: `\u03a3(x : A). B`, a dependent pair type.\n    Sigma(String, Term, Term)\n    // Pair Term: `(a, b)`.\n    Pair(Term, Term)\n    // Projection: Extracting the first or second element of a pair.\n    Proj(Projection, Term)\n}\n\ntype Projection = inductive {\n    Fst; Snd\n}\n\n/**\n * `Value` represents the evaluated form of terms, reducing to values during evaluation.\n */\ntype Value = inductive {\n    // Neutral Value: A value that cannot be reduced further\n    Neutral(NeutralValue)\n    // Universe Level: A type at a specific universe level.\n    Type(Int)\n    // Lambda Function: A function value with its parameter type and body.\n    Lambda(Value, Value -&gt; Value)\n    // Pi Type Value: Represents a dependent function type.\n    Pi(Value, Value -&gt; Value)\n    // Sigma Type Value: Represents a dependent pair type.\n    Sigma(Value, Value -&gt; Value)\n    // Pair Value: A pair of values.\n    Pair(Value, Value)\n}\n\n/**\n * Types are represented as values within this implementation.\n */\ntype Type = Value\n\n// **Neutral Values**\n\n/*\n * `NeutralValue` represents expressions that cannot be evaluated further due to\n * the absence of sufficient information (e.g., variables or applications of variables).\n */\ntype NeutralValue = inductive {\n    // Variable: A neutral value representing an unresolved variable.\n    Var(String)\n    // Application: Applying a neutral function to a value.\n    Apply(NeutralValue, Value)\n    // Projection: Extracting the first or second element of a pair.\n    Proj(Projection, NeutralValue)\n}\n\n/**\n * Converts a `NeutralValue` into a `Value`.\n * @param neutral The `NeutralValue` to convert.\n * @return The resulting `Value`.\n */\ndef toValue(neutral: NeutralValue): Value = Value::Neutral(neutral)\n\n/**\n * `TypedValue` pairs a value with its type, essential for type checking and\n * ensuring type safety during evaluation.\n */\ntype TypedValue = record {\n    value: Value    // The evaluated value.\n    ty: Type        // The type of the value.\n}\n\n/**\n * `Env` represents the typing context, mapping variable names to their corresponding typed values.\n */\ntype Env = inductive {\n    Empty\n    Cons(String, TypedValue, Env)\n}\n\n/**\n * Adds a new binding to the environment.\n * @param env The current environment.\n * @param name The variable name.\n * @param value The value to bind.\n * @param ty The type of the value.\n * @return A new environment with the added binding.\n */\ndef add(env: Env, name: String, value: Value, ty: Type): Env = {\n    let typedValue = TypedValue '{\n        value = value  // The value associated with the name.\n        ty = ty        // The type of the value.\n    }\n    Env::Cons(name, typedValue, env)\n}\n\n/**\n * Adds a variable to the environment as a neutral value, commonly used when introducing parameters.\n * @param env The current environment.\n * @param ident The identifier of the variable.\n * @param ty The type of the variable.\n * @return A new environment with the variable added as a neutral value.\n */\ndef addVar(env: Env, ident: String, ty: Type): Env = {\n    env.add(ident, NeutralValue::Var(ident).toValue, ty)\n}\n\n/**\n * Retrieves a binding from the environment by name.\n * @param env The current environment.\n * @param name The name of the variable to retrieve.\n * @return An `Option` of `TypedValue` containing the variable's type if found, or `None` if not found.\n */\ndef get(env: Env, name: String): Option[TypedValue] = {\n    match env {\n        case Env::Empty =&gt; Option[TypedValue]::None  // Name not found.\n        case Env::Cons(name', value, env') =&gt; {\n            if name' == name then Option[TypedValue]::Some(value)\n            else env'.get(name) // Search in the rest of the environment.\n        }\n    }\n}\n\n/**\n * Checks if a name exists in the environment.\n * @param env The current environment.\n * @param name The name to check for.\n * @return `true` if the name exists in the environment, `false` otherwise.\n */\ndef contains(env: Env, name: String): Bool = match env {\n    case Env::Empty =&gt; false  // Name not found.\n    case Env::Cons(name', _, env') =&gt; name' == name || env'.contains(name)  // Found or continue searching.\n}\n\n/**\n * Generates a fresh identifier not present in the environment, used to avoid variable capture during substitution.\n * @param env The current environment.\n * @param cnt The starting count for generating identifiers.\n * @return A fresh identifier not currently in the environment.\n */\ndef freshIdentFrom(env: Env, cnt: Int): String = {\n    let ident = \"$\" ++ cnt.toString     // Generates identifiers like `$0`, `$1`, etc.\n    if !env.contains(ident) then ident  // If not in the environment, it's fresh.\n    else env.freshIdentFrom(cnt + 1)    // Try the next identifier.\n}\n\n/**\n * Generates a fresh identifier starting from `$0`.\n * @param env The current environment.\n * @return A fresh identifier.\n */\ndef freshIdent(env: Env): String = env.freshIdentFrom(0)\n\n/**\n * Evaluates a `Term` in a given environment to produce a `Value`.\n * Evaluation proceeds by pattern matching on the term's structure.\n * @param env The current environment.\n * @param expr The `Term` to evaluate.\n * @return The evaluated `Value`.\n */\ndef evaluate(env: Env, expr: Term): Value = match expr {\n    // Look up the variable's value.\n    case Term::Var(name) =&gt; env.get(name).unwrap[TypedValue].value\n    // A type evaluates to itself.\n    case Term::Type(univ) =&gt; Value::Type(univ)\n    // Lambda Evaluation: Constructs a closure capturing the environment and parameter.\n    case Term::Lambda(paramIdent, paramTypeTerm, bodyTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate the body with the argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(bodyTerm)\n        }\n        Value::Lambda(paramType, closure)\n    }\n    // Pi Type Evaluation: Similar to lambda\n    case Term::Pi(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate codomain with argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(codomainTerm)\n        }\n        Value::Pi(paramType, closure)\n    }\n    // Sigma Type Evaluation: Similar to lambda\n    case Term::Sigma(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate codomain with argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(codomainTerm)\n        }\n        Value::Sigma(paramType, closure)\n    }\n    // Function Application Evaluation\n    case Term::Apply(fn, arg) =&gt; match env.evaluate(fn) {\n        // Apply function to the argument.\n        case Value::Lambda(_, fn) =&gt; fn(env.evaluate(arg))\n        // Neutral Application: Cannot reduce further; keep it a neutral value.\n        case Value::Neutral(neutral) =&gt; NeutralValue::Apply(neutral, env.evaluate(arg)).toValue\n        case _ =&gt; panic(\"Invalid type: not a function\")\n    }\n    // Pair Construction\n    case Term::Pair(fst, snd) =&gt; Value::Pair(env.evaluate(fst), env.evaluate(snd))\n    // Pair Projection\n    case Term::Proj(proj, pair) =&gt; match env.evaluate(pair) {\n        case Value::Pair(fst, snd) =&gt; match proj {\n            case Projection::Fst =&gt; fst\n            case Projection::Snd =&gt; snd\n        }\n        case Value::Neutral(neutral) =&gt; NeutralValue::Proj(proj, neutral).toValue\n        case _ =&gt; panic(\"Invalid type: not a pair\")\n    }\n}\n\n/**\n * Converts a `NeutralValue` back into a `Term`, used during normalization to reconstruct\n * terms from evaluated values.\n * @param neutral The `NeutralValue` to convert.\n * @param env The current environment.\n * @return The reconstructed `Term`.\n */\ndef readBack(neutral: NeutralValue, env: Env): Term = match neutral {\n    // Convert variable to term.\n    case NeutralValue::Var(name) =&gt; Term::Var(name)\n    // Reconstruct application.\n    case NeutralValue::Apply(fn, arg) =&gt; Term::Apply(fn.readBack(env), arg.readBack(env))\n    // Reconstruct projection.\n    case NeutralValue::Proj(proj, neutral) =&gt; Term::Proj(proj, neutral.readBack(env))\n}\n\n/**\n * Converts a `Value` back into a `Term`, effectively normalizing the term by reducing it to its simplest form.\n * @param value The `Value` to convert.\n * @param env The current environment.\n * @return The normalized `Term`.\n */\ndef readBack(value: Value, env: Env): Term = match value {\n    case Value::Neutral(neutral) =&gt; neutral.readBack(env)\n    case Value::Type(univ) =&gt; Term::Type(univ)\n    case Value::Pair(fst, snd) =&gt; Term::Pair(fst.readBack(env), snd.readBack(env))\n\n    // Lambda Normalization: Generate a fresh variable to avoid capture.\n    case Value::Lambda(paramType, fn) =&gt; {\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Lambda(\n            paramIdent, paramTypeTerm,         // Construct lambda term.\n            fn(variable).readBack(updatedEnv)  // Normalize the body.\n        )\n    }\n\n    // Pi Type Normalization: Similar to lambda normalization.\n    case Value::Pi(paramType, fn) =&gt; {\n        // Fresh parameter name.\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Pi(\n            paramIdent, paramTypeTerm,          // Construct Pi type term.\n            fn(variable).readBack(updatedEnv)   // Normalize the codomain.\n        )\n    }\n\n    // Sigma Type Normalization: Similar to lambda normalization.\n    case Value::Sigma(paramType, fn) =&gt; {\n        // Fresh parameter name.\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Sigma(\n            paramIdent, paramTypeTerm,          // Construct Sigma type term.\n            fn(variable).readBack(updatedEnv)   // Normalize the codomain.\n        )\n    }\n}\n\n/**\n * Retrieves the universe level from a `Type` value.\n * Universe levels are critical in MLTT to maintain consistency and avoid paradoxes.\n * @param ty The `Type` value.\n * @return The universe level as an `Int`.\n */\ndef universeLevel(ty: Type): Int = match ty {\n    case Value::Type(univ) =&gt; univ                                  // Extract universe level.\n    case _ =&gt; panic(\"Failed to unwrap universe level: not a type\")  // Panic if not a type.\n}\n\n/**\n * Infers the type of a `Term` within a given environment following MLTT's typing rules.\n * @param env The current environment.\n * @param expr The `Term` whose type is inferred.\n * @return The inferred type as a `Value`.\n */\ndef infer(env: Env, expr: Term): Value = match expr {\n\n    // Retrieve the variable's type from the environment.\n    case Term::Var(name) =&gt; env.get(name).unwrap[TypedValue].ty\n\n    // `Type(n)` has type `Type(n + 1)`.\n    case Term::Type(univ) =&gt; Value::Type(univ + 1)\n\n    // Lambda Type Inference:\n    case Term::Lambda(paramIdent, paramTypeTerm, bodyTerm) =&gt; {\n        // Infer parameter type's universe level.\n        let paramLevel = env.infer(paramTypeTerm).universeLevel\n        // Evaluate parameter type.\n        let paramType: Type = env.evaluate(paramTypeTerm)\n        // Create variable for parameter.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment with parameter.\n        let bodyEnv = env.add(paramIdent, variable, paramType)\n        // Infer body's type.\n        let returnType: Type = bodyEnv.infer(bodyTerm)\n        // The lambda's type is a Pi type from parameter to return type.\n        Value::Pi(\n            paramType,\n            (arg: Value) =&gt; {\n                // Infer argument's type.\n                let argType = env.infer(arg.readBack(bodyEnv))\n                // Evaluate the body.\n                bodyEnv.add(paramIdent, arg, argType).evaluate(bodyTerm)\n            }\n        )\n    }\n\n    // Pair Type Inference:\n    case Term::Pair(fst, snd) =&gt; {\n        // Infer the type of the first element.\n        let fstType: Type = env.infer(fst)\n        // Infer the type of the second element.\n        let sndType: Type = env.infer(snd)\n        // The pair type is a Sigma type of the two elements.\n        Value::Sigma(fstType, (fstValue: Value) =&gt; {\n            Value::Sigma(sndType, (sndValue: Value) =&gt; Value::Pair(fstValue, sndValue))\n        })\n    }\n\n    // Pi Type Inference:\n    case Term::Pi(paramIdent, paramTypeTerm, returnTypeTerm) =&gt; {\n        // Infer parameter type's universe level.\n        let paramLevel = env.infer(paramTypeTerm).universeLevel\n        // Evaluate parameter type.\n        let paramType: Type = env.evaluate(paramTypeTerm)\n        // Create variable for parameter.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        let returnTypeLevel = env.add(paramIdent, variable, paramType).infer(returnTypeTerm).universeLevel\n        // The Pi type's universe level is the maximum of parameter and return types.\n        Value::Type(max paramLevel returnTypeLevel)\n    }\n\n    // Sigma Type Inference:\n    case Term::Sigma(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        // Infer parameter type's universe level.\n        let paramLevel = env.infer(paramTypeTerm).universeLevel\n        // Evaluate parameter type.\n        let paramType: Type = env.evaluate(paramTypeTerm)\n        // Create variable for parameter.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        let rhsTypeLevel = env.add(paramIdent, variable, paramType).infer(codomainTerm).universeLevel\n        // The sigma type's universe level is the maximum of lhs and rhs types.\n        Value::Type(max paramLevel rhsTypeLevel)\n    }\n}\n\n/**\n * Normalizes a `Term` by evaluating it and converting the result back into a term.\n * Normalization is essential for comparing terms for equality and ensuring consistent behavior.\n * @param env The current environment.\n * @param expr The `Term` to normalize.\n * @return The normalized `Term`.\n */\ndef normalize(env: Env, expr: Term): Term = env.evaluate(expr).readBack(env)\n\ndef pretty(expr: Term): String = match expr {\n    case Term::Var(name) =&gt; name\n    case Term::Type(univ) =&gt; \"Type(\" ++ univ.toString ++ \")\"\n    case Term::Lambda(paramIdent, paramType, body) =&gt;\n        \"\u03bb(\" ++ paramIdent ++ \" : \" ++ paramType.pretty ++ \"). \" ++ body.pretty\n    case Term::Apply(fn, arg) =&gt; \"(\" ++ fn.prettyAtom ++ \" \" ++ arg.prettyAtom ++ \")\"\n    case Term::Pi(paramIdent, paramType, returnType) =&gt;\n        \"\u03a0(\" ++ paramIdent ++ \" : \" ++ paramType.pretty ++ \"). \" ++ returnType.pretty\n    case Term::Sigma(paramIdent, paramType, codomain) =&gt;\n        \"\u03a3(\" ++ paramIdent ++ \" : \" ++ paramType.pretty ++ \"). \" ++ codomain.pretty\n    case Term::Pair(fst, snd) =&gt; \"(\" ++ fst.pretty ++ \", \" ++ snd.pretty ++ \")\"\n    case Term::Proj(Projection::Fst, pair) =&gt; \"fst \" ++ pair.pretty\n}\n\ndef prettyAtom(expr: Term): String = match expr {\n    case Term::Var(name) =&gt; name\n    case Term::Type(_) =&gt; expr.pretty\n    case Term::Lambda(_, _, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Apply(_, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Pi(_, _, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Sigma(_, _, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Pair(_, _) =&gt; expr.pretty\n    case Term::Proj(_, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n}\n\ndef var(ident: String): Value = NeutralValue::Var(ident).toValue\n\ndef prelude: Env = Env::Empty\n    .addVar(\"Any\", Value::Type(0))\n    .addVar(\"Nothing\", Value::Type(0))\n    .addVar(\"Bool\", Value::Type(0))\n    .addVar(\"true\", var(\"Bool\"))\n    .addVar(\"false\", var(\"Bool\"))\n    .addVar(\"Nat\", Value::Type(0))\n    .addVar(\"zero\", var(\"Nat\"))\n    .addVar(\"succ\", Value::Pi(var(\"Nat\"), (n: Value) =&gt; var(\"Nat\")))\n\neval \"\\nBeta-reduction: (\u03bbx. t) v -&gt; t[x := v]  Case 1: x[x := N] = N\"\neval {\n    let term: Term = Term::Apply(\n        Term::Lambda(\"x\", Term::Var(\"Bool\"), Term::Var(\"x\")),\n        Term::Var(\"true\")\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nBeta-reduction: (\u03bbx. t) v -&gt; t[x := v]  Case 2: y[x := N] = y, if x \u2260 y\"\neval {\n    let term: Term = Term::Apply(\n        Term::Lambda(\n            \"x\", Term::Var(\"Bool\"),\n            Term::Lambda(\"y\", Term::Var(\"Bool\"), Term::Var(\"y\"))\n        ),\n        Term::Var(\"true\")\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nHigher-order function:\"\neval {\n    let term = Term::Apply(\n        Term::Lambda(\"f\", Term::Pi(\"x\", Term::Var(\"Bool\"), Term::Var(\"Bool\")),\n            Term::Apply(Term::Var(\"f\"), Term::Var(\"true\"))\n        ),\n        Term::Lambda(\"x\", Term::Var(\"Bool\"), Term::Var(\"x\"))\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nAlpha-conversion: \u03bbx. t -&gt; \u03bby. t[x := y] -- no name collision\"\neval {\n    let term = Term::Pi(\"A\", Term::Type(0),\n        Term::Lambda(\"x\", Term::Var(\"A\"), Term::Var(\"x\"))\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nSigma type - elimination\"\neval {\n    let term = Term::Apply(\n        Term::Lambda(\"p\", Term::Sigma(\"A\", Term::Var(\"Bool\"), Term::Var(\"A\")),\n            Term::Proj(Projection::Fst, Term::Var(\"p\"))\n        ),\n        Term::Pair(Term::Var(\"true\"), Term::Var(\"false\"))\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nChurch numeral 0:\"\neval {\n    let zero = Term::Lambda(\"f\", Term::Pi(\"x\", Term::Var(\"Any\"), Term::Var(\"Any\")),\n        Term::Lambda(\"x\", Term::Var(\"Any\"), Term::Var(\"x\"))\n    )\n    zero.pretty ++ \"  \u2261  \" ++ prelude.normalize(zero).pretty\n}\n\neval \"\\nChurch numeral 1:\"\neval {\n    let one = Term::Lambda(\"f\", Term::Pi(\"x\", Term::Var(\"Any\"), Term::Var(\"Any\")),\n        Term::Lambda(\"x\", Term::Var(\"Any\"), Term::Apply(Term::Var(\"f\"), Term::Var(\"x\")))\n    )\n    one.pretty ++ \"  \u2261  \" ++ prelude.normalize(one).pretty\n}\n</code></pre> Run Code"},{"location":"#repl","title":"REPL","text":""},{"location":"01-keywords/","title":"Keywords and Identifiers","text":""},{"location":"01-keywords/#keywords","title":"Keywords","text":"<p>Saki supports following keywords:</p> Keyword Description <code>import</code> Module import <code>pub</code> Public modifier <code>def</code> Function definition <code>impl</code> Implementation block <code>operator</code> Operator declaration <code>prefix</code> Prefix modifier (unary operator) <code>postfix</code> Postfix modifier (unary operator) <code>left-assoc</code> Left association modifier (binary operator) <code>right-assoc</code> Right association modifier (binary operator) <code>tighter-than</code> Precedence partial-order modifier (binary operator) <code>looser-than</code> Precedence partial-order modifier (binary operator) <code>same-as</code> Precedence partial-order modifier (binary operator) <code>let</code> Let binding <code>instance</code> Instance value <code>enum</code> Enum type (Algebraic Data Type) <code>record</code> Record type <code>universe</code> Universe <code>self</code> Self instance <code>Self</code> Self type <code>this</code> Current subject (such as recursive access in anonymous function) <code>forall</code> / <code>\u03a0</code> / <code>\u2200</code> Forall / dependent pi type <code>exists</code> / <code>\u03a3</code> / <code>\u2203</code> Exists / dependent sigma type <code>if</code> If-expression <code>then</code> Then branch in if-expression <code>else</code> Else branch in if-expression <code>match</code> Match-expression <code>case</code> Case clause in match-expression"},{"location":"01-keywords/#identifiers","title":"Identifiers","text":"Identifier Example Description <code>camelCaseWithEnglishOrGreekLetters</code> / <code>withOptionalPostfixSingleQuotation'</code> <code>value</code>, <code>\u03b1</code>, <code>\u03c0\u03b1\u03c1\u03ac\u03b4\u03b5\u03b9\u03b3\u03bc\u03b1</code>, <code>n'</code> Values <code>PascalCaseInEnglish</code> / A single blackboard bold letter <code>Nat</code>, <code>\u2115</code> Types <code>'PascalCaseWithAPrefixedSingleQuotation</code> <code>'Type</code>, <code>'Runnable</code> Contract universes <code>#Universe</code> <code>#Universe</code> The universe that all contract universes lives in <code>'Type_n</code> / <code>'Type\u2099</code> <code>'Type_3</code>, <code>'Type\u2083</code> Higher-level universes"},{"location":"02-mltt/","title":"Martin-L\u00f6f Type Theory","text":"<p>Martin-L\u00f6f Type Theory (MLTT) stands as a foundational system intertwining constructive mathematics and computer science, developed by Per Martin-L\u00f6f in the 1970s. It offers a framework where logic and computation are unified, serving both as a formal language for mathematical proofs and as a typed functional programming language. The hallmark of MLTT is its use of dependent types, which enhances the expressiveness of the type system by allowing types to depend on terms. This introduction delves into the theoretical underpinnings of MLTT, emphasizing the role and implications of dependent types within the system.</p>"},{"location":"02-mltt/#background-and-motivation","title":"Background and Motivation","text":""},{"location":"02-mltt/#constructive-mathematics-and-computation","title":"Constructive Mathematics and Computation","text":"<p>Constructive mathematics emphasizes the necessity of constructing mathematical objects explicitly rather than assuming their existence non-constructively. This approach aligns naturally with computation, where mathematical proofs correspond to algorithms, and existence proofs provide methods to compute the objects in question.</p>"},{"location":"02-mltt/#the-curry-howard-correspondence","title":"The Curry-Howard Correspondence","text":"<p>The Curry-Howard correspondence establishes a profound connection between logic and computation, interpreting types as propositions and terms as proofs or programs. In this paradigm:</p> <ul> <li>Types \u2248 Propositions</li> <li>Terms \u2248 Proofs/Programs</li> <li>Type Checking \u2248 Proof Verification</li> <li>Program Execution \u2248 Proof Normalization</li> </ul> <p>MLTT extends this correspondence by incorporating dependent types, allowing for more expressive propositions and enabling the representation of intricate mathematical concepts within the type system.</p>"},{"location":"02-mltt/#dependent-types","title":"Dependent Types","text":""},{"location":"02-mltt/#dependent-function-types-types","title":"Dependent Function Types (\u03a0-Types)","text":"<p>Formation Rule:</p> \\[ \\frac{\\Gamma \\vdash A : \\mathcal{U} \\quad \\Gamma, x : A \\vdash B(x) : \\mathcal{U}}{\\Gamma \\vdash \\Pi(x : A) . B(x) : \\mathcal{U}} \\] <p>Introduction Rule:</p> \\[ \\frac{\\Gamma, x : A \\vdash b(x) : B(x)}{\\Gamma \\vdash \\lambda x. b(x) : \\Pi(x : A) . B(x)} \\] <p>Elimination Rule (Application):</p> \\[ \\frac{\\Gamma \\vdash f : \\Pi(x : A) . B(x) \\quad \\Gamma \\vdash a : A}{\\Gamma \\vdash f(a) : B(a)} \\]"},{"location":"02-mltt/#dependent-pair-types-types","title":"Dependent Pair Types (\u03a3-Types)","text":"<p>Formation Rule:</p> \\[ \\frac{\\Gamma \\vdash A : \\mathcal{U} \\quad \\Gamma, x : A \\vdash B(x) : \\mathcal{U}}{\\Gamma \\vdash \\Sigma(x : A) . B(x) : \\mathcal{U}} \\] <p>Introduction Rule:</p> \\[ \\frac{\\Gamma \\vdash a : A \\quad \\Gamma \\vdash b : B(a)}{\\Gamma \\vdash (a, b) : \\Sigma(x : A) . B(x)} \\] <p>Elimination Rules (Projections):</p> <p>For \\(p : (\\Sigma x : A) B(x)\\):</p> <ul> <li>First Projection: \\(\\text{fst}(p) : A\\)</li> <li>Second Projection: \\(\\text{snd}(p) : B(\\text{fst}(p))\\)</li> </ul>"},{"location":"02-mltt/#universes-and-type-hierarchies","title":"Universes and Type Hierarchies","text":"<p>To prevent paradoxes such as Girard's paradox, MLTT introduces a hierarchy of universes:</p> <ul> <li>Type Universes (\\(\\mathcal{U}_0, \\mathcal{U}_1, \\ldots\\)): Each universe \\(\\mathcal{U}_i\\) is a type whose elements are types in the universe \\(\\mathcal{U}_{i-1}\\).</li> <li>Cumulativity: If \\(A : \\mathcal{U}_i\\), then \\(A : \\mathcal{U}_{i+1}\\).</li> </ul> <p>This stratification ensures the consistency of the type theory by avoiding circular definitions.</p>"},{"location":"02-mltt/#syntax-of-martin-lof-type-theory","title":"Syntax of Martin-L\u00f6f Type Theory","text":"<p>To formalize the discussion, we present the syntax of MLTT, focusing on constructs related to dependent types:</p> \\[ \\begin{array}{lcll} t, u &amp; ::= &amp; x &amp; \\text{Variable} \\\\  &amp; | &amp; \\mathcal{U} &amp; \\text{Universe} \\\\ &amp; | &amp; \\Pi(x: t).u &amp; \\text{Dependent Pi Type} \\\\ &amp; | &amp; \\Sigma(x: t).u &amp; \\text{Dependent Sigma Type} \\\\ &amp; | &amp; \\lambda(x: t).u &amp; \\text{Lambda Expression} \\\\ &amp; | &amp; t \\ u &amp; \\text{Application} \\\\ &amp; | &amp; (t, u) &amp; \\text{Pair} \\\\ &amp; | &amp; \\text{fst}(t) &amp; \\text{First Projection} \\\\ &amp; | &amp; \\text{snd}(t) &amp; \\text{Second Projection} \\\\ \\end{array} \\] <p>In this syntax:</p> <ul> <li>Variables (\\( x \\)) represent identifiers.</li> <li>Universes (\\( \\mathcal{U} \\)) represent types of types, introducing a hierarchy to prevent paradoxes.</li> <li>Dependent Pi Types (\\( \\Pi(x: t).u \\)) generalize function types, allowing the return type \\( u \\) to depend on the input \\( x \\).</li> <li>Dependent Sigma Types (\\( \\Sigma(x: t).u \\)) represent dependent pairs, where the second component depends on the first.</li> <li>Lambda Expressions (\\( \\lambda(x: t).u \\)) define functions with parameter \\( x \\) of type \\( t \\) and body \\( u \\).</li> <li>Applications (\\( t \\ u \\)) apply functions to arguments.</li> <li>Pairs (\\( (t, u) \\)) create dependent pairs.</li> <li>Projections (\\( \\text{fst}(t) \\) and \\( \\text{snd}(t) \\)) extract the first and second components of a pair.</li> </ul> <p>To further elucidate the structure of terms in MLTT, we can represent them using an inductive data type:</p> <pre><code>type Term = inductive {\n    // Variable: Represents a variable identified by its name.\n    Var(String)\n    // Universe Level: Represents types at a certain universe level.\n    Type(Int)\n    // Dependent Pi Type: `\u03a0(x : A). B`, where `B` may depend on `x`.\n    Pi(String, Term, Term)\n    // Lambda Term: `\u03bb(x : A). t`.\n    Lambda(String, Term, Term)\n    // Application: Applying a function to an argument.\n    Apply(Term, Term)\n    // Sigma Type: `\u03a3(x : A). B`, a dependent pair type.\n    Sigma(String, Term, Term)\n    // Pair Term: `(a, b)`.\n    Pair(Term, Term)\n    // Projection: Extracting the first or second element of a pair.\n    Proj(Projection, Term)\n}\n</code></pre>"},{"location":"02-mltt/#normalization-by-evaluation-nbe","title":"Normalization by Evaluation (NBE)","text":"<p>Evaluation in MLTT aims to reduce terms to their normal forms, or fully simplified versions. The process involves translating syntactic terms into a structured representation that allows terms with bound variables to be resolved efficiently. Traditional reduction-based evaluation relies on direct substitution and can be inefficient. Normalization by Evaluation (NBE), however, uses an environment to track bindings and reification to convert values back into terms. It differs fundamentally from direct reduction methods by bypassing substitution and instead leveraging environments and reification to achieve efficient normalization of terms to their irreducible, or normal forms. NBE is especially advantageous in dependent type theories, where terms can depend on values, and normalization is essential for type-checking and proof verification. </p>"},{"location":"02-mltt/#values-and-neutral-values","title":"Values and Neutral Values","text":"<p>Values in NBE are representations of terms that can fully evaluate within an environment, encompassing functions, constants, and closed expressions.</p> <pre><code>type Value = inductive {\n    // Neutral Value: A value that cannot be reduced further\n    Neutral(NeutralValue)\n    // Universe Level: A type at a specific universe level.\n    Type(Int)\n    // Lambda Function: A function value with its parameter type and body.\n    Lambda(Value, Value -&gt; Value)\n    // Pi Type Value: Represents a dependent function type.\n    Pi(Value, Value -&gt; Value)\n    // Sigma Type Value: Represents a dependent pair type.\n    Sigma(Value, Value -&gt; Value)\n    // Pair Value: A pair of values.\n    Pair(Value, Value)\n}\n\n// In this implementation, types are represented as values.\ntype Type = Value\n</code></pre> <p>Neutral values, however, represent terms that are blocked from further reduction due to free variables or unsolved dependencies. Neutral values allow terms with unresolved components to be stored without forcing premature reductions. They are especially significant in representing expressions that cannot simplify further because they involve variables that are free in the current context.</p> <pre><code>type NeutralValue = inductive {\n    // Variable: A neutral value representing an unresolved variable.\n    Var(String)\n    // Application: Applying a neutral function to a value.\n    Apply(NeutralValue, Value)\n    // Projection: Extracting the first or second element of a pair.\n    Proj(Projection, NeutralValue)\n}\n</code></pre>"},{"location":"02-mltt/#environments-and-closures","title":"Environments and Closures","text":"<p>In NBE, functions are represented as closures, capturing both the function body and its environment. An environment binds variables to values, avoiding the need for explicit substitution and enhancing the efficiency of evaluation.</p> <p>For instance, if a term <code>\u03bbx.t</code> is in the environment <code>Env</code>, it can be represented as a closure combining <code>t</code> with <code>Env</code>. This representation enables the function to retain variable bindings even as it passes through various stages of evaluation.</p> <p>For simplicity, we use a linked list to implement the environment and lambda functions in the host language to represent closures:</p> <pre><code>type Env = inductive {\n    Empty\n    Cons(String, TypedValue, Env)\n}\n\ntype Value = inductive {\n    /* ... */\n    Lambda(Value, Value -&gt; Value)\n    Pi(Value, Value -&gt; Value)\n    Sigma(Value, Value -&gt; Value)\n}\n</code></pre>"},{"location":"02-mltt/#evaluation","title":"Evaluation","text":"<p>Evaluation in NBE converts syntactic terms into a structured representation of values. Each variable is looked up in the environment rather than being substituted directly, streamlining the process. Below is a function implementing this evaluation, handling variables, functions, and applications:</p> <pre><code>def evaluate(env: Env, expr: Term): Value = match expr {\n    // Look up the variable's value.\n    case Term::Var(name) =&gt; env.get(name).unwrap[TypedValue].value\n    // A type evaluates to itself.\n    case Term::Type(univ) =&gt; Value::Type(univ)\n    // Lambda Evaluation: Constructs a closure capturing the environment and parameter.\n    case Term::Lambda(paramIdent, paramTypeTerm, bodyTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate the body with the argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(bodyTerm)\n        }\n        Value::Lambda(paramType, closure)\n    }\n    // Pi Type Evaluation: Similar to lambda\n    case Term::Pi(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate codomain with argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(codomainTerm)\n        }\n        Value::Pi(paramType, closure)\n    }\n    // Sigma Type Evaluation: Similar to lambda\n    case Term::Sigma(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate codomain with argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(codomainTerm)\n        }\n        Value::Sigma(paramType, closure)\n    }\n    // Function Application Evaluation\n    case Term::Apply(fn, arg) =&gt; match env.evaluate(fn) {\n        // Apply function to the argument.\n        case Value::Lambda(_, fn) =&gt; fn(env.evaluate(arg))\n        // Neutral Application: Cannot reduce further; keep it a neutral value.\n        case Value::Neutral(neutral) =&gt; NeutralValue::Apply(neutral, env.evaluate(arg)).toValue\n        case _ =&gt; panic(\"Invalid type: not a function\")\n    }\n    // Pair Construction\n    case Term::Pair(fst, snd) =&gt; Value::Pair(env.evaluate(fst), env.evaluate(snd))\n}\n</code></pre>"},{"location":"02-mltt/#reification-read-back","title":"Reification (Read-Back)","text":"<p>The final stage in NBE is reification, which converts evaluated values back into syntactic terms, producing a term in its normal form. Reification ensures that the term representation is irreducible and allows comparisons of normalized terms. In essence, reification \u201creads back\u201d a value by converting closures and neutral values to their term equivalents. For example:</p> <pre><code>def readBack(value: Value, env: Env): Term = match value {\n    case Value::Neutral(neutral) =&gt; neutral.readBack(env)\n    case Value::Type(univ) =&gt; Term::Type(univ)\n    case Value::Pair(fst, snd) =&gt; Term::Pair(fst.readBack(env), snd.readBack(env))\n\n    // Lambda Normalization: Generate a fresh variable to avoid capture.\n    case Value::Lambda(paramType, fn) =&gt; {\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Lambda(\n            paramIdent, paramTypeTerm,         // Construct lambda term.\n            fn(variable).readBack(updatedEnv)  // Normalize the body.\n        )\n    }\n\n    // Pi Type Normalization: Similar to lambda normalization.\n    case Value::Pi(paramType, fn) =&gt; {\n        // Fresh parameter name.\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Pi(\n            paramIdent, paramTypeTerm,          // Construct Pi type term.\n            fn(variable).readBack(updatedEnv)   // Normalize the codomain.\n        )\n    }\n\n    // Sigma Type Normalization: Similar to lambda normalization.\n    case Value::Sigma(paramType, fn) =&gt; {\n        // Fresh parameter name.\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Sigma(\n            paramIdent, paramTypeTerm,          // Construct Sigma type term.\n            fn(variable).readBack(updatedEnv)   // Normalize the codomain.\n        )\n    }\n}\n</code></pre>"},{"location":"02-mltt/#neutral-value-reification","title":"Neutral Value Reification","text":"<p>Neutral terms are read back by preserving the unresolved structure, which makes them appear in their simplest, irreducible forms. For instance, if the neutral term is a variable <code>x</code>, <code>readBack</code> simply returns <code>Term::Var(x)</code>:</p> <pre><code>def readBack(neutral: NeutralValue, env: Env): Term = match neutral {\n    // Convert variable to term.\n    case NeutralValue::Var(name) =&gt; Term::Var(name)\n    // Reconstruct application.\n    case NeutralValue::Apply(fn, arg) =&gt; Term::Apply(fn.readBack(env), arg.readBack(env))\n    // Reconstruct projection.\n    case NeutralValue::Proj(proj, neutral) =&gt; Term::Proj(proj, neutral.readBack(env))\n}\n</code></pre>"},{"location":"02-mltt/#formalization-of-nbes-core-operations","title":"Formalization of NBE\u2019s Core Operations","text":"<p>In formal terms, NBE employs structured definitions of evaluation and application, capturing both the computational essence and logical foundation of dependent type theories. These formalizations are represented with mathematical notations:</p>"},{"location":"02-mltt/#evaluation-rules","title":"Evaluation Rules","text":"\\[ \u27e6 x \u27e7_{\\rho} = \\rho(x) \\] <p>For a variable \\(x\\), evaluation retrieves \\(x\\)'s value from the environment \\(\\rho\\).</p> \\[ \u27e6 \\lambda x.t \u27e7_{\\rho} = (\\rho, \\lambda x.t) \\] <p>A lambda function evaluates to a closure with \\(\\rho\\) capturing the environment.</p> \\[ \u27e6 t \\ u \u27e7_{\\rho} = \u27e6 t \u27e7_{\\rho} \\cdot \u27e6 u \u27e7_{\\rho} \\] <p>Application proceeds by evaluating both the function \\(t\\) and argument \\(u\\).</p>"},{"location":"02-mltt/#application-in-formal-terms","title":"Application in Formal Terms","text":"<p>Application between values distinguishes between closures and neutral values:</p> <p>$$ (\\rho, \\lambda x.t) \\cdot v = \u27e6 t \u27e7_{\\rho[x \\mapsto v]} $$ If the function is a closure, the argument \\(v\\) extends the environment.</p> <p>$$ n \\cdot v = \\text{Neutral}(n \\ v) $$ For neutral values, application produces another neutral structure.</p>"},{"location":"02-mltt/#complete-implementation","title":"Complete Implementation","text":"<p>The following code implements a simple type checker and evaluator for Martin-L\u00f6f Type Theory (MLTT).</p> <pre><code>/**\n * This code implements a simple type checker and evaluator for Martin-L\u00f6f Type Theory (MLTT).\n *\n * MLTT is a constructive type theory foundational to many proof assistants and dependently\n * typed programming languages, such as Agda (MLTT) and Coq (CIC).\n *\n * In MLTT, types depend on values, leading to a system where functions can accept types\n * as parameters and return types as results. Key concepts include:\n * - Dependent Function Types (Pi Types): Generalizations of function types where the\n *   return type depends on the input value.\n * - Lambda Abstractions: Anonymous functions defined by specifying parameters and body.\n * - Universes: A hierarchy of types (e.g., `Type(0)`, `Type(1)`, etc.).\n *\n * This implementation models core constructs of MLTT, including terms, values, environments,\n * evaluation, type inference, and normalization.\n */\n\n/**\n * Extracts the value from an `Option[A]`. Throws an error if the option is `None`.\n * @param &lt;A&gt; Type of the value.\n * @param option The `Option` instance.\n * @return The extracted value of type `A`.\n */\ntype Option[A: 'Type] = inductive {\n    None        // Represents the absence of a value.\n    Some(A)     // Wraps a value of type A.\n}\n\n/**\n * Extracts the value from an `Option[A]`. Throws an error if the option is `None`.\n * @param &lt;A&gt; Type of the value.\n * @param option The `Option` instance.\n * @return The extracted value of type `A`.\n */\ndef unwrap[A: 'Type](option: Option[A]): A = match option {\n    case Option[A]::None =&gt; panic(\"Unwrapping a none option type\")\n    case Option[A]::Some(value) =&gt; value\n}\n\n/**\n * `Term` represents the syntax of expressions in MLTT. Each constructor corresponds\n * to a syntactic category.\n */\ntype Term = inductive {\n    // Variable: Represents a variable identified by its name.\n    Var(String)\n    // Universe Level: Represents types at a certain universe level.\n    Type(Int)\n    // Dependent Pi Type: `\u03a0(x : A). B`, where `B` may depend on `x`.\n    Pi(String, Term, Term)\n    // Lambda Term: `\u03bb(x : A). t`.\n    Lambda(String, Term, Term)\n    // Application: Applying a function to an argument.\n    Apply(Term, Term)\n    // Sigma Type: `\u03a3(x : A). B`, a dependent pair type.\n    Sigma(String, Term, Term)\n    // Pair Term: `(a, b)`.\n    Pair(Term, Term)\n    // Projection: Extracting the first or second element of a pair.\n    Proj(Projection, Term)\n}\n\ntype Projection = inductive {\n    Fst; Snd\n}\n\n/**\n * `Value` represents the evaluated form of terms, reducing to values during evaluation.\n */\ntype Value = inductive {\n    // Neutral Value: A value that cannot be reduced further\n    Neutral(NeutralValue)\n    // Universe Level: A type at a specific universe level.\n    Type(Int)\n    // Lambda Function: A function value with its parameter type and body.\n    Lambda(Value, Value -&gt; Value)\n    // Pi Type Value: Represents a dependent function type.\n    Pi(Value, Value -&gt; Value)\n    // Sigma Type Value: Represents a dependent pair type.\n    Sigma(Value, Value -&gt; Value)\n    // Pair Value: A pair of values.\n    Pair(Value, Value)\n}\n\n/**\n * Types are represented as values within this implementation.\n */\ntype Type = Value\n\n// **Neutral Values**\n\n/*\n * `NeutralValue` represents expressions that cannot be evaluated further due to\n * the absence of sufficient information (e.g., variables or applications of variables).\n */\ntype NeutralValue = inductive {\n    // Variable: A neutral value representing an unresolved variable.\n    Var(String)\n    // Application: Applying a neutral function to a value.\n    Apply(NeutralValue, Value)\n    // Projection: Extracting the first or second element of a pair.\n    Proj(Projection, NeutralValue)\n}\n\n/**\n * Converts a `NeutralValue` into a `Value`.\n * @param neutral The `NeutralValue` to convert.\n * @return The resulting `Value`.\n */\ndef toValue(neutral: NeutralValue): Value = Value::Neutral(neutral)\n\n/**\n * `TypedValue` pairs a value with its type, essential for type checking and\n * ensuring type safety during evaluation.\n */\ntype TypedValue = record {\n    value: Value    // The evaluated value.\n    ty: Type        // The type of the value.\n}\n\n/**\n * `Env` represents the typing context, mapping variable names to their corresponding typed values.\n */\ntype Env = inductive {\n    Empty\n    Cons(String, TypedValue, Env)\n}\n\n/**\n * Adds a new binding to the environment.\n * @param env The current environment.\n * @param name The variable name.\n * @param value The value to bind.\n * @param ty The type of the value.\n * @return A new environment with the added binding.\n */\ndef add(env: Env, name: String, value: Value, ty: Type): Env = {\n    let typedValue = TypedValue '{\n        value = value  // The value associated with the name.\n        ty = ty        // The type of the value.\n    }\n    Env::Cons(name, typedValue, env)\n}\n\n/**\n * Adds a variable to the environment as a neutral value, commonly used when introducing parameters.\n * @param env The current environment.\n * @param ident The identifier of the variable.\n * @param ty The type of the variable.\n * @return A new environment with the variable added as a neutral value.\n */\ndef addVar(env: Env, ident: String, ty: Type): Env = {\n    env.add(ident, NeutralValue::Var(ident).toValue, ty)\n}\n\n/**\n * Retrieves a binding from the environment by name.\n * @param env The current environment.\n * @param name The name of the variable to retrieve.\n * @return An `Option` of `TypedValue` containing the variable's type if found, or `None` if not found.\n */\ndef get(env: Env, name: String): Option[TypedValue] = {\n    match env {\n        case Env::Empty =&gt; Option[TypedValue]::None  // Name not found.\n        case Env::Cons(name', value, env') =&gt; {\n            if name' == name then Option[TypedValue]::Some(value)\n            else env'.get(name) // Search in the rest of the environment.\n        }\n    }\n}\n\n/**\n * Checks if a name exists in the environment.\n * @param env The current environment.\n * @param name The name to check for.\n * @return `true` if the name exists in the environment, `false` otherwise.\n */\ndef contains(env: Env, name: String): Bool = match env {\n    case Env::Empty =&gt; false  // Name not found.\n    case Env::Cons(name', _, env') =&gt; name' == name || env'.contains(name)  // Found or continue searching.\n}\n\n/**\n * Generates a fresh identifier not present in the environment, used to avoid variable capture during substitution.\n * @param env The current environment.\n * @param cnt The starting count for generating identifiers.\n * @return A fresh identifier not currently in the environment.\n */\ndef freshIdentFrom(env: Env, cnt: Int): String = {\n    let ident = \"$\" ++ cnt.toString     // Generates identifiers like `$0`, `$1`, etc.\n    if !env.contains(ident) then ident  // If not in the environment, it's fresh.\n    else env.freshIdentFrom(cnt + 1)    // Try the next identifier.\n}\n\n/**\n * Generates a fresh identifier starting from `$0`.\n * @param env The current environment.\n * @return A fresh identifier.\n */\ndef freshIdent(env: Env): String = env.freshIdentFrom(0)\n\n/**\n * Evaluates a `Term` in a given environment to produce a `Value`.\n * Evaluation proceeds by pattern matching on the term's structure.\n * @param env The current environment.\n * @param expr The `Term` to evaluate.\n * @return The evaluated `Value`.\n */\ndef evaluate(env: Env, expr: Term): Value = match expr {\n    // Look up the variable's value.\n    case Term::Var(name) =&gt; env.get(name).unwrap[TypedValue].value\n    // A type evaluates to itself.\n    case Term::Type(univ) =&gt; Value::Type(univ)\n    // Lambda Evaluation: Constructs a closure capturing the environment and parameter.\n    case Term::Lambda(paramIdent, paramTypeTerm, bodyTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate the body with the argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(bodyTerm)\n        }\n        Value::Lambda(paramType, closure)\n    }\n    // Pi Type Evaluation: Similar to lambda\n    case Term::Pi(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate codomain with argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(codomainTerm)\n        }\n        Value::Pi(paramType, closure)\n    }\n    // Sigma Type Evaluation: Similar to lambda\n    case Term::Sigma(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        let paramType = env.evaluate(paramTypeTerm) // Evaluate parameter type.\n        let closure = (arg: Value) =&gt; {\n            // Evaluate codomain with argument bound.\n            env.add(paramIdent, arg, paramType).evaluate(codomainTerm)\n        }\n        Value::Sigma(paramType, closure)\n    }\n    // Function Application Evaluation\n    case Term::Apply(fn, arg) =&gt; match env.evaluate(fn) {\n        // Apply function to the argument.\n        case Value::Lambda(_, fn) =&gt; fn(env.evaluate(arg))\n        // Neutral Application: Cannot reduce further; keep it a neutral value.\n        case Value::Neutral(neutral) =&gt; NeutralValue::Apply(neutral, env.evaluate(arg)).toValue\n        case _ =&gt; panic(\"Invalid type: not a function\")\n    }\n    // Pair Construction\n    case Term::Pair(fst, snd) =&gt; Value::Pair(env.evaluate(fst), env.evaluate(snd))\n    // Pair Projection\n    case Term::Proj(proj, pair) =&gt; match env.evaluate(pair) {\n        case Value::Pair(fst, snd) =&gt; match proj {\n            case Projection::Fst =&gt; fst\n            case Projection::Snd =&gt; snd\n        }\n        case Value::Neutral(neutral) =&gt; NeutralValue::Proj(proj, neutral).toValue\n        case _ =&gt; panic(\"Invalid type: not a pair\")\n    }\n}\n\n/**\n * Converts a `NeutralValue` back into a `Term`, used during normalization to reconstruct\n * terms from evaluated values.\n * @param neutral The `NeutralValue` to convert.\n * @param env The current environment.\n * @return The reconstructed `Term`.\n */\ndef readBack(neutral: NeutralValue, env: Env): Term = match neutral {\n    // Convert variable to term.\n    case NeutralValue::Var(name) =&gt; Term::Var(name)\n    // Reconstruct application.\n    case NeutralValue::Apply(fn, arg) =&gt; Term::Apply(fn.readBack(env), arg.readBack(env))\n    // Reconstruct projection.\n    case NeutralValue::Proj(proj, neutral) =&gt; Term::Proj(proj, neutral.readBack(env))\n}\n\n/**\n * Converts a `Value` back into a `Term`, effectively normalizing the term by reducing it to its simplest form.\n * @param value The `Value` to convert.\n * @param env The current environment.\n * @return The normalized `Term`.\n */\ndef readBack(value: Value, env: Env): Term = match value {\n    case Value::Neutral(neutral) =&gt; neutral.readBack(env)\n    case Value::Type(univ) =&gt; Term::Type(univ)\n    case Value::Pair(fst, snd) =&gt; Term::Pair(fst.readBack(env), snd.readBack(env))\n\n    // Lambda Normalization: Generate a fresh variable to avoid capture.\n    case Value::Lambda(paramType, fn) =&gt; {\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Lambda(\n            paramIdent, paramTypeTerm,         // Construct lambda term.\n            fn(variable).readBack(updatedEnv)  // Normalize the body.\n        )\n    }\n\n    // Pi Type Normalization: Similar to lambda normalization.\n    case Value::Pi(paramType, fn) =&gt; {\n        // Fresh parameter name.\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Pi(\n            paramIdent, paramTypeTerm,          // Construct Pi type term.\n            fn(variable).readBack(updatedEnv)   // Normalize the codomain.\n        )\n    }\n\n    // Sigma Type Normalization: Similar to lambda normalization.\n    case Value::Sigma(paramType, fn) =&gt; {\n        // Fresh parameter name.\n        let paramIdent: String = env.freshIdent\n        // Normalize parameter type.\n        let paramTypeTerm = paramType.readBack(env)\n        // Create variable value.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment.\n        let updatedEnv = env.add(paramIdent, variable, env.evaluate(paramTypeTerm))\n        Term::Sigma(\n            paramIdent, paramTypeTerm,          // Construct Sigma type term.\n            fn(variable).readBack(updatedEnv)   // Normalize the codomain.\n        )\n    }\n}\n\n/**\n * Retrieves the universe level from a `Type` value.\n * Universe levels are critical in MLTT to maintain consistency and avoid paradoxes.\n * @param ty The `Type` value.\n * @return The universe level as an `Int`.\n */\ndef universeLevel(ty: Type): Int = match ty {\n    case Value::Type(univ) =&gt; univ                                  // Extract universe level.\n    case _ =&gt; panic(\"Failed to unwrap universe level: not a type\")  // Panic if not a type.\n}\n\n/**\n * Infers the type of a `Term` within a given environment following MLTT's typing rules.\n * @param env The current environment.\n * @param expr The `Term` whose type is inferred.\n * @return The inferred type as a `Value`.\n */\ndef infer(env: Env, expr: Term): Value = match expr {\n\n    // Retrieve the variable's type from the environment.\n    case Term::Var(name) =&gt; env.get(name).unwrap[TypedValue].ty\n\n    // `Type(n)` has type `Type(n + 1)`.\n    case Term::Type(univ) =&gt; Value::Type(univ + 1)\n\n    // Lambda Type Inference:\n    case Term::Lambda(paramIdent, paramTypeTerm, bodyTerm) =&gt; {\n        // Infer parameter type's universe level.\n        let paramLevel = env.infer(paramTypeTerm).universeLevel\n        // Evaluate parameter type.\n        let paramType: Type = env.evaluate(paramTypeTerm)\n        // Create variable for parameter.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        // Extend environment with parameter.\n        let bodyEnv = env.add(paramIdent, variable, paramType)\n        // Infer body's type.\n        let returnType: Type = bodyEnv.infer(bodyTerm)\n        // The lambda's type is a Pi type from parameter to return type.\n        Value::Pi(\n            paramType,\n            (arg: Value) =&gt; {\n                // Infer argument's type.\n                let argType = env.infer(arg.readBack(bodyEnv))\n                // Evaluate the body.\n                bodyEnv.add(paramIdent, arg, argType).evaluate(bodyTerm)\n            }\n        )\n    }\n\n    // Pair Type Inference:\n    case Term::Pair(fst, snd) =&gt; {\n        // Infer the type of the first element.\n        let fstType: Type = env.infer(fst)\n        // Infer the type of the second element.\n        let sndType: Type = env.infer(snd)\n        // The pair type is a Sigma type of the two elements.\n        Value::Sigma(fstType, (fstValue: Value) =&gt; {\n            Value::Sigma(sndType, (sndValue: Value) =&gt; Value::Pair(fstValue, sndValue))\n        })\n    }\n\n    // Pi Type Inference:\n    case Term::Pi(paramIdent, paramTypeTerm, returnTypeTerm) =&gt; {\n        // Infer parameter type's universe level.\n        let paramLevel = env.infer(paramTypeTerm).universeLevel\n        // Evaluate parameter type.\n        let paramType: Type = env.evaluate(paramTypeTerm)\n        // Create variable for parameter.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        let returnTypeLevel = env.add(paramIdent, variable, paramType).infer(returnTypeTerm).universeLevel\n        // The Pi type's universe level is the maximum of parameter and return types.\n        Value::Type(max paramLevel returnTypeLevel)\n    }\n\n    // Sigma Type Inference:\n    case Term::Sigma(paramIdent, paramTypeTerm, codomainTerm) =&gt; {\n        // Infer parameter type's universe level.\n        let paramLevel = env.infer(paramTypeTerm).universeLevel\n        // Evaluate parameter type.\n        let paramType: Type = env.evaluate(paramTypeTerm)\n        // Create variable for parameter.\n        let variable: Value = NeutralValue::Var(paramIdent).toValue\n        let rhsTypeLevel = env.add(paramIdent, variable, paramType).infer(codomainTerm).universeLevel\n        // The sigma type's universe level is the maximum of lhs and rhs types.\n        Value::Type(max paramLevel rhsTypeLevel)\n    }\n}\n\n/**\n * Normalizes a `Term` by evaluating it and converting the result back into a term.\n * Normalization is essential for comparing terms for equality and ensuring consistent behavior.\n * @param env The current environment.\n * @param expr The `Term` to normalize.\n * @return The normalized `Term`.\n */\ndef normalize(env: Env, expr: Term): Term = env.evaluate(expr).readBack(env)\n\ndef pretty(expr: Term): String = match expr {\n    case Term::Var(name) =&gt; name\n    case Term::Type(univ) =&gt; \"Type(\" ++ univ.toString ++ \")\"\n    case Term::Lambda(paramIdent, paramType, body) =&gt;\n        \"\u03bb(\" ++ paramIdent ++ \" : \" ++ paramType.pretty ++ \"). \" ++ body.pretty\n    case Term::Apply(fn, arg) =&gt; \"(\" ++ fn.prettyAtom ++ \" \" ++ arg.prettyAtom ++ \")\"\n    case Term::Pi(paramIdent, paramType, returnType) =&gt;\n        \"\u03a0(\" ++ paramIdent ++ \" : \" ++ paramType.pretty ++ \"). \" ++ returnType.pretty\n    case Term::Sigma(paramIdent, paramType, codomain) =&gt;\n        \"\u03a3(\" ++ paramIdent ++ \" : \" ++ paramType.pretty ++ \"). \" ++ codomain.pretty\n    case Term::Pair(fst, snd) =&gt; \"(\" ++ fst.pretty ++ \", \" ++ snd.pretty ++ \")\"\n    case Term::Proj(Projection::Fst, pair) =&gt; \"fst \" ++ pair.pretty\n}\n\ndef prettyAtom(expr: Term): String = match expr {\n    case Term::Var(name) =&gt; name\n    case Term::Type(_) =&gt; expr.pretty\n    case Term::Lambda(_, _, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Apply(_, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Pi(_, _, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Sigma(_, _, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n    case Term::Pair(_, _) =&gt; expr.pretty\n    case Term::Proj(_, _) =&gt; \"(\" ++ expr.pretty ++ \")\"\n}\n\ndef var(ident: String): Value = NeutralValue::Var(ident).toValue\n\ndef prelude: Env = Env::Empty\n    .addVar(\"Any\", Value::Type(0))\n    .addVar(\"Nothing\", Value::Type(0))\n    .addVar(\"Bool\", Value::Type(0))\n    .addVar(\"true\", var(\"Bool\"))\n    .addVar(\"false\", var(\"Bool\"))\n    .addVar(\"Nat\", Value::Type(0))\n    .addVar(\"zero\", var(\"Nat\"))\n    .addVar(\"succ\", Value::Pi(var(\"Nat\"), (n: Value) =&gt; var(\"Nat\")))\n\neval \"\\nBeta-reduction: (\u03bbx. t) v -&gt; t[x := v]  Case 1: x[x := N] = N\"\neval {\n    let term: Term = Term::Apply(\n        Term::Lambda(\"x\", Term::Var(\"Bool\"), Term::Var(\"x\")),\n        Term::Var(\"true\")\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nBeta-reduction: (\u03bbx. t) v -&gt; t[x := v]  Case 2: y[x := N] = y, if x \u2260 y\"\neval {\n    let term: Term = Term::Apply(\n        Term::Lambda(\n            \"x\", Term::Var(\"Bool\"),\n            Term::Lambda(\"y\", Term::Var(\"Bool\"), Term::Var(\"y\"))\n        ),\n        Term::Var(\"true\")\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nHigher-order function:\"\neval {\n    let term = Term::Apply(\n        Term::Lambda(\"f\", Term::Pi(\"x\", Term::Var(\"Bool\"), Term::Var(\"Bool\")),\n            Term::Apply(Term::Var(\"f\"), Term::Var(\"true\"))\n        ),\n        Term::Lambda(\"x\", Term::Var(\"Bool\"), Term::Var(\"x\"))\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nAlpha-conversion: \u03bbx. t -&gt; \u03bby. t[x := y] -- no name collision\"\neval {\n    let term = Term::Pi(\"A\", Term::Type(0),\n        Term::Lambda(\"x\", Term::Var(\"A\"), Term::Var(\"x\"))\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nSigma type - elimination\"\neval {\n    let term = Term::Apply(\n        Term::Lambda(\"p\", Term::Sigma(\"A\", Term::Var(\"Bool\"), Term::Var(\"A\")),\n            Term::Proj(Projection::Fst, Term::Var(\"p\"))\n        ),\n        Term::Pair(Term::Var(\"true\"), Term::Var(\"false\"))\n    )\n    term.pretty ++ \"  \u2261  \" ++ prelude.normalize(term).pretty\n}\n\neval \"\\nChurch numeral 0:\"\neval {\n    let zero = Term::Lambda(\"f\", Term::Pi(\"x\", Term::Var(\"Any\"), Term::Var(\"Any\")),\n        Term::Lambda(\"x\", Term::Var(\"Any\"), Term::Var(\"x\"))\n    )\n    zero.pretty ++ \"  \u2261  \" ++ prelude.normalize(zero).pretty\n}\n\neval \"\\nChurch numeral 1:\"\neval {\n    let one = Term::Lambda(\"f\", Term::Pi(\"x\", Term::Var(\"Any\"), Term::Var(\"Any\")),\n        Term::Lambda(\"x\", Term::Var(\"Any\"), Term::Apply(Term::Var(\"f\"), Term::Var(\"x\")))\n    )\n    one.pretty ++ \"  \u2261  \" ++ prelude.normalize(one).pretty\n}\n</code></pre> Run Code"},{"location":"03-proofs/","title":"Construct Formal Proofs","text":""},{"location":"03-proofs/#background","title":"Background","text":"<p>In modern software and systems development, especially in critical applications like artificial intelligence, cryptography, and distributed systems, ensuring code correctness is of utmost importance. Errors in these domains can lead to severe consequences, ranging from security vulnerabilities to catastrophic failures in autonomous systems. Therefore, it's essential to rigorously verify code correctness. Formal proofs provide a solid foundation for this verification, ensuring that programs not only execute correctly but are mathematically guaranteed to meet their specifications.</p> <p>A formal proof is a mathematically rigorous argument demonstrating the truth of a statement within a formal system. Unlike informal proofs that rely on intuition and natural language, formal proofs are expressed symbolically and precisely. They are designed to be machine-verifiable, meaning automated theorem provers or proof assistants can check them. This capability is particularly important in fields such as:</p> <ul> <li>Software Verification: Ensuring that critical software components (e.g., in aerospace, medical devices, or autonomous systems) are free of bugs and perform as intended.</li> <li>AI Code Synthesis: Verified AI code synthesis uses formal proofs to ensure that automatically generated code meets its specification, reducing the risk of errors in complex systems generated by machine learning models.</li> </ul>"},{"location":"03-proofs/#type-level-programming-and-proofs","title":"Type-Level Programming and Proofs","text":"<p>In type-level programming, types are not just used for ensuring low-level correctness (e.g., checking that an integer is passed to a function expecting an integer) but for encoding complex logical propositions and ensuring that programs satisfy deep properties, such as invariants or theorems. When we speak of dependent types, these are types that depend on values, allowing us to encode even more detailed and precise properties about programs.</p> <p>For example, when dealing with natural numbers, the proof of properties such as equality, commutativity, and associativity can be encoded directly in the type system. The formal proof of a mathematical statement like \"equality is symmetric\" becomes a recursive function over the natural numbers, and the type system ensures that the proof is complete and correct.</p> <p>We will now move from this background into the concrete construction of a formal proof of the symmetry of equality for natural numbers. This construction will follow the principles of the Curry-Howard correspondence, where the proof is represented as a program in a type-safe, recursive language, and the proposition of symmetric equality is encoded as a type.</p>"},{"location":"03-proofs/#curry-howard-correspondence","title":"Curry-Howard Correspondence","text":"<p>The Curry-Howard correspondence, also known as the propositions-as-types paradigm, is a foundational concept in type theory that establishes a deep relationship between logic and computation. According to this correspondence, logical propositions correspond to types in programming, and proofs of those propositions correspond to programs (or functions) that inhabit those types.</p> <p>In this framework:</p> <ul> <li>Logical Propositions (such as \\(P \\to Q\\), \\(P \\land Q\\), and \\(P \\lor Q\\)) correspond to types in programming languages.</li> <li>Proofs of these propositions correspond to programs (i.e., functions) that construct elements of these types.</li> <li>Constructive Proofs: A proof of a logical statement in this system is constructive, meaning that it not only asserts the truth of the proposition but also provides a method (i.e., an algorithm) for constructing evidence that the proposition holds.</li> </ul> <p>The Curry-Howard correspondence can be summarized as:</p> Logical Concept Programming Concept Proposition \\(P\\) Type \\(T\\) Proof of \\(P\\) Value of type \\(T\\) Implication \\(P \\to Q\\) Function type \\(T_1 \\to T_2\\) Conjunction \\(P \\land Q\\) Pair type \\(T_1 \\times T_2\\) Disjunction \\(P \\lor Q\\) Sum type \\(T_1 + T_2\\) Falsehood \\(\\bot\\) Empty type (no inhabitants) Truth \\(\\top\\) Unit type (single inhabitant) Universal quantification \\(\\forall\\) Dependent function type (\\(\\Pi\\)-type) Existential quantification \\(\\exists\\) Dependent pair type (\\(\\Sigma\\)-type) <p>Through the Curry-Howard correspondence, we can view formal proofs as programs, and the act of proving a theorem becomes synonymous with writing a program that satisfies the corresponding type signature. This correspondence has significant implications for formal verification, enabling the use of proof assistants (such as Coq, Agda, and Lean) to both prove mathematical theorems and verify the correctness of programs in type-safe programming languages like Saki, Haskell, or other dependent type systems.</p> <p>For example, the proposition \\(P \\to Q\\) (i.e., if \\(P\\) holds, then \\(Q\\) holds) corresponds to a function that takes a value of type \\(P\\) and returns a value of type \\(Q\\). Proving this proposition requires constructing such a function. Similarly, proving equality between two elements \\(a\\) and \\(b\\) corresponds to constructing a proof of type \\(A.\\text{Eq}(a, b)\\), which can be interpreted as constructing a witness to the fact that \\(a\\) and \\(b\\) are equal in the system.</p>"},{"location":"03-proofs/#dependent-types","title":"Dependent Types","text":"<p>Dependent types are an extension of the basic types used in functional programming languages. They allow types to depend on values, thus enabling richer and more precise specifications of programs. Two important forms of dependent types that correspond to universal and existential quantifiers in logic are:</p>"},{"location":"03-proofs/#dependent-function-types-pi-types","title":"Dependent Function Types (\\(\\Pi\\)-Types)","text":"<p>These types correspond to the universal quantifier \\(\\forall\\) in logic. They are also called dependent function types because they generalize the function types to allow the output type to depend on the value of the input. Formally:</p> \\[ \\Pi(x : A) . P(x) \\] <p>This represents a function that, for each value \\(x\\) of type \\(A\\), returns a value of type \\(P(x)\\), where \\(P(x)\\) is a type that may depend on \\(x\\). In logical terms, this corresponds to the statement \"\\(\\forall x \\in A, P(x)\\)\" which means \"for every \\(x\\) of type \\(A\\), the proposition \\(P(x)\\) holds.\"</p> <p>In programming terms, this is a generalization of function types because the type of the result of the function can vary depending on the input. For example, in a dependently typed language, we might express the type of a list's length as a function from lists to natural numbers:</p> <pre><code>length : \u2200(A : Type) -&gt; List(A) -&gt; \u2115\n</code></pre> <p>This says that for every type \\(A\\), <code>length</code> is a function from a list of type \\(A\\) to a natural number, describing the length of the list.</p>"},{"location":"03-proofs/#dependent-pair-types-sigma-types","title":"Dependent Pair Types (\\(\\Sigma\\)-Types)","text":"<p>These types correspond to the existential quantifier \\(\\exists\\) in logic. They represent pairs where the type of the second element depends on the value of the first element. Formally:</p> \\[ \\Sigma(x : A) . P(x) \\] <p>This represents a pair \\((x, y)\\) where \\(x\\) is of type \\(A\\) and \\(y\\) is of type \\(P(x)\\), where \\(P(x)\\) depends on \\(x\\). In logical terms, this corresponds to the statement \"\\(\\exists x \\in A, P(x)\\)\" which means \"there exists an \\(x\\) of type \\(A\\) such that the proposition \\(P(x)\\) holds.\"</p> <p>In programming, a \\(\\Sigma\\)-type allows for encoding richer structures where some values depend on others. For example, we can encode the type of non-empty lists by using a \\(\\Sigma\\)-type where the list's first element exists and subsequent elements are of type \\(A\\):</p> <pre><code>NonEmptyList(A : Type) = \u2203(n : \u2115) \u00d7 Vector(A, n)\n</code></pre> <p>This says that a non-empty list of type \\(A\\) is a pair consisting of a natural number \\(n\\) and a vector of \\(n\\) elements of type \\(A\\). The second component depends on the first, reflecting the idea that the length of the list is tied to the vector's length.</p>"},{"location":"03-proofs/#universal-quantification-forall-and-dependent-pi-types","title":"Universal Quantification (\\(\\forall\\)) and Dependent \\(\\Pi\\)-Types","text":"<p>In logic, the universal quantifier \\(\\forall\\) represents statements that hold for all elements of a certain set. In the Curry-Howard correspondence, \\(\\forall\\) corresponds to the dependent function type (also called the \\(\\Pi\\)-type). A proposition \\(\\forall x \\in A, P(x)\\) is equivalent to constructing a function that, given any \\(x\\) of type \\(A\\), returns a proof of \\(P(x)\\). </p> <p>For example, to prove a statement like \"\\(\\forall n \\in \\mathbb{N}, n + 0 = n\\)\" (i.e., zero is the identity element for addition over natural numbers), we construct a function that takes a natural number \\(n\\) and returns a proof that \\(n + 0 = n\\).</p> <p>In type theory, the dependent function type \\(\\Pi(x : A) . P(x)\\) is used to encode this idea. It represents a function that, for each \\(x \\in A\\), returns a value of type \\(P(x)\\), where \\(P(x)\\) can depend on the input \\(x\\). </p>"},{"location":"03-proofs/#existential-quantification-exists-and-dependent-sigma-types","title":"Existential Quantification (\\(\\exists\\)) and Dependent \\(\\Sigma\\)-Types","text":"<p>The existential quantifier \\(\\exists\\) in logic asserts the existence of an element with a certain property. In the Curry-Howard correspondence, \\(\\exists\\) corresponds to the dependent pair type (or \\(\\Sigma\\)-type). A proposition \\(\\exists x \\in A, P(x)\\) is equivalent to constructing a pair consisting of an element \\(x\\) of type \\(A\\) and a proof that \\(P(x)\\) holds for that \\(x\\).</p> <p>In type theory, the dependent pair type \\(\\Sigma(x : A) . P(x)\\) is used to encode this idea. It represents a pair \\((x, p)\\), where \\(x\\) is an element of type \\(A\\) and \\(p\\) is a proof that \\(P(x)\\) holds. The type \\(P(x)\\) can depend on \\(x\\), allowing us to express properties that vary depending on the value of \\(x\\).</p> <p>For instance, if we want to express the statement \"there exists a natural number \\(n\\) such that \\(n\\) is even,\" we could use a \\(\\Sigma\\)-type to represent this in type theory:</p> <pre><code>EvenNumber = \u2203(n : \u2115) \u00d7 isEven(n)\n</code></pre> <p>This type encodes both the natural number \\(n\\) and a proof that \\(n\\) satisfies the property of being even.</p>"},{"location":"03-proofs/#definition-of-equality-reflexivity-and-symmetry","title":"Definition of Equality, Reflexivity, and Symmetry","text":"<p>We begin by establishing the formal definitions of equality, reflexivity, and symmetry within the framework of type theory. These definitions are critical for the subsequent construction of inductive proofs on natural numbers.</p>"},{"location":"03-proofs/#definition-of-equality","title":"Definition of Equality","text":"<p>The equality relation between two elements \\(a, b\\) of a type \\(A\\) is defined as a dependent type \\(A.Eq(a, b)\\), which asserts that \\(a\\) and \\(b\\) are equal. This is expressed using a dependent type \\(A \\to \\mathcal{U}\\) where \\(\\mathcal{U}\\) is the universe of types. Formally, the equality type \\(A.Eq(a, b)\\) is defined as:</p> \\[ Eq_A(a, b) :\\equiv \\forall (P : A \\to \\mathcal{U}) . P(a) \\to P(b) \\] <p>This means that \\(A.Eq(a, b)\\) holds if, for all propositions \\(P\\) on \\(A\\), whenever \\(P(a)\\) is true, \\(P(b)\\) must also hold. In essence, this defines equality as the ability to substitute \\(a\\) for \\(b\\) in any context described by \\(P\\).</p> <pre><code>def Eq(A: 'Type, a b: A): 'Type = \u2200(P: A -&gt; 'Type) -&gt; P(a) -&gt; P(b)\n</code></pre>"},{"location":"03-proofs/#reflexivity-of-equality","title":"Reflexivity of Equality","text":"<p>The property of reflexivity asserts that any element \\(a\\) of a type \\(A\\) is equal to itself. This is a fundamental axiom of equality, which can be proven for all types by constructing a proof using the definition of equality.</p> <p>For any element \\(a \\in A\\), reflexivity is stated as:</p> \\[ \\text{refl}_A : \\forall(a: A) . Eq_A(a, a) :\\equiv \\lambda (P : A \\to \\mathcal{U}) . \\lambda (p : P(a)) . p \\] <p>This is trivially true because the proof \\(pa : P(a)\\) already holds. Reflexivity is defined as:</p> <pre><code>def refl(A: 'Type, a: A): A.Eq(a, a) = (P: A -&gt; 'Type, p: P(a)) =&gt; p\n</code></pre> <p>This expresses that for any proposition \\(P\\), if \\(P(a)\\) holds, then \\(P(a)\\) trivially holds again, establishing that \\(a = a\\).</p>"},{"location":"03-proofs/#symmetry-of-equality","title":"Symmetry of Equality","text":"<p>The property of symmetry states that if \\(a = b\\), then \\(b = a\\). Formally, given a proof \\(A.Eq(a, b)\\), we construct a proof of \\(A.Eq(b, a)\\).</p> <p>The symmetry of equality is defined as follows:</p> \\[ \\begin{align} \\text{symm}_A : &amp; \\, \\forall(a, b: A) . Eq_A(a, b) \\to Eq_A(b, a)      \\\\ &amp; :\\equiv \\lambda (e_{ab} : Eq_A(a, b)) . e_{ab}(\\lambda (b' : A) . Eq_A(b', a), \\text{refl}_A(a)) \\end{align} \\] <p>Given a proof of \\(A.Eq(a, b)\\), we construct a proof of \\(A.Eq(b, a)\\) by applying \\(A.Eq(a, b)\\) to the proposition \\(P(b') = A.Eq(b', a)\\), and using the reflexivity of \\(a\\). This is formally stated as:</p> <pre><code>def symmetry(A: 'Type, a b: A, eqab: A.Eq(a, b)): A.Eq(b, a) = {\n    eqab((b': A) =&gt; A.Eq(b', a), A.refl(a))\n}\n</code></pre> <p>This construction uses the existing proof \\(eqab : A.Eq(a, b)\\) to establish \\(A.Eq(b, a)\\), thereby proving symmetry.</p>"},{"location":"03-proofs/#natural-numbers","title":"Natural Numbers","text":"<p>We now turn to the formal inductive definition of the natural numbers \\(\\mathbb{N}\\), which forms the basis for all subsequent proofs.</p>"},{"location":"03-proofs/#inductive-definition-of-mathbbn-natural-numbers-peano-axioms","title":"Inductive Definition of \\(\\mathbb{N}\\) (Natural Numbers): Peano Axioms","text":"<p>The Peano axioms provide a formal foundation for the natural numbers and their properties. These axioms define the structure of \\(\\mathbb{N}\\) (the set of natural numbers) in a recursive manner. The Peano axioms, originally formulated by Giuseppe Peano in 1889, consist of a set of rules that describe how natural numbers are constructed and how operations like addition and equality are defined.</p> <p>The Peano axioms can be summarized as follows:</p> <ol> <li> <p>Zero is a natural number: \\(Z \\in \\mathbb{N}\\).</p> </li> <li> <p>Every natural number has a successor: For each \\(n \\in \\mathbb{N}\\), there exists a successor \\(S(n) \\in \\mathbb{N}\\), which represents the next natural number after \\(n\\).</p> </li> <li> <p>Zero is not the successor of any number: \\(\\forall n \\in \\mathbb{N}, S(n) \\neq Z\\).</p> </li> <li> <p>Distinct numbers have distinct successors: \\(\\forall n, m \\in \\mathbb{N}, S(n) = S(m) \\implies n = m\\).</p> </li> <li> <p>Mathematical induction: If a property \\(P\\) holds for zero and holds for the successor of \\(n\\) whenever it holds for \\(n\\), then \\(P\\) holds for all natural numbers \\(n\\).</p> </li> </ol> <p>These axioms define the structure of the natural numbers and allow us to reason about properties such as addition, multiplication, and equality in a recursive manner. The natural numbers, as defined by these axioms, are typically represented as:</p> \\[ \\mathbb{N} ::= Z \\mid S(n) \\quad \\text{where } n \\in \\mathbb{N} \\] <ul> <li>\\(Z\\) is the natural number zero.</li> <li>\\(S(n)\\) is the successor of \\(n\\), representing the number immediately following \\(n\\).</li> </ul> <p>For example:</p> <ul> <li>\\(Z\\) represents the number \\(0\\),</li> <li>\\(S(Z)\\) represents \\(1\\),</li> <li>\\(S(S(Z))\\) represents \\(2\\), and so on.</li> </ul> <p>The natural numbers are defined inductively by two constructors:</p> <ul> <li>\\(\\text{Zero} : \\mathbb{N}\\), representing the number \\(0\\),</li> <li>\\(\\text{Succ} : \\mathbb{N} \\to \\mathbb{N}\\), representing the successor of a natural number \\(n\\).</li> </ul> <p>Formally, the inductive type \\(\\mathbb{N}\\) is given by:</p> \\[ \\mathbb{N} ::= \\text{Zero} \\mid \\text{Succ}(n) \\quad \\text{where } n \\in \\mathbb{N} \\] <p>This is captured in the following Saki code:</p> <pre><code>type \u2115 = inductive {\n    Zero\n    Succ(\u2115)\n}\n</code></pre> <p>To make the proof code clear, we add some extra definitions for further proof: </p> <pre><code>operator binary (===) left-assoc {\n    looser-than (+)\n}\n\ndef (===)(a b: \u2115): 'Type = \u2115.Eq(a, b)\n\ndef o: \u2115 = \u2115::Zero\ndef succ(n: \u2115): \u2115 = \u2115::Succ(n)\n</code></pre>"},{"location":"03-proofs/#definition-of-addition-for-natural-numbers","title":"Definition of Addition for Natural Numbers","text":"<p>Addition on natural numbers is defined recursively. For \\(a, b \\in \\mathbb{N}\\), the addition function \\(+\\) is defined as: $$ + : \\mathbb{N} \\to \\mathbb{N} \\to \\mathbb{N} $$ $$ a + 0 = a $$ $$ a + \\text{Succ}(b) = \\text{Succ}(a + b) $$</p> <p>and is formally defined in Saki code below:</p> <pre><code>def (+)(a b : \u2115): \u2115 = match a {\n    case \u2115::Zero =&gt; b\n    case \u2115::Succ(a') =&gt; \u2115::Succ(a' + b)\n}\n</code></pre> <ul> <li>Base Case: When \\(a = 0\\), \\(a + b = b\\).</li> <li>Recursive Step: When \\(a = \\text{Succ}(a')\\), \\(a + b = \\text{Succ}(a' + b)\\), adding one to the result of adding \\(a'\\) and \\(b\\).</li> </ul>"},{"location":"03-proofs/#induction-principles-and-theorems-on-natural-numbers","title":"Induction Principles and Theorems on Natural Numbers","text":"<p>Let \\(\\mathbb{N}\\) be the type of natural numbers, defined inductively by \\(\\text{Zero} : \\mathbb{N}\\) and \\(\\text{Succ} : \\mathbb{N} \\to \\mathbb{N}\\). The following formal proof is conducted using type theory and the induction principle, denoted as follows:</p>"},{"location":"03-proofs/#induction-principle","title":"Induction Principle","text":"<p>Let \\(P : \\mathbb{N} \\to \\mathcal{U}\\) be a dependent type, where \\(\\mathcal{U}\\) is the universe of types. The induction principle on natural numbers is formulated as:</p> \\[ \\text{induction}_{\\mathbb{N}} : \\prod_{P : \\mathbb{N} \\to \\mathcal{U}} P(\\text{Zero}) \\to \\left( \\prod_{n : \\mathbb{N}} P(n) \\to P(\\text{Succ}(n)) \\right) \\to \\prod_{n : \\mathbb{N}} P(n) \\] <p>This principle constructs a proof that \\(P(n)\\) holds for all \\(n \\in \\mathbb{N}\\), given that \\(P(\\text{Zero})\\) holds and that \\(P(n) \\to P(\\text{Succ}(n))\\) holds for all \\(n \\in \\mathbb{N}\\).</p> <pre><code>def induction(\n    P: \u2115 -&gt; 'Type,\n    base: P(\u2115::Zero),\n    induce: \u2200(n: \u2115) -&gt; P(n) -&gt; P(n.succ),\n    nat: \u2115,\n): P(nat) = match nat {\n    case \u2115::Zero =&gt; base\n    case \u2115::Succ(n') =&gt; induce(n', P.induction(base, induce, n'))\n}\n</code></pre>"},{"location":"03-proofs/#induction-reduction","title":"Induction Reduction","text":"<p>Let \\(a, b : \\mathbb{N}\\) and \\(P : \\mathbb{N} \\to \\mathcal{U}\\) be a dependent type. To simplify inductive proofs, we define a reduction function based on symmetry:</p> \\[ \\text{inductionReduce} : \\prod_{a, b : \\mathbb{N}} (b = a) \\to P(a) \\to P(b) \\] <p>This function allows us to reverse the direction of an equality \\(b = a\\) to \\(a = b\\) via the symmetry of equality and use \\(P(a)\\) to derive \\(P(b)\\).</p> <pre><code>def inductionReduce(\n    a b: \u2115,\n    eqba: (b === a),\n    P: \u2115 -&gt; 'Type,\n    pa: P(a),\n): P(b) = {\n    let eqab = \u2115.symmetry(b, a, eqba)\n    eqab(P, pa)\n}\n</code></pre>"},{"location":"03-proofs/#theorem-n-0-n","title":"Theorem: \\(n + 0 = n\\)","text":"<p>We prove by induction on \\(n \\in \\mathbb{N}\\) that \\(n + 0 = n\\): $$ \\forall n \\in \\mathbb{N}, n + 0 = n $$</p> <p>This is formalized using the induction principle:</p> \\[ \\text{theoremPlusZero} : \\prod_{n : \\mathbb{N}} (n + 0 = n) \\] <pre><code>def theoremPlusZero: \u2200(n: \u2115) -&gt; (n + o === n) = {\n    ((n: \u2115) =&gt; (n + o === n)).induction(\n        \u2115.refl(\u2115::Zero),\n        (n: \u2115, assumption: (n + o === n)) =&gt; {\n            inductionReduce(\n                n, n + o, assumption,\n                (n': \u2115) =&gt; (n'.succ === n.succ),\n                \u2115.refl(n.succ)\n            )\n        }\n    )\n}\n</code></pre> <p>This inductive proof proceeds as follows:</p> <ul> <li>Base Case: \\(0 + 0 = 0\\), by reflexivity of equality.</li> <li>Inductive Step: Assume \\(n + 0 = n\\), and prove that \\(S(n) + 0 = S(n)\\), which follows from the inductive hypothesis and the definition of addition.</li> </ul>"},{"location":"03-proofs/#leibniz-equality","title":"Leibniz Equality","text":"<p>We define the Leibniz rule of equality, which states that if \\(a = b\\), then for any function \\(f : \\mathbb{N} \\to \\mathbb{N}\\), \\(f(a) = f(b)\\). This is formalized as:</p> \\[ \\text{leibnizEq} : \\prod_{a, b : \\mathbb{N}} (a = b) \\to \\prod_{f : \\mathbb{N} \\to \\mathbb{N}} f(a) = f(b) \\] <pre><code>def leibnizEq(f: \u2115 -&gt; \u2115): \u2200(a: \u2115) -&gt; \u2200(b: \u2115) -&gt; (a === b) -&gt; (f(a) === f(b)) = {\n    (a b : \u2115, eqab: (a === b)) =&gt; {\n        (P: \u2115 -&gt; 'Type, pfa: P(f a)) =&gt; eqab((b': \u2115) =&gt; P(f b'), pfa)\n    }\n}\n</code></pre>"},{"location":"03-proofs/#theorem-n-n-0","title":"Theorem: \\(n = n + 0\\)","text":"<p>The reverse direction, \\(n = n + 0\\), is derived using the symmetry of equality and the previously proven theorem:</p> \\[ \\forall n \\in \\mathbb{N}, n = n + 0 \\] <p>This is formalized as:</p> <pre><code>def theoremPlusZeroInv: \u2200(n: \u2115) -&gt; (n === n + o) = {\n    (n: \u2115) =&gt; \u2115.symmetry(n + o, n, theoremPlusZero(n))\n}\n</code></pre>"},{"location":"03-proofs/#theorem-successor-and-addition","title":"Theorem: Successor and Addition","text":"<p>We now prove that for all \\(a, b \\in \\mathbb{N}\\), the following holds:</p> \\[ \\forall a, b \\in \\mathbb{N}, S(a + b) = a + S(b) \\] <p>This is formalized as:</p> <pre><code>def theoremPlusSucc: \u2200(a: \u2115) -&gt; \u2200(b: \u2115) -&gt; (succ(a + b) === a + b.succ) = {\n    (a b : \u2115) =&gt; induction(\n        (a': \u2115) =&gt; (succ(a' + b) === a' + b.succ),\n        \u2115.refl(succ(o + b)),\n        (a': \u2115, assumption: (succ(a' + b) === a' + b.succ)) =&gt; {\n            leibnizEq(succ, succ(a' + b), a' + b.succ, assumption)\n        }, a\n    )\n}\n</code></pre> <ul> <li>Base Case: \\(S(0 + b) = 0 + S(b)\\), which holds by reflexivity.</li> <li>Inductive Step: Assuming \\(S(a + b) = a + S(b)\\), prove that \\(S(S(a) + b) = S(a) + S(b)\\), using the inductive hypothesis.</li> </ul>"},{"location":"03-proofs/#transitivity-of-equality","title":"Transitivity of Equality","text":"<p>Equality in type theory satisfies the transitivity property: $$ \\forall a, b, c \\in \\mathbb{N}, (a = b) \\land (b = c) \\to a = c $$ This is formalized as: $$ \\text{transitivity} : \\prod_{a, b, c : A} A.Eq(a, b) \\to A.Eq(b, c) \\to A.Eq(a, c) $$</p> <pre><code>def transitivity(A: 'Type, a b c: A, eqab: A.Eq(a, b), eqbc: A.Eq(b, c)): A.Eq(a, c) = {\n    (P: A -&gt; 'Type, pa: P(a)) =&gt; eqbc(P, eqab(P, pa))\n}\n</code></pre>"},{"location":"03-proofs/#theorem-commutativity-of-addition","title":"Theorem: Commutativity of Addition","text":"<p>Finally, we prove the commutativity of addition, i.e., for all \\(a, b \\in \\mathbb{N}\\): $$ a + b = b + a $$ This is formalized as:</p> <pre><code>def theoremPlusComm: \u2200(a: \u2115) -&gt; \u2200(b: \u2115) -&gt; (a + b === b + a) = {\n    (a: \u2115, b: \u2115) =&gt; induction(\n        (a': \u2115) =&gt; (a' + b === b + a'),\n        theoremPlusZeroInv b,\n        (a': \u2115, IH: (a' + b === b + a')) =&gt; {\n            let eq1 = \u2115.refl(succ(a' + b))                  // succ(a') + b === succ(a' + b)\n            let eq2 = leibnizEq(succ, a' + b, b + a', IH)   // succ(a' + b) === succ(b + a')\n            let eq3 = theoremPlusSucc(b, a')                // succ(b + a') === b + succ(a')\n            let eq4 = transitivity(\u2115, succ(a' + b), succ(b + a'), b + succ(a'), eq2, eq3)\n            transitivity(\u2115, succ(a') + b, succ(a' + b), b + succ(a'), eq1, eq4)\n        }, a\n    )\n}\n</code></pre> <ul> <li>Base Case: \\(0 + b = b + 0\\), follows from \\(n + 0 = n\\) and \\(n = n + 0\\).</li> <li>Inductive Step: Assuming \\(a + b = b + a\\), prove that \\(S(a) + b = b + S(a)\\), using the inductive hypothesis, successor properties, and transitivity of equality.</li> </ul>"},{"location":"03-proofs/#complete-code","title":"Complete Code","text":"<pre><code>def Eq(A: 'Type, a b: A): 'Type = \u2200(P: A -&gt; 'Type) -&gt; P(a) -&gt; P(b)\n\ndef refl(A: 'Type, a: A): A.Eq(a, a) = {\n    (P: A -&gt; 'Type, pa: P(a)) =&gt; pa\n}\n\ndef symmetry(A: 'Type, a b: A, eqab: A.Eq(a, b)): A.Eq(b, a) = {\n    eqab((b': A) =&gt; A.Eq(b', a), A.refl(a))\n}\n\ntype \u2115 = inductive {\n    Zero\n    Succ(\u2115)\n}\n\ndef o: \u2115 = \u2115::Zero\ndef succ(n: \u2115): \u2115 = \u2115::Succ(n)\n\noperator binary (===) left-assoc {\n    looser-than (+)\n}\n\ndef (===)(a b: \u2115): 'Type = \u2115.Eq(a, b)\n\ndef (+)(a b : \u2115): \u2115 = match a {\n    case \u2115::Zero =&gt; b\n    case \u2115::Succ(a') =&gt; \u2115::Succ(a' + b)\n}\n\ndef induction(\n    P: \u2115 -&gt; 'Type,\n    base: P(\u2115::Zero),\n    induce: \u2200(n: \u2115) -&gt; P(n) -&gt; P(n.succ),\n    nat: \u2115,\n): P(nat) = match nat {\n    case \u2115::Zero =&gt; base\n    case \u2115::Succ(n') =&gt; induce(n', P.induction(base, induce, n'))\n}\n\ndef inductionReduce(\n    a b: \u2115,\n    eqba: (b === a),\n    P: \u2115 -&gt; 'Type,\n    pa: P(a),\n): P(b) = {\n    let eqab = \u2115.symmetry(b, a, eqba)\n    eqab(P, pa)\n}\n\ndef theoremPlusZero: \u2200(n: \u2115) -&gt; (n + o === n) = {\n    ((n: \u2115) =&gt; (n + o === n)).induction(\n        \u2115.refl(\u2115::Zero),\n        (n: \u2115, assumption: (n + o === n)) =&gt; {\n            inductionReduce(\n                n, n + o, assumption,\n                (n': \u2115) =&gt; (n'.succ === n.succ),\n                \u2115.refl(n.succ)\n            )\n        }\n    )\n}\n\ndef leibnizEq(f: \u2115 -&gt; \u2115): \u2200(a: \u2115) -&gt; \u2200(b: \u2115) -&gt; (a === b) -&gt; (f(a) === f(b)) = {\n    (a b : \u2115, eqab: (a === b)) =&gt; {\n        (P: \u2115 -&gt; 'Type, pfa: P(f a)) =&gt; eqab((b': \u2115) =&gt; P(f b'), pfa)\n    }\n}\n\ndef theoremPlusZeroInv: \u2200(n: \u2115) -&gt; (n === n + o) = {\n    (n: \u2115) =&gt; \u2115.symmetry(n + o, n, theoremPlusZero(n))\n}\n\ndef theoremPlusSucc: \u2200(a: \u2115) -&gt; \u2200(b: \u2115) -&gt; (succ(a + b) === a + b.succ) = {\n    (a b : \u2115) =&gt; induction(\n        (a': \u2115) =&gt; (succ(a' + b) === a' + b.succ),\n        \u2115.refl(succ(o + b)),\n        (a': \u2115, assumption: (succ(a' + b) === a' + b.succ)) =&gt; {\n            leibnizEq(succ, succ(a' + b), a' + b.succ, assumption)\n        }, a\n    )\n}\n\ndef transitivity(A: 'Type, a b c: A, eqab: A.Eq(a, b), eqbc: A.Eq(b, c)): A.Eq(a, c) = {\n    (P: A -&gt; 'Type, pa: P(a)) =&gt; eqbc(P, eqab(P, pa))\n}\n\ndef theoremPlusComm: \u2200(a: \u2115) -&gt; \u2200(b: \u2115) -&gt; (a + b === b + a) = {\n    (a: \u2115, b: \u2115) =&gt; induction(\n        (a': \u2115) =&gt; (a' + b === b + a'),\n        theoremPlusZeroInv b,\n        (a': \u2115, IH: (a' + b === b + a')) =&gt; {\n            let eq1 = \u2115.refl(succ(a' + b))                  // succ(a') + b === succ(a' + b)\n            let eq2 = leibnizEq(succ, a' + b, b + a', IH)   // succ(a' + b) === succ(b + a')\n            let eq3 = theoremPlusSucc(b, a')                // succ(b + a') === b + succ(a')\n            let eq4 = transitivity(\u2115, succ(a' + b), succ(b + a'), b + succ(a'), eq2, eq3)\n            transitivity(\u2115, succ(a') + b, succ(a' + b), b + succ(a'), eq1, eq4)\n        }, a\n    )\n}\n\neval \"\u2200(n: \u2115), n + 0 = n\"\neval theoremPlusZero\n\neval \"\"\n\neval \"\u2200(a b : \u2115), S(a + b) = a + S(b)\"\neval theoremPlusSucc\n\neval \"\"\n\neval \"\u2200(a b : \u2115), a + b = b + a\"\neval theoremPlusComm\n</code></pre> Run Type Checker"},{"location":"04-overloading/","title":"Ad-Hoc Polymorphism (Overloading)","text":"<p>In Saki, function overloading is introduced by leveraging a new type construct called the superposition type (\\(A \\oplus B\\)), which allows a single function to operate over multiple input types, providing different behaviors based on the types of arguments passed to the function. This generalizes traditional function overloading, often found in programming languages, into the type-theoretic framework of Martin-L\u00f6f Type Theory (MLTT). The superposition type formalizes this behavior, ensuring that function overloading is type-safe and rigorous, enabling polymorphism at the type level.</p>"},{"location":"04-overloading/#superposition-types","title":"Superposition Types","text":"<p>The superposition type \\(A \\oplus B\\) encapsulates the ability of a function to accept multiple types as input and return different types depending on the context of the application. Unlike a sum type (\\(A \\sqcup B\\)), which restricts a term to belong to either \\(A\\) or \\(B\\), the superposition type dynamically resolves the term\u2019s type based on the argument passed, making it applicable multiple times for different types.</p> <p>For example, if a function can handle both integer and string types, its type would be expressed as \\(Int \\oplus String\\), meaning that the function can accept either type, and the appropriate behavior will be applied based on the argument.</p>"},{"location":"04-overloading/#typing-rules-for-superposition-types","title":"Typing Rules for Superposition Types","text":"<p>The rules for superposition types enable the safe typing and application of overloaded functions in the type system. These rules are as follows:</p>"},{"location":"04-overloading/#term-typing-for-superposition-types","title":"Term Typing for Superposition Types","text":"\\[ \\frac{\\Gamma \\vdash t: A \\quad \\Delta \\vdash t: B}{\\Gamma, \\Delta \\vdash t: A \\oplus B} \\] <p>If a term \\(t\\) can be typed as both \\(A\\) in context \\(\\Gamma\\) and \\(B\\) in context \\(\\Delta\\), then \\(t\\) can be assigned the superposition type \\(A \\oplus B\\) in the combined context \\(\\Gamma, \\Delta\\). This allows the function to behave polymorphically, with its type determined by the argument.</p>"},{"location":"04-overloading/#function-overloading-with-superposition","title":"Function Overloading with Superposition","text":"\\[ \\frac{\\Gamma \\vdash t: A \\rightarrow B \\quad \\Delta \\vdash t: A \\rightarrow C}{\\Gamma, \\Delta \\vdash t: A \\rightarrow (B \\oplus C)} \\] <p>This rule allows a function to have multiple return types based on the context of its application. The function <code>t</code> can return either <code>B</code> in context \\(\\Gamma\\) or \\(C\\) in context \\(\\Delta\\), and the final type is resolved as \\(B \\oplus C\\) depending on the argument.</p>"},{"location":"04-overloading/#function-application-for-overloaded-functions","title":"Function Application for Overloaded Functions","text":"\\[ \\frac{\\Gamma \\vdash f: (A \\rightarrow B) \\oplus (C \\rightarrow D) \\quad \\Gamma \\vdash t: A}{\\Gamma \\vdash f\\ t: B} \\] <p>This rule governs the application of overloaded functions. If a function <code>f</code> has a superposition type \\((A \\rightarrow B) \\oplus (C \\rightarrow D)\\), applying it to an argument of type <code>A</code> resolves the function to return type <code>B</code>.</p>"},{"location":"04-overloading/#subtyping-for-superposition-types","title":"Subtyping for Superposition Types","text":"\\[ (A \\sqcap B) \\leq (A \\oplus B) \\] <p>The superposition type \\(A \\oplus B\\) is a subtype of the intersection type \\(A \\sqcap B\\). This rule comes from the property of an intersection type:</p> \\[ (A_1 \\to B_1) \\sqcap (A_2 \\to B_2) \\equiv (A_1 \\sqcup A_2) \\to (B_1 \\sqcap B_2) \\] <p>A superposition type \\((A_1 \\to B_1) \\sqcap (A_2 \\to B_2)\\) yields \\(B_1\\) when applied to \\(A_1\\) and \\(B_2\\) when applied to \\(A_2\\). The input type satisfies \\(A_1 \\geq A_1 \\sqcup A_2\\) and \\(A_2 \\geq A_1 \\sqcup A_2\\), and the output type satisfies \\(B_1 \\leq B_1 \\sqcap B_2\\) and \\(B_2 \\leq B_1 \\sqcap B_2\\). And because the covariance of the input type and the contravariance of the output type:</p> \\[ \\begin{align} \\begin{array}{c} \\Gamma \\vdash A_1 \\geq B_1 \\quad A_2 \\leq B_2 \\\\\\hline \\Gamma \\vdash A_1 \\rightarrow A_2 \\leq B_1 \\rightarrow B_2 \\end{array} \\end{align} \\] <p>Thus, the superposition type is considered as a subtype of the intersection type.</p>"},{"location":"04-overloading/#function-application-with-overloading","title":"Function Application with Overloading","text":"<p>When functions are overloaded via superposition types, the function's behavior is dependent on the type of the argument. The superposition type allows a function to operate on multiple types and dynamically resolve which version of the function to apply based on the argument\u2019s type.</p> <p>The typing rule for overloaded functions is:</p> \\[ \\frac{\\Gamma \\vdash f: (A \\rightarrow B) \\oplus (C \\rightarrow D) \\quad \\Gamma \\vdash t: A}{\\Gamma \\vdash f\\ t: B} \\] <p>This rule means that if: - <code>f</code> is an overloaded function with the type <code>(A \u2192 B) \u2295 (C \u2192 D)</code> in the context \\(\\Gamma\\), - and <code>t</code> is an argument of type <code>A</code>,</p> <p>then applying <code>f</code> to <code>t</code> will resolve the function to return a result of type <code>B</code>.</p>"},{"location":"04-overloading/#function-overloading-with-identical-return-types","title":"Function Overloading with Identical Return Types","text":"<p>Consider the following overloaded function <code>describe</code>, which can take either an integer or a string:</p> <pre><code>def describe(x: Int): String = \"The number is \" + x.toString\ndef describe(x: String): String = \"The string is \\\"\" + x + \"\\\"\"\n</code></pre> <p>The function <code>describe</code> has the following type:</p> \\[ \\text{describe}: (Int \\to String) \\oplus (String \\to String) \\] <p>Which is identical to</p> \\[ \\text{describe}: (Int \\oplus String) \\to String \\] <p>When applying <code>describe</code>, the behavior depends on the argument type:</p> <pre><code>def describe(x: Int): String = \"The number is \" ++ x.toString\ndef describe(x: String): String = \"The string is \\\"\" ++ x ++ \"\\\"\"\neval describe 114514     // Result: \"The number is 114514\"\neval describe \"Saki\"     // Result: \"The string is \"Saki\"\"\n</code></pre> Run Code <p>In this case:</p> <ul> <li>When applied to an integer (<code>42</code>), the function returns a description of the number.</li> <li>When applied to a string (<code>\"Saki\"</code>), the function returns a description of the string.</li> </ul>"},{"location":"04-overloading/#overloaded-function-with-different-return-types","title":"Overloaded Function with Different Return Types","text":"<p>Consider an overloaded function <code>concat</code> that operates on both numbers and strings, returning different types based on the argument type:</p> <pre><code>def ceilDec(x: Int): Int = if x == 0 then 1 else 10 * ceilDec(x / 10)\ndef concat(a: Int, b: Int): Int = a * ceilDec(b) + b\ndef concat(x: String, y: String): String = x ++ y\neval concat\n</code></pre> Run Code <p>The type of this function is:</p> \\[ \\text{concat}: (Int \\to Int \\to Int) \u2295 (String \\to String \\to String) \\] <p>Application:</p> <pre><code>def ceilDec(x: Int): Int = if x == 0 then 1 else 10 * ceilDec(x / 10)\ndef concat(a: Int, b: Int): Int = a * ceilDec(b) + b\ndef concat(x: String, y: String): String = x ++ y\n\neval concat(123, 456)               // Result: 123456\neval concat(\"It's \", \"mygo!!!!!\")   // Result: \"It's mygo!!!!!\"\n</code></pre> Run Code <p>Here, the overloaded function <code>concat</code>:</p> <ul> <li>Concatenates numbers when passed two integers using mathematical operations.</li> <li>Concatenates strings when passed two strings using built-in string concatenation.</li> </ul>"},{"location":"04-overloading/#currying-with-overloaded-functions","title":"Currying with Overloaded Functions","text":"<p>Due to the nature of superposition types, overloaded functions are curried as well like regular functions.  This allows for partial application and dynamic resolution of the function's behavior based on the arguments provided.</p> <p>Consider the following example:</p> <pre><code>def ceilDec(x: Int): Int = if x == 0 then 1 else 10 * ceilDec(x / 10)\ndef concat(a: Int, b: Int): Int = a * ceilDec(b) + b\ndef concat(x: String, y: String): String = x ++ y\n\neval concat 123\neval concat \"Hello! \"\n</code></pre> Run Code <p>Here, <code>concat</code> can be partially applied to an integer or string, with its final behavior determined by the type of the subsequent argument. Specifically, applying an overloaded lambda to an argument invokes a selection process based on the argument\u2019s type, identifying the corresponding function branch. This type-based selection mechanism is termed \"measurement\" of an overloaded lambda, analogous to quantum state measurement, where an indeterminate superposed state collapses into a definite outcome upon observation.</p>"},{"location":"04-overloading/#why-superposition-types","title":"Why Superposition Types?","text":"<p>Superposition types in Saki elegantly combine function overloading (ad-hoc polymorphism) with currying, overcoming challenges that typically arise when attempting to integrate these concepts in functional programming languages.</p> <p>In many functional programming languages, currying and function overloading can clash. Currying, which allows functions to be partially applied, introduces ambiguity when combined with overloading. For instance, in a curried function, the compiler may struggle to determine which version of an overloaded function to apply based on partial arguments, leading to errors.</p> <p>A typical example of this issue occurs in Scala, where the following code results in an ambiguous overload error:</p> <pre><code>def appendToString(s: String)(x: Int): String = s + x\ndef appendToString(s: String)(x: String): String = s + x\ndef test = appendToString(\"foo\")\n</code></pre> <p>In this case, the compiler cannot decide whether to apply <code>appendToString(\"foo\")(Int)</code> or <code>appendToString(\"foo\")(String)</code>, because both are valid overloads. The argument <code>\"foo\"</code> is a <code>String</code>, but it could be followed by either an <code>Int</code> or a <code>String</code>, causing ambiguity. However, Saki addresses this problem through superposition types. A superposition type, such as <code>A \u2295 B</code>, enables a function to handle multiple types dynamically and resolve overloading in a way that is both type-safe and flexible. When superposition types are used in conjunction with currying, the function can accept and handle different argument types across different stages of application without ambiguity. In Saki, the curried function <code>appendToString</code> would look like this:</p> <pre><code>def appendToString(s: String, x: Int): String = s ++ x.toString\ndef appendToString(s: String, x: String): String = s ++ x\neval appendToString \"foo\"\n</code></pre> Run Code <p>Here, the superposition type ensures that the function can adapt its behavior based on the next argument type\u2014whether it\u2019s an <code>Int</code> or a <code>String</code>. The type of the partial application <code>appendToString(\"foo\")</code> would be:</p> \\[ (Int \\to String) \\oplus (String \\to String) \\] <p>This means that Saki\u2019s type system can resolve the correct overload dynamically based on the second argument\u2019s type, thus avoiding the ambiguity.</p>"},{"location":"05-subtyping/","title":"Subtyping and Algebraic Subtyping","text":"<p>Subtyping is mathematically represented as a subset relation, \\( A \\subseteq B \\), such that \\( \\forall t \\in A, t \\in B \\). This interpretation allows subtyping to reflect a preorder relation, which becomes a partial order under equivalence (\\( A \\leq B \\land B \\leq A \\implies A = B \\)). The introduction of least upper bounds (lub, \\( A \\sqcup B \\)) and greatest lower bounds (glb, \\( A \\sqcap B \\)) converts this structure into a lattice. When combined with the universal top type (\\( \\top \\)) and bottom type (\\( \\bot \\)), the lattice becomes bounded, satisfying:</p> \\[ \\forall T, \\ T \\leq \\top \\quad \\text{and} \\quad  \\forall T, \\ \\bot \\leq T \\]"},{"location":"05-subtyping/#the-subsumption-rule","title":"The Subsumption Rule","text":"<p>In a type system with subtyping, a type \\( A \\) can be considered a subtype of another type \\( B \\) if \\( A \\) satisfies all the constraints and properties of \\( B \\), and possibly some additional ones. The subsumption rule formalizes this idea by allowing expressions of a more specific type to be treated as expressions of a more general type.</p> <p>The subsumption rule can be expressed as:</p> \\[ \\frac{A \\leq B \\quad \\Gamma \\vdash e : A}{\\Gamma \\vdash e : B} \\] <p>This means that if we have an expression \\( e \\) of type \\( A \\), and we know that \\( A \\) is a subtype of \\( B \\) (denoted \\( A \\leq B \\)), then we can treat \\( e \\) as an expression of type \\( B \\) without any further checks.</p>"},{"location":"05-subtyping/#basic-subtype-relationships","title":"Basic Subtype Relationships","text":""},{"location":"05-subtyping/#reflexivity-of-subtyping","title":"Reflexivity of Subtyping","text":"<p>Subtyping is reflexive, implying any type \\( T \\) is trivially a subtype of itself:</p> \\[ \\begin{align} \\begin{array}{c} \\\\\\hline T \\leq T \\end{array} \\end{align} \\] <p>This property is foundational to any preorder relation that subtyping models.</p>"},{"location":"05-subtyping/#transitivity-of-subtyping","title":"Transitivity of Subtyping","text":"<p>Transitivity guarantees consistency across multiple subtyping relations. If \\( T_1 \\leq T_2 \\) and \\( T_2 \\leq T_3 \\), then \\( T_1 \\leq T_3 \\). Formally:</p> \\[ \\begin{align} \\begin{array}{c} \\Gamma \\vdash T_1 \\leq T_2 \\quad \\Gamma \\vdash T_2 \\leq T_3 \\\\\\hline \\Gamma \\vdash T_1 \\leq T_3 \\end{array} \\end{align} \\]"},{"location":"05-subtyping/#functions","title":"Functions","text":"<p>The subtyping relation for function types follows contravariant behavior in the parameter type and covariant behavior in the return type:</p> \\[ \\begin{align} \\begin{array}{c} \\Gamma \\vdash A_1 \\geq B_1 \\quad A_2 \\leq B_2 \\\\\\hline \\Gamma \\vdash A_1 \\rightarrow A_2 \\leq B_1 \\rightarrow B_2 \\end{array} \\end{align} \\] <p>Here, \\( A_1 \\geq B_1 \\) indicates the parameter type \\( A_1 \\) is a supertype of \\( B_1 \\), while \\( A_2 \\leq B_2 \\) requires the return type \\( A_2 \\) to be a subtype of \\( B_2 \\).</p>"},{"location":"05-subtyping/#union-and-intersection-types","title":"Union and Intersection Types","text":""},{"location":"05-subtyping/#union-types","title":"Union Types","text":"<p>Union types, denoted \\( \\sqcup \\), allow combining types such that a value of the union type belongs to at least one constituent type:</p> \\[ \\begin{align} \\begin{array}{c} \\forall i \\,.\\, \\exists j \\,.\\, (\\Gamma \\vdash A_i \\leq B_j) \\\\\\hline \\Gamma \\vdash \\bigsqcup_i A_i \\leq \\bigsqcup_j B_j \\end{array} \\end{align} \\] <p>This expresses that the union of subtypes remains a subtype of the union of their respective supertypes.</p>"},{"location":"05-subtyping/#intersection-types","title":"Intersection Types","text":"<p>Intersection types, denoted \\( \\sqcap \\), describe a type that belongs simultaneously to multiple constituent types:</p> \\[ \\newcommand{\\bigsqcap}{\\mathop \u2a05} \\begin{align} \\begin{array}{c} \\Gamma \\vdash \\forall i \\,.\\, \\exists j \\,.\\, (A_i \\geq B_j) \\\\\\hline \\Gamma \\vdash \\bigsqcap_i A_i \\geq \\bigsqcap_j B_j \\end{array} \\end{align} \\] <p>The intersection of supertypes forms a supertype of the intersection of their respective subtypes.</p>"},{"location":"05-subtyping/#relationships","title":"Relationships","text":"<p>For function types, union and intersection obey distributive laws:</p> \\[ (A_1 \\to B_1) \\sqcap (A_2 \\to B_2) = (A_1 \\sqcup A_2) \\to (B_1 \\sqcap B_2) \\] <p>This states that the intersection of function types corresponds to the union of parameter types and the intersection of return types.</p> <p>For example:</p> <pre><code>(Int -&gt; String) &amp; (Float -&gt; Bool)\n</code></pre> Run Example <p>Similarly, the union of function types results from the intersection of parameter types and the union of return types.</p> \\[ (A_1 \\to B_1) \\sqcup (A_2 \\to B_2) = (A_1 \\sqcap A_2) \\to (B_1 \\sqcup B_2) \\] <p>For example:</p> <pre><code>(Int -&gt; String) | (Float -&gt; Bool)\n</code></pre> Run Example"},{"location":"05-subtyping/#records","title":"Records","text":"<p>Subtyping for record types aligns with structural subtyping, where records are compatible if they share the same fields and types. The typing rule for record types is:</p> \\[ \\begin{align} \\begin{array}{c} \\Gamma \\vdash \\overline{t_i : T_i}^i \\\\ \\hline \\Gamma \\vdash \\{ \\overline{l_i = t_i}^i \\} : \\{ \\overline{l_i : T_i}^i \\} \\end{array} \\end{align} \\] <p>Here, \\( \\overline{t_i : T_i}^i \\) denotes record fields, and field labels \\( l_i \\) and types \\( T_i \\) determine the record's type.</p> <p>Field access ensures type preservation:</p> \\[ \\begin{align} \\begin{array}{c} \\Gamma \\vdash t: \\{ \\overline{l_i : T_i}^i \\} \\\\\\hline \\Gamma \\vdash t.l_i : T_i \\end{array} \\end{align} \\] <p>Subtyping among records supports the subset relation:</p> \\[ \\begin{align} \\begin{array}{c} \\\\\\hline \\forall S \\,.\\, \\forall (S' \\subseteq S) \\,.\\, (\\{\\overline{l_i : T_i}^{i \\in S}\\} \\leq  \\{\\overline{l_i : T_i}^{i \\in S'}\\}) \\end{array} \\end{align} \\] <p>If fields \\( S' \\) are a subset of \\( S \\), then their respective record types exhibit a subtyping relationship.</p> <p>Pointwise subtyping applies across all fields in records:</p> \\[ \\begin{align} \\begin{array}{c} \\Gamma \\vdash \\forall i \\,.\\, (A_i \\leq B_i) \\\\\\hline \\Gamma \\vdash \\{\\overline{a_i : A_i}^i\\} \\leq \\{\\overline{b_i : B_i}^i\\} \\end{array} \\end{align} \\]"},{"location":"05-subtyping/#union-and-intersection-rules-for-record-types","title":"Union and Intersection Rules for Record Types","text":"<p>In algebraic subtyping, union (\\( \\sqcup \\)) and intersection (\\( \\sqcap \\)) types can also be extended to record types. These operations allow record subtyping to support partial and combined views of records, ensuring compatibility and flexibility in handling structured data.</p>"},{"location":"05-subtyping/#union-of-record-types","title":"Union of Record Types","text":"<p>The union of two record types combines their fields, allowing overlapping fields to resolve to the union of their respective types:</p> \\[ \\{\\overline{l_i : A_i}^{i \\in S}\\} \\sqcup \\{\\overline{l_i : B_i}^{i \\in T}\\} = \\{\\overline{l_i : A_i \\sqcup B_i}^{i \\in S \\cap T}, \\overline{l_j : A_j}^{j \\in S \\setminus T}, \\overline{l_k : B_k}^{k \\in T \\setminus S}\\} \\] <ul> <li>For shared fields \\( l_i \\in S \\cap T \\), the resulting type is the union of their individual types \\( A_i \\sqcup B_i \\).</li> <li>For fields exclusive to one record (e.g., \\( l_j \\in S \\setminus T \\) or \\( l_k \\in T \\setminus S \\)), their types remain unchanged.</li> </ul> <p>For example:</p> <pre><code>(record { a: Int; b: String }) | (record { b: Float; c: Bool })\n</code></pre> Run Example"},{"location":"05-subtyping/#intersection-of-record-types","title":"Intersection of Record Types","text":"<p>The intersection of two record types combines their fields similarly, but overlapping fields resolve to the intersection of their types:</p> \\[ \\{\\overline{l_i : A_i}^{i \\in S}\\} \\sqcap \\{\\overline{l_i : B_i}^{i \\in T}\\} = \\{\\overline{l_i : A_i \\sqcap B_i}^{i \\in S \\cap T}\\} \\] <ul> <li>Only fields common to both records (\\( l_i \\in S \\cap T \\)) are preserved in the resulting record.</li> <li>For shared fields, the resulting type is the intersection of their individual types \\( A_i \\sqcap B_i \\).</li> <li>Fields exclusive to one record are excluded from the intersection.</li> </ul> <p>For example:</p> <pre><code>(record { a: Int; b: String }) &amp; (record { b: String; c: Bool })\n</code></pre> Run Example"},{"location":"05-subtyping/#subtyping-for-recursive-type","title":"Subtyping for Recursive Type","text":"\\[ \\frac{ \\Gamma \\vdash T : \\mathcal{U} \\quad \\Gamma, x : T \\vdash \\sigma \\leq T }{ \\Gamma \\vdash \\mu (x : T) . \\sigma \\leq T } \\]"},{"location":"05-subtyping/#dependent-types","title":"Dependent Types","text":"<p>Dependent types extend the expressive power of type systems by allowing types to depend on values or other types. Algebraic subtyping supports dependent types, incorporating union and intersection constructs to define relationships between dependent types effectively.</p>"},{"location":"05-subtyping/#subtyping-relationships","title":"Subtyping Relationships","text":""},{"location":"05-subtyping/#dependent-pi-type","title":"Dependent \\(\\Pi\\)-Type","text":"<p>The dependent \\(\\Pi\\)-type rule for subtyping is given by:</p> \\[ \\frac{ \\Gamma \\vdash A_2 \\leq A_1 \\quad \\Gamma, x:A_1 \\vdash B_1(x) \\quad \\Gamma, x:A_2 \\vdash B_1(x) \\leq B_2(x) }{ \\Gamma \\vdash \\Pi(x:A_1). B_1(x) \\leq \\Pi(x:A_2). B_2(x) } \\]"},{"location":"05-subtyping/#dependent-sigma-type","title":"Dependent \\(\\Sigma\\)-Type","text":"<p>The dependent \\(\\Sigma\\)-type rule for subtyping is given by:</p> \\[ \\frac{ \\Gamma \\vdash A_1 \\leq A_2 \\quad \\Gamma, x:A_1 \\vdash B_1(x) \\leq B_2(x) }{ \\Gamma \\vdash \\Sigma(x:A_1). B_1(x) \\leq \\Sigma(x:A_2). B_2(x) } \\]"},{"location":"05-subtyping/#intersection-of-dependent-pi-types","title":"Intersection of Dependent \\( \\Pi \\)-Types","text":""},{"location":"05-subtyping/#type-formation-rule-for-intersection-of-dependent-pi-types","title":"Type Formation Rule for Intersection of Dependent \\( \\Pi \\)-Types","text":"<p>Dependent \\( \\Pi \\)-types are function-like types where the codomain depends on the specific value of the domain. For the intersection of such types:</p> \\[ \\frac{ \\Gamma \\vdash A_1 : \\mathcal{U} \\quad \\Gamma \\vdash A_2 : \\mathcal{U} \\quad \\Gamma, x:A_1 \\vdash B_1(x) : \\mathcal{U} \\quad \\Gamma, x:A_2 \\vdash B_2(x) : \\mathcal{U} }{ \\Gamma \\vdash \\Pi(x:A_1). B_1(x) \\cap \\Pi(x:A_2). B_2(x) : \\mathcal{U} } \\] <p>Refinement ensures that \\( x \\) must be in both \\( A_1 \\) and \\( A_2 \\), producing:</p> \\[ \\frac{ \\Gamma \\vdash A = A_1 \\cap A_2 : \\mathcal{U} \\quad \\Gamma, x:A \\vdash B(x) = B_1(x) \\cap B_2(x) : \\mathcal{U} }{ \\Gamma \\vdash \\Pi(x:A). B(x) : \\mathcal{U} } \\]"},{"location":"05-subtyping/#type-formation-rule-for-intersection-of-dependent-sigma-types","title":"Type Formation Rule for Intersection of Dependent \\( \\Sigma \\)-Types","text":"<p>Dependent \\( \\Sigma \\)-types represent dependent pairs, where the type of the second component depends on the value of the first. The intersection of such types is defined as:</p> \\[ \\frac{ \\Gamma \\vdash A_1 : \\mathcal{U} \\quad \\Gamma \\vdash A_2 : \\mathcal{U} \\quad \\Gamma, x:A_1 \\vdash B_1(x) : \\mathcal{U} \\quad \\Gamma, x:A_2 \\vdash B_2(x) : \\mathcal{U} }{ \\Gamma \\vdash \\Sigma(x:A_1). B_1(x) \\cap \\Sigma(x:A_2). B_2(x) : \\mathcal{U} } \\]"},{"location":"05-subtyping/#union-of-dependent-pi-types","title":"Union of Dependent \\( \\Pi \\)-Types","text":""},{"location":"05-subtyping/#type-formation-rule-for-union-of-dependent-pi-types","title":"Type Formation Rule for Union of Dependent \\( \\Pi \\)-Types","text":"<p>The union of dependent \\( \\Pi \\)-types combines the domains and codomains of the respective types:</p> \\[ \\frac{ \\Gamma \\vdash A_1 : \\mathcal{U} \\quad \\Gamma \\vdash A_2 : \\mathcal{U} \\quad \\Gamma, x:A_1 \\vdash B_1(x) : \\mathcal{U} \\quad \\Gamma, x:A_2 \\vdash B_2(x) : \\mathcal{U} }{ \\Gamma \\vdash \\Pi(x:A_1). B_1(x) \\cup \\Pi(x:A_2). B_2(x) : \\mathcal{U} } \\]"},{"location":"05-subtyping/#type-formation-rule-for-union-of-dependent-sigma-types","title":"Type Formation Rule for Union of Dependent \\( \\Sigma \\)-Types","text":"<p>The union of dependent \\( \\Sigma \\)-types combines the types of the first and second components:</p> \\[ \\frac{ \\Gamma \\vdash A_1 : \\mathcal{U} \\quad \\Gamma \\vdash A_2 : \\mathcal{U} \\quad \\Gamma, x:A_1 \\vdash B_1(x) : \\mathcal{U} \\quad \\Gamma, x:A_2 \\vdash B_2(x) : \\mathcal{U} }{ \\Gamma \\vdash \\Sigma(x:A_1). B_1(x) \\cup \\Sigma(x:A_2). B_2(x) : \\mathcal{U} } \\]"},{"location":"Definition/","title":"Definition","text":"<p>In Saki, a definition is used to introduce named functions, constants, or operators within the type system. Definitions allow for explicit type annotations, parameter bindings, and a function body. The definition syntax is designed to handle explicit and implicit parameter lists, allowing for greater flexibility when defining generic, polymorphic functions.</p>"},{"location":"Definition/#syntax-of-definitions","title":"Syntax of Definitions","text":"<p>The syntax for defining functions or operators in Saki is structured as follows:</p> <pre><code>ParamBindings ::= Ident+ ':' Term\nParamList     ::= ParamBindings (',' ParamBindings)*\nDefinition    ::= 'def' (Ident|OpIdent) ('[' ParamList ']')? ('(' ParamList ')')? '=' Term\n</code></pre> <ul> <li>ParamBindings: Defines one or more parameters, where <code>Ident+</code> represents one or more parameter identifiers, and <code>Term</code> represents the type of the parameters.</li> <li>ParamList: A list of ParamBindings, separated by commas.</li> <li>Definition: Starts with the <code>def</code> keyword, followed by the function name (or operator), and can optionally include:</li> <li>Implicit Parameters in square brackets (<code>[ParamList]</code>), typically used for type-level parameters or constraints.</li> <li>Explicit Parameters in parentheses (<code>(ParamList)</code>), representing the values passed to the function.</li> <li>The function body, which is the expression on the right-hand side of the <code>=</code> symbol that defines the behavior of the function.</li> </ul>"},{"location":"Definition/#components-of-definitions","title":"Components of Definitions","text":"<ol> <li> <p>Identifier: The name of the function, constant, or operator. This can be a regular identifier or an operator (denoted as <code>OpIdent</code>).</p> </li> <li> <p>Implicit Parameters: Parameters in square brackets (<code>[ ]</code>) are implicit, meaning they are typically inferred by the compiler during function application. These parameters are often used for type parameters or contract constraints. In Saki, these parameters are generally related to the type system and are inferred based on the arguments passed to the function.</p> </li> <li> <p>Explicit Parameters: Parameters in parentheses (<code>( )</code>) are explicit, meaning they must be provided by the caller. These are the values or expressions passed to the function when it is invoked.</p> </li> <li> <p>Return Type: The return type is specified after the parameter list and before the function body, indicating the type of the value returned by the function.</p> </li> <li> <p>Function Body: The expression or series of expressions that define the actual behavior of the function.</p> </li> </ol>"},{"location":"Definition/#typical-example-of-a-function-definition","title":"Typical Example of a Function Definition","text":"<p>Consider a simple definition for a <code>map</code> function that operates on a list:</p> <pre><code>def map[A: 'Type](list: List[A], transform: A -&gt; A): List[A] = ...\n</code></pre> <ul> <li><code>map</code> is the function name.</li> <li><code>[A: 'Type]</code> is the implicit parameter list:</li> <li><code>A</code> is a type parameter, constrained by <code>'Type</code>, meaning it can be any type in the universe of types.</li> <li>The compiler infers the type <code>A</code> based on the type of the list passed to the function.</li> <li><code>(list: List[A], transform: A -&gt; A)</code> is the explicit parameter list:</li> <li><code>list</code> is a list of elements of type <code>A</code>.</li> <li><code>transform</code> is a function that takes a value of type <code>A</code> and returns a new value of type <code>A</code>.</li> <li><code>List[A]</code> is the return type, indicating that the function returns a list of elements of type <code>A</code>.</li> <li><code>...</code> represents the function body, which defines how the elements of the list are transformed by the <code>transform</code> function.</li> </ul>"},{"location":"Definition/#implicit-and-explicit-parameters","title":"Implicit and Explicit Parameters","text":"<p>In Saki, functions often have both implicit and explicit parameters. Implicit parameters allow for generic and polymorphic functions without needing to specify the type each time the function is called.</p> <p>For example:</p> <pre><code>def identity[A: 'Type](x: A): A = x\n</code></pre> <ul> <li>The function <code>identity</code> takes a single value <code>x</code> of type <code>A</code> and returns <code>x</code>.</li> <li>The type <code>A</code> is inferred from the argument passed to <code>identity</code>, so the user doesn't need to explicitly provide <code>A</code> when calling the function.</li> </ul>"},{"location":"Definition/#type-constraints-in-definitions","title":"Type Constraints in Definitions","text":"<p>In Saki, contract universes can be used to impose constraints on the types of the parameters. For example, consider the following function that requires the type <code>A</code> to satisfy the <code>'Add</code> contract (i.e., it must support an <code>add</code> operation):</p> <pre><code>def sum[A: 'Add](x: A, y: A): A = x.add(y)\n</code></pre> <ul> <li>The function <code>sum</code> takes two values <code>x</code> and <code>y</code> of type <code>A</code>.</li> <li>The type <code>A</code> is constrained by the contract <code>'Add</code>, meaning that <code>A</code> must implement the <code>add</code> method.</li> <li>The function returns the result of adding <code>x</code> and <code>y</code> using <code>A</code>'s <code>add</code> method.</li> </ul>"},{"location":"Definition/#operator-definitions","title":"Operator Definitions","text":"<p>Operators can be defined similarly to functions, using the same syntax. For example, a custom addition operator could be defined as follows:</p> <pre><code>def (+)[A: 'Add](x: A, y: A): A = x.add(y)\n</code></pre> <ul> <li>The operator <code>+</code> is defined for any type <code>A</code> that satisfies the <code>'Add</code> contract.</li> <li>This allows users to use <code>+</code> in the same way they would for built-in numeric types, but it applies to any type that defines an <code>add</code> method.</li> </ul>"},{"location":"Definition/#higher-level-universe-in-definition","title":"Higher-Level Universe in Definition","text":"<p>Consider a function that multiplies a value by itself, where the type <code>A</code> is constrained by the <code>'Mul</code> contract universe:</p> <pre><code>def square[R: 'Type, A: 'Mul(A, R)](self: A): R = self.mul(self)\n</code></pre> <ul> <li><code>square</code> is the function name.</li> <li><code>[R: 'Type, A: 'Mul(A, R)]</code> are implicit parameters:</li> <li><code>R</code> is a type, and <code>A</code> is a type constrained by the <code>'Mul(A, R)</code> contract, meaning that <code>A</code> must implement a <code>mul</code> method that returns a value of type <code>R</code>.</li> <li><code>(self: A)</code> is the explicit parameter.</li> <li>The return type is <code>R</code>, the result of multiplying <code>self</code> by itself using the <code>mul</code> method.</li> </ul> <p>This function is generic across any type <code>A</code> that supports multiplication, allowing it to work with numbers, matrices, or any other type that implements the <code>'Mul</code> contract.</p>"},{"location":"Definition/01-decorator/","title":"Decorator","text":"<p>Warning</p> <p>This feature is not yet implemented or not fully supported in the current version of Saki interpreter/REPL.</p> <p>A decorator in Saki is a higher-order function that takes another function as its argument and returns a new function with the same type signature. Decorators allow for the dynamic augmentation of functions with additional functionality, enhancing the behavior of the original function without modifying its core logic. In essence, a decorator has the type:</p> \\[ (T \\rightarrow R) \\rightarrow (T \\rightarrow R) \\] <p>This means it takes a function of type <code>T -&gt; R</code> and returns a function of the same type.</p> <p>Decorators in Saki can be applied directly to functions using a specific syntax. They enable modular code, where functionality can be extended in a reusable and composable manner.</p>"},{"location":"Definition/01-decorator/#syntax","title":"Syntax","text":"<p>The syntax for applying one or more decorators to a function is as follows:</p> <pre><code>DecoratorApply ::= '#' '[' Term (',' Term)* ']'\n</code></pre> <p>The general form for applying decorators looks like this:</p> <pre><code>#[dec1, dec2, ..., decN]\ndef func: T -&gt; R\n</code></pre> <ul> <li><code>#[dec1, dec2, ..., decN]</code>: Decorators are applied using a <code>#</code> followed by a list of decorators enclosed in square brackets. These decorators are applied to the function that follows.</li> </ul>"},{"location":"Definition/01-decorator/#typing-rules","title":"Typing Rules","text":"<p>Decorators must preserve the type signature of the functions they are applied to. If a function <code>func</code> has type <code>T -&gt; R</code>, and a decorator <code>dec</code> transforms it while maintaining the same type, the resulting decorated function also has type <code>T -&gt; R</code>. The typing rule can be formalized as:</p> \\[ \\frac{\\Gamma \\vdash func : T \\rightarrow R \\quad \\Gamma \\vdash dec : (T \\rightarrow R) \\rightarrow (T \\rightarrow R)}{\\Gamma \\vdash dec(func) : T \\rightarrow R} \\] <p>This ensures that the decorator takes in a function of type <code>T -&gt; R</code> and returns a function with the same signature.</p>"},{"location":"Definition/01-decorator/#examples","title":"Examples","text":""},{"location":"Definition/01-decorator/#ensuring-positive-input-values","title":"Ensuring Positive Input Values","text":"<p>Consider a decorator that ensures that a function only operates on positive input values. This decorator checks if the input is greater than 0 and only calls the original function if the condition is satisfied. Otherwise, it returns <code>None</code>.</p> <pre><code>universe GreaterThan(T: 'Type) = contract {\n    require (&gt;)(self, other: T): Bool\n}\n\ndef ensurePositive[T: 'GreaterThan(\u2115)](func: T -&gt; Option[T]): T -&gt; Option[T] = {\n    return |arg: T|: Option[T] =&gt; if arg &gt; 0 then func(arg) else None\n}\n\n#[ensurePositive]\ndef safeDivide(x: \u2115): Option[\u2115] = if x != 0 then Some(10 / x) else None\n</code></pre> <ul> <li><code>ensurePositive</code>: The decorator checks if the input is greater than 0. If true, it calls the original function; otherwise, it returns <code>None</code>.</li> <li><code>safeDivide</code>: This function divides 10 by the input value, but using the decorator, it is guaranteed to only operate on positive integers. If the input is 0 or negative, it returns <code>None</code>.</li> </ul>"},{"location":"Definition/01-decorator/#transforming-input-before-applying-a-function","title":"Transforming Input Before Applying a Function","text":"<p>The following example demonstrates how a decorator can be used to modify the input before passing it to the original function.</p> <pre><code>def mapInput[T1 T2 R: 'Type](transform: T1 -&gt; T2, func: T2 -&gt; R): T1 -&gt; R = {\n    return |arg: T1|: R =&gt; func(transform(arg))\n}\n\n#[mapInput(|x: \u2115| =&gt; x * 2)]\ndef half(n: \u2115): \u2115 = n / 2\n</code></pre> <ul> <li><code>mapInput</code>: This decorator takes a transformation function and applies it to the input before passing it to the original function.</li> <li><code>half</code>: This function divides the input by 2, but with the decorator applied, the input is first doubled, so <code>half(5)</code> would return the result of <code>10 / 2</code>, which is <code>5</code>.</li> </ul>"},{"location":"Definition/01-decorator/#transforming-the-output-of-a-function","title":"Transforming the Output of a Function","text":"<p>A decorator can also be used to modify the output of a function. In the following example, the decorator multiplies the function's result by 10.</p> <pre><code>def mapOutput[T R1 R2: 'Type](func: T -&gt; R1, transform: R1 -&gt; R2): T -&gt; R2 = {\n    return |arg: T|: R2 =&gt; transform(func(arg))\n}\n\n#[mapOutput(|x: \u2115| =&gt; x * 10)]\ndef increment(n: \u2115): \u2115 = n + 1\n</code></pre> <ul> <li><code>mapOutput</code>: This decorator takes a transformation function and applies it to the output of the original function.</li> <li><code>increment</code>: This function adds 1 to the input, but with the decorator, the result is multiplied by 10. So, <code>increment(5)</code> results in <code>60</code>, as <code>(5 + 1) * 10 = 60</code>.</li> </ul>"},{"location":"Definition/01-decorator/#composition-of-decorators","title":"Composition of Decorators","text":"<p>Decorators in Saki can be composed. Multiple decorators can be applied to the same function in sequence. This means that each decorator applies its transformation on the function that results from the previous decorator.</p> <p>For example:</p> <pre><code>#[ensurePositive, mapOutput(|x: \u2115| =&gt; x * 10)]\ndef safeDivideAndScale(x: \u2115): Option[\u2115] = if x != 0 then Some(10 / x) else None\n</code></pre> <p>In this case: - <code>ensurePositive</code> ensures that the function only operates on positive inputs. - <code>mapOutput</code> scales the result of the function by 10.</p> <p>If the input to <code>safeDivideAndScale</code> is <code>2</code>, the function returns <code>Some(50)</code> (since <code>10 / 2 = 5</code> and <code>5 * 10 = 50</code>). If the input is <code>0</code>, the function returns <code>None</code> due to <code>ensurePositive</code>.</p>"},{"location":"Definition/01-decorator/#contract-universes-and-decorators","title":"Contract Universes and Decorators","text":"<p>In Saki, decorators can leverage contract universes to enforce behavior through constraints. For example, decorators like <code>ensurePositive</code> can depend on contract universes such as <code>'GreaterThan</code>, ensuring that the function operates only on types that support comparison.</p> <pre><code>universe GreaterThan(T: 'Type) = contract {\n    require (&gt;)(self, other: T): Bool\n}\n\ndef ensurePositive[T: 'GreaterThan(\u2115)](func: T -&gt; Option[T]): T -&gt; Option[T] = {\n    return |arg: T|: Option[T] =&gt; if arg &gt; 0 then func(arg) else None\n}\n</code></pre> <p>In this example, the decorator relies on the contract universe <code>'GreaterThan</code>, ensuring that the input type supports the <code>&gt;</code> operator. This enforces additional type safety by ensuring that only types adhering to this contract can use the decorator.</p>"},{"location":"Terms/","title":"Terms","text":""},{"location":"Terms/#basic-subtype-relationship","title":"Basic Subtype Relationship","text":"<p>In type theory, subtyping formalizes a notion of substitutability between types, where a term of one type can be used in any context where a term of another (super)type is expected. The subtyping relation, written as \\(T_1 &lt;: T_2\\), expresses that type \\(T_1\\) is a subtype of \\(T_2\\), meaning that every term of type \\(T_1\\) can be safely used where a term of type \\(T_2\\) is required.</p>"},{"location":"Terms/#reflexivity-of-subtyping","title":"Reflexivity of Subtyping","text":"<p>The first rule expresses the reflexivity of subtyping: $$ T &lt;: T $$ This states that any type \\(T\\) is trivially a subtype of itself. Reflexivity is a foundational property ensuring that a type can always be substituted for itself.</p>"},{"location":"Terms/#transitivity-of-subtyping","title":"Transitivity of Subtyping","text":"<p>The second rule describes the transitivity of the subtyping relation: $$ \\frac{\\Gamma \\vdash T_1 &lt;: T_2 \\quad \\Gamma \\vdash T_2 &lt;: T_3}{\\Gamma \\vdash T_1 &lt;: T_3} $$ In words, if \\(T_1\\) is a subtype of \\(T_2\\) and \\(T_2\\) is a subtype of \\(T_3\\), then \\(T_1\\) is also a subtype of \\(T_3\\). </p>"},{"location":"Terms/#primitive-terms","title":"Primitive Terms","text":"Name Type Super Type Set Representation Nothing (Bottom) <code>Nothing</code> - \\(\\emptyset\\) Unit (Top) <code>Unit</code> - \\(\\{e\\}\\) Boolean <code>Bool</code> / <code>\ud835\udd39</code> - \\(\\mathbb{B}\\) Byte <code>Byte</code> - \\(\\{x \\mid [0, 255] \\cup \\mathbb{N} \\}\\) Natural Number <code>Nat</code> / <code>\u2115</code> - \\(\\mathbb{N}\\) Integer <code>Int</code> / <code>\u2124</code> <code>Nat</code> \\(\\mathbb{Z}\\) Real Number <code>Float</code> / <code>\u211d</code> <code>Nat</code>, <code>Int</code> \\(\\mathbb{R}\\) Complex Number <code>Complex</code> / <code>\u2102</code> <code>Nat</code>, <code>Int</code>, <code>Real</code> \\(\\mathbb{C}\\) Char <code>Char</code> - \\(U\\) (Unicode characters) String <code>String</code> - \\(\\{ s \\in U^* \\mid s = c_1c_2\\dots c_n, \\, n \\in \\mathbb{N}\\}\\)"},{"location":"Terms/01-lambda/","title":"Function (Lambda)","text":""},{"location":"Terms/01-lambda/#lambda-expressions","title":"Lambda Expressions","text":"<p>Lambda expressions in Saki serve as anonymous functions, allowing computations to be defined concisely and utilized without requiring a named identifier. These expressions are automatically curried, meaning that a function expecting multiple parameters is interpreted as a sequence of unary functions, each taking a single argument and returning a new function. This implicit currying supports partial application, a powerful feature in functional programming.</p>"},{"location":"Terms/01-lambda/#syntax-of-lambda-expressions","title":"Syntax of Lambda Expressions","text":"<p>Lambda expressions in Saki are defined using a specific syntax to ensure type safety and expressiveness. The core syntax is as follows:</p> <pre><code>ParamBinding    ::= \u2018self\u2019 \n                  | Ident+ \u2018:\u2019 Term\nParamList       ::= ParamBinding (\u2018,\u2019 ParamBinding)*\nFuncTerm        ::= \u2018(\u2019 ParamList \u2018)\u2019 \u2018=&gt;\u2019 Term\n</code></pre> <ul> <li> <p><code>ParamBinding</code>: Represents each parameter in a function, specifying the parameter name (<code>Ident</code>) and its type (<code>Term</code>). In Saki, <code>self</code> is a special keyword used to refer to the current instance, commonly in implementation contexts (e.g., in classes or modules).</p> </li> <li> <p><code>ParamList</code>: A list of <code>ParamBinding</code>s separated by commas, enclosed in a pair of parentheses. This structure defines the parameters accepted by the lambda function.</p> </li> <li> <p><code>FuncTerm</code>: Specifies the function body following the <code>=&gt;</code> symbol. This term represents the operation applied to the parameters provided in <code>ParamList</code>.</p> </li> </ul>"},{"location":"Terms/01-lambda/#syntax-of-lambda-types","title":"Syntax of Lambda Types","text":"<p>The syntax of function types in Saki follows the common notation used in functional programming and type theory. A function type is composed of a domain and codomain, separated by an arrow (<code>-&gt;</code>). Formally, this is expressed as:</p> <pre><code>FuncType    ::= Term \"-&gt;\" Term\n</code></pre> <p>Here, <code>A -&gt; B</code> represents the type of a function that takes an argument of the first type (<code>A</code>) and returns a value of the second type (<code>B</code>). This notation generalizes higher-order functions, where both the input and output can themselves be functions, and extends naturally to the lambda calculus formulation of functions.</p>"},{"location":"Terms/01-lambda/#typing-rules","title":"Typing Rules","text":"<p>The basic typing rule for functions follows from the lambda calculus. For a function term \\(\\lambda (x: T_1) . t\\) that takes an argument \\(x\\) of type \\(T_1\\) and returns a result \\(t\\) of type \\(T_2\\), the corresponding typing rule is: $$ \\frac{\\Gamma, x: T_1 \\vdash t: T_2}{\\Gamma \\vdash \\lambda (x: T_1) \\,.\\, t : T_1 \\rightarrow T_2} $$</p> <p>This states that: Given a context \\(\\Gamma\\) and assuming that \\(x\\) is a variable of type \\(T_1\\), if the term \\(t\\) has type \\(T_2\\), then the lambda abstraction \\(\\lambda (x: T_1) . t\\) (a function taking \\(x\\) as an argument) has the type \\(T_1 \\rightarrow T_2\\).</p>"},{"location":"Terms/01-lambda/#subtyping-relationship","title":"Subtyping Relationship","text":"<p>Subtyping in function types adheres to the principles of contravariance for the argument types and covariance for the return types. This is formally captured by the subtyping rule for function types: $$ \\frac{\\Gamma \\vdash A_1 &gt;: B_1 \\quad A_2 &lt;: B_2}{\\Gamma \\vdash A_1 \\rightarrow A_2 &lt;: B_1 \\rightarrow B_2} $$</p> <ul> <li>Contravariance in the argument: If \\(A_1\\) is a supertype of \\(B_1\\) (\\(A_1 &gt;: B_1\\)), then we can safely replace \\(B_1\\) with \\(A_1\\) in the function's input position, meaning that \\(A_1 \\rightarrow A_2\\) is a subtype of \\(B_1 \\rightarrow A_2\\).</li> <li>Covariance in the return: If \\(A_2\\) is a subtype of \\(B_2\\) (\\(A_2 &lt;: B_2\\)), then the result type can safely be replaced with a more general type, preserving the function's output.</li> </ul>"},{"location":"Terms/01-lambda/#basic-lambda-expression","title":"Basic Lambda Expression","text":"<p>A lambda function that increments an integer by 1 is defined as:</p> <pre><code>(x: \u2124): \u2124 =&gt; x + 1\n</code></pre> <p>Here, <code>x</code> is the integer parameter, and the function returns the result of <code>x + 1</code>. The type of this function is: $$ \\text{\u2124} \\rightarrow \\text{\u2124} $$</p>"},{"location":"Terms/01-lambda/#lambda-expression-with-block-syntax","title":"Lambda Expression with Block Syntax","text":"<p>Block syntax is supported to handle more complex operations within the function body. For example:</p> <pre><code>(x: \u2124): \u2124 =&gt; { x + 1 }\n</code></pre> <p>This expression performs the same operation as the previous one but includes braces (<code>{}</code>), allowing more complex logic within the lambda.</p>"},{"location":"Terms/01-lambda/#multiple-parameters","title":"Multiple Parameters","text":"<p>Lambda expressions in Saki can take multiple parameters, illustrated as follows:</p> <pre><code>(x y: \u2124): \u2124 =&gt; x + y\n</code></pre> <p>This lambda expression takes two integers, <code>x</code> and <code>y</code>, and returns their sum. The type of this lambda expression is: $$ \\text{\u2124} \\rightarrow \\text{\u2124} \\rightarrow \\text{\u2124} $$</p> <p>Since functions are curried in Saki, this means the lambda takes an argument of type <code>\u2124</code> and returns a new function that also takes an argument of type <code>\u2124</code> and returns an <code>\u2124</code>. Curried functions enable partial application, meaning that this function can be applied to one argument at a time.</p>"},{"location":"Terms/01-lambda/#lambda-as-an-argument","title":"Lambda as an Argument","text":"<p>Suppose we have the following definitions:</p> <pre><code>type List[T: 'Type] = inductive {\n    Nil\n    Cons(T, List[T])\n}\n\ndef map(transform: \u2124 -&gt; \u2124, list: List[\u2124]): List[\u2124] = match list {\n    case List[\u2124]::Nil =&gt; List[\u2124]::Nil\n    case List[\u2124]::Cons(head, tail) =&gt; List[\u2124]::Cons(transform head, map transform tail)\n}\n</code></pre> <p>This <code>map</code> function applies a transformation to each element of a list of integers. The type of <code>map</code> is: $$ (\\text{\u2124} \\rightarrow \\text{\u2124}) \\rightarrow \\text{List}[\\text{\u2124}] \\rightarrow \\text{List}[\\text{\u2124}] $$</p> <p>Since functions are curried, <code>map</code> can take a single argument (the transformation function of type <code>\u2124 -&gt; \u2124</code>) and return another function that expects a list of integers (<code>List[\u2124]</code>) and returns a transformed list (<code>List[\u2124]</code>).</p> <p>An example of using <code>map</code> with a lambda expression:</p> <pre><code>type List[T: 'Type] = inductive {\n    Nil\n    Cons(T, List[T])\n}\n\ndef map(transform: \u2124 -&gt; \u2124, list: List[\u2124]): List[\u2124] = match list {\n    case List[\u2124]::Nil =&gt; List[\u2124]::Nil\n    case List[\u2124]::Cons(head, tail) =&gt; List[\u2124]::Cons(transform head, map transform tail)\n}\n\neval {\n    let list = List[\u2124]::Cons(1, List[\u2124]::Cons(2, List[\u2124]::Cons(3, List[\u2124]::Nil)))\n    map ((x: \u2124) =&gt; x + 1) list\n}\n</code></pre> Run Example <p>Here, the lambda <code>(x: \u2124) =&gt; x + 1</code> is passed as the <code>transform</code> argument. The type of the lambda is <code>\u2124 -&gt; \u2124</code>, and the application of <code>map</code> returns a new function that accepts a <code>List[\u2124]</code> and returns a transformed <code>List[\u2124]</code>.</p> <p>In addition, the return type of the lambda expression is not nessessarily to be identical to the argument type.  Consider a <code>filter</code> function that takes a list and a predicate (a function that returns a boolean), returning a list of elements that satisfy the predicate:</p> <pre><code>def filter(list: List[\u2124], predicate: \u2124 -&gt; Bool): List[\u2124] = match list {\n    case List[\u2124]::Nil =&gt; List[\u2124]::Nil\n    case List[\u2124]::Cons(head, tail) =&gt; {\n        if predicate head then {\n            List[\u2124]::Cons(head, tail.filter(predicate))\n        } else {\n            tail.filter(predicate) \n        }\n    }\n}\n</code></pre> <p>The type of <code>filter</code> is: $$ \\text{List}[\\text{\u2124}] \\rightarrow (\\text{\ud835\udd39} \\rightarrow \\text{\u2124}) \\rightarrow \\text{List}[\\text{\u2124}] $$</p> <p>To use <code>filter</code>, we can pass a lambda to filter out negative numbers:</p> <pre><code>type List[T: 'Type] = inductive {\n    Nil\n    Cons(T, List[T])\n}\n\ndef filter(list: List[\u2124], predicate: \u2124 -&gt; Bool): List[\u2124] = match list {\n    case List[\u2124]::Nil =&gt; List[\u2124]::Nil\n    case List[\u2124]::Cons(head, tail) =&gt; {\n        if predicate head then {\n            List[\u2124]::Cons(head, tail.filter(predicate))\n        } else {\n            tail.filter(predicate) \n        }\n    }\n}\n\neval {\n    let list = List[\u2124]::Cons(-1, List[\u2124]::Cons(2, List[\u2124]::Cons(-3, List[\u2124]::Nil)))\n    list.filter((x: \u2124) =&gt; x &gt; 0) \n}\n</code></pre> Run Example <p>The lambda <code>(x: \u2124) =&gt; x &gt; 0</code> has the type <code>\u2124 -&gt; Bool</code>, and the result of <code>filter</code> will be a new list containing only the positive integers from the original <code>list</code>.</p>"},{"location":"Terms/01-lambda/#partial-application-of-curried-functions","title":"Partial Application of Curried Functions","text":"<p>Due to currying, functions in Saki can be partially applied. For example:</p> <pre><code>type List[T: 'Type] = inductive {\n    Nil\n    Cons(T, List[T])\n}\n\ndef map(transform: \u2124 -&gt; \u2124, list: List[\u2124]): List[\u2124] = match list {\n    case List[\u2124]::Nil =&gt; List[\u2124]::Nil\n    case List[\u2124]::Cons(head, tail) =&gt; List[\u2124]::Cons(transform head, map transform tail)\n}\n\neval {\n    let list = List[\u2124]::Cons(1, List[\u2124]::Cons(2, List[\u2124]::Cons(3, List[\u2124]::Nil)))\n    let incrementAll = map ((x: \u2124) =&gt; x + 1)\n    incrementAll list\n}\n</code></pre> Run Example <p>In this case, <code>incrementAll</code> is a partially applied version of <code>map</code>, accepting a list of integers and returning a list with each element incremented by 1. The resulting type of <code>incrementAll</code> is: $$ \\text{List}[\\text{\u2124}] \\rightarrow \\text{List}[\\text{\u2124}] $$</p> <p>This means <code>incrementAll</code> is now a function that takes a list of integers and returns a list of integers where each element has been incremented by 1.</p>"},{"location":"Terms/01-lambda/#omitting-type-annotations-in-lambda-expressions","title":"Omitting Type Annotations in Lambda Expressions","text":"<p>When a lambda is passed as an argument and the type can be inferred, type annotations can often be omitted:</p> <pre><code>map (|x| =&gt; x + 1) list\n</code></pre> <p>In this example, <code>x</code> is inferred to be of type <code>\u2124</code> from the context of <code>map</code>\u2019s signature. This reduces verbosity without compromising type safety.</p>"},{"location":"Terms/01-lambda/#syntactic-sugar-for-lambda-expressions","title":"Syntactic Sugar for Lambda Expressions","text":"<p>Saki supports syntax simplifications for lambda expressions. When a lambda is the final argument to a function, parentheses around the lambda can be omitted, as can the <code>=&gt;</code> symbol:</p> <pre><code>map list |x| { x + 1 }\n</code></pre> <p>The type of this lambda remains the same: $$ \\text{\u2124} \\rightarrow \\text{\u2124} $$</p>"},{"location":"Terms/01-lambda/#lambda-returning-another-lambda-curried-function","title":"Lambda Returning Another Lambda (Curried Function)","text":"<p>Lambda expressions in Saki can return other lambdas, facilitating nested function applications. For example:</p> <pre><code>let multiply = (x: \u2124) =&gt; (y: \u2124) =&gt; x * y\n</code></pre> <p>The type of <code>multiply</code> is: $$ \\text{\u2124} \\rightarrow \\text{\u2124} \\rightarrow \\text{\u2124} $$</p> <p>This function takes an integer <code>x</code> and returns a new function that takes another integer <code>y</code> and returns the product <code>x * y</code>. You can partially apply this function:</p> <p>When partially applied, <code>multiply 2</code>, for instance, produces a function <code>\u2124 -&gt; \u2124</code> that doubles any integer input:</p> <pre><code>eval {\n    let multiply = (x: \u2124) =&gt; (y: \u2124) =&gt; x * y\n    multiply 2\n}\n</code></pre> Run Example"},{"location":"Terms/02-dependent-pi/","title":"Dependent Pi (Function) Type","text":"<p>Dependent types generalize function types by allowing the result type to depend on the input value. This capability enables richer type systems where the type returned by a function can vary based on its argument.</p>"},{"location":"Terms/02-dependent-pi/#syntax","title":"Syntax","text":"<p>Dependent types are expressed in terms of \\(\\Pi\\)-types (Pi-types), which describe functions where the return type is dependent on the actual input value. The syntax for dependent function types in Saki is:</p> <pre><code>PiTypeSymbol    ::= \u2018forall\u2019 | \u2018\u03a0\u2019 | \u2018\u2200\u2019\nDepFuncType     ::= PiTypeSymbol \u2018(\u2019 Ident \u2018:\u2019 Term \u2018)\u2019 \u2018-&gt;\u2019 Term\n</code></pre> <p>This can be read as: for all \\(x\\) of type \\(A\\), the type of the result is \\(B(x)\\), where \\(B(x)\\) may depend on the actual value of \\(x\\).</p>"},{"location":"Terms/02-dependent-pi/#typing-rules","title":"Typing Rules","text":""},{"location":"Terms/02-dependent-pi/#formation-rule","title":"Formation Rule","text":"<p>The \\(\\Pi\\)-type is formed when the return type is dependent on the input value. The rule for forming a dependent function type is: $$ \\frac{\\Gamma ,x:A \\vdash B: \\mathcal{U}}{\\Gamma \\vdash \\Pi (x:A) \\,.\\, B: \\mathcal{U}} $$ This rule means that if the return type \\(B(x)\\) is well-formed in the universe \\(\\mathcal{U}\\) when \\(x\\) has type \\(A\\), then the dependent function type \\(\\Pi(x:A) . B(x)\\) is also well-formed in the universe.</p>"},{"location":"Terms/02-dependent-pi/#introduction-rule","title":"Introduction Rule","text":"<p>$$ \\frac{\\Gamma ,x:A \\vdash B: \\mathcal{U} \\quad \\Gamma ,x:A \\vdash b : B}{\\Gamma \\vdash \\lambda (x:A)\\,.\\,b : \\Pi (x:A) \\,.\\, B} $$ This rule means that if \\(b\\) is a term of type \\(B(x)\\) when \\(x\\) has type \\(A\\), then the lambda abstraction \\(\\lambda (x:A) . b\\) has the dependent function type \\(\\Pi(x:A) . B(x)\\).</p>"},{"location":"Terms/02-dependent-pi/#application-rule","title":"Application Rule","text":"\\[ \\frac{\\Gamma \\vdash f : \\Pi(x:A)\\,.\\,B \\quad \\Gamma \\vdash a: A}{\\Gamma \\vdash f \\ a : [x \\mapsto a]B} \\] <p>This rule governs how to apply a dependent function. If \\(f\\) is a function of dependent type \\(\\Pi(x:A) . B(x)\\) and \\(a\\) is a term of type \\(A\\), then applying \\(f\\) to \\(a\\) gives a result of type \\(B(a)\\).</p>"},{"location":"Terms/02-dependent-pi/#beta-reduction-rule","title":"Beta-Reduction Rule","text":"<p>$$ \\frac{\\Gamma \\vdash a: A \\quad \\Gamma ,x:A \\vdash B: \\mathcal{U} \\quad \\Gamma ,x:A \\vdash b : B}{\\Gamma \\vdash (\\lambda (x:A)\\,.\\,b)\\ a \\equiv [x\\mapsto a] b : \\Pi (x:A) \\,.\\, B} $$ This rule is a version of beta-reduction for dependent types. It states that applying a lambda abstraction to an argument results in substituting the argument for the bound variable in the body of the lambda expression. </p> \\[ \\frac{\\Gamma, x : A \\vdash B : \\mathcal{U}}{\\Gamma \\vdash \\Lambda (x : A) \\,.\\, B : \\Pi (x : A) \\,.\\, \\mathcal{U}} \\]"},{"location":"Terms/02-dependent-pi/#subtyping-in-dependent-functions","title":"Subtyping in Dependent Functions","text":"\\[ \\frac{ \\begin{array}{c} \\Gamma, x: A_1 \\vdash B_1 : \\mathcal{U} \\quad \\Gamma, y: A_2 \\vdash B_2 : \\mathcal{U} \\\\ \\Gamma \\vdash A_1 &gt;: A_2 \\quad \\Gamma,\\, x: A_1,\\, y: A_2 \\vdash B_1 &lt;: B_2 \\end{array} }{ \\Gamma \\vdash \\Pi (x: A_1) \\,.\\, B_1 &lt;: \\Pi (x: A_2) \\,.\\, B_2 } \\]"},{"location":"Terms/02-dependent-pi/#examples","title":"Examples","text":""},{"location":"Terms/02-dependent-pi/#dependent-identity-function","title":"Dependent identity function","text":"<p>The dependent identity function takes a type <code>A</code> as an argument and returns a function that takes a value of type <code>A</code> and returns it:</p> <pre><code>forall(A: 'Type) -&gt; (A -&gt; A)\n</code></pre> <p>This can be written in Saki using symbolic notation:</p> <pre><code>\u03a0(A: 'Type) -&gt; (A -&gt; A)\n</code></pre> <p>or</p> <pre><code>\u2200(A: 'Type) -&gt; (A -&gt; A)\n</code></pre> <p>This type describes a polymorphic identity function that works for any type <code>A</code>.</p> <p>An example implementation of this function could be:</p> <pre><code>|A: 'Type| =&gt; |x: A| =&gt; x\n</code></pre> <p>Here, <code>A</code> is a type, and <code>x</code> is a value of type <code>A</code>, which is returned unchanged. The function type is <code>\u03a0(A: 'Type) -&gt; (A -&gt; A)</code>.</p>"},{"location":"Terms/02-dependent-pi/#vector-length-function","title":"Vector length function","text":"<p>Suppose we define a vector type where the length of the vector is encoded in its type. The type of a vector of length <code>n</code> over elements of type <code>A</code> might be written as <code>Vector(A, n)</code>. A function that returns the length of such a vector can be written as:</p> <pre><code>\u2200(A: 'Type) -&gt; \u2200(n: \u2115) -&gt; Vector(A, n) -&gt; \u2115\n</code></pre> <p>This function takes a type <code>A</code>, a natural number <code>n</code>, and a vector of type <code>Vector(A, n)</code>, and returns the length of the vector (which is <code>n</code>).</p> <p>An example implementation might look like:</p> <pre><code>|A: 'Type, n: \u2115, v: Vector(A, n)|: \u2115 =&gt; n\n</code></pre>"},{"location":"Terms/02-dependent-pi/#function-that-depends-on-a-value","title":"Function that depends on a value","text":"<p>Consider a function that returns a type based on the input value. For instance, a function that returns <code>Bool</code> if the input is positive and <code>\u2115</code> otherwise:</p> <pre><code>\u2200(n: \u2124) -&gt; (if n &gt; 0 then Bool else \u2115)\n</code></pre> <p>This is an example of a dependent type where the return type varies depending on the value of the input. The function could be implemented as:</p> <pre><code>|n: \u2124| =&gt; if n &gt; 0 then true else 0\n</code></pre> <p>The return type is <code>Bool</code> if <code>n &gt; 0</code>, and <code>\u2115</code> (represented as 0 here) otherwise. The type of this function is a dependent function type.</p>"},{"location":"Terms/04-expr/","title":"Expressions","text":""},{"location":"Terms/04-expr/#if-expression-terms","title":"If Expression Terms","text":"<p>The if-expression in Saki provides a way to perform conditional branching, allowing a program to execute one of two expressions based on a boolean condition. Unlike some languages where control flow statements are separate from expressions, Saki\u2019s if-expression integrates into the language's expression system, meaning that an if-expression always evaluates to a value.</p>"},{"location":"Terms/04-expr/#syntax","title":"Syntax","text":"<p>The syntax for an if-expression in Saki is:</p> <pre><code>IfExpr ::= 'if' Term 'then' Term 'else' Term\n</code></pre> <ul> <li><code>if</code>: Starts the conditional expression.</li> <li>Condition (<code>Term</code>): The first <code>Term</code> represents the condition. This must be of type <code>Bool</code>.</li> <li><code>then</code>: If the condition evaluates to <code>true</code>, the expression following the <code>then</code> keyword is evaluated.</li> <li><code>else</code>: If the condition evaluates to <code>false</code>, the expression following the <code>else</code> keyword is evaluated.</li> </ul>"},{"location":"Terms/04-expr/#typing-rules","title":"Typing Rules","text":"<p>The typing rule for an if-expression ensures that the result of the expression is type-consistent across both branches (<code>then</code> and <code>else</code>). Formally, the rule can be written as:</p> \\[ \\frac{\\Gamma \\vdash t_1: \\mathbb{B} \\quad \\Gamma \\vdash t_2: T \\quad \\Gamma \\vdash t_3: T}{\\Gamma \\vdash \\text{if } t_1 \\text{ then } t_2 \\text{ else } t_3 : T} \\] <p>Where:</p> <ul> <li>The condition \\(t_1\\) must have type <code>Bool</code> (denoted by \\(\\mathbb{B}\\)).</li> <li>The <code>then</code> and <code>else</code> branches (\\(t_2\\) and \\(t_3\\)) must both have the same type \\(T\\) for the if-expression to be well-typed.</li> </ul> <pre><code>eval {\n    let value = 10\n    if value % 2 == 0 then \"Even\" else \"Odd\"\n}\n</code></pre> Run Code"},{"location":"Terms/04-expr/#match-expression-terms","title":"Match Expression Terms","text":"<p>The match-expression in Saki is a powerful construct for pattern matching, similar to pattern matching in languages like Haskell or ML. It allows a value (usually of a record, inductive type or algebraic data type) to be deconstructed and matched against a set of patterns. The matched pattern determines which branch of the expression will be executed. Pattern matching is essential for working with algebraic data types and other complex structures.</p>"},{"location":"Terms/04-expr/#syntax_1","title":"Syntax","text":"<p>The syntax for a match-expression is:</p> <pre><code>MatchExpr  ::= 'match' Term '{' CaseClause+ '}'\nCaseClause ::= 'case' Pattern '=&gt;' Term\n</code></pre> <ul> <li><code>match</code>: Begins the match-expression.</li> <li>Term: The term being matched, often an algebraic data type or inductive type.</li> <li><code>with</code>: Introduces the case clauses that follow.</li> <li><code>case</code>: Defines each pattern to match.</li> <li>Pattern: The pattern to match against the term.</li> <li><code>=&gt;</code>: Separates the pattern from the corresponding expression to evaluate.</li> </ul>"},{"location":"Terms/04-expr/#typing-rules_1","title":"Typing Rules","text":"<p>The typing rule for match-expressions ensures that the matched patterns are exhaustive and that each branch returns the same type <code>T</code>:</p> \\[ \\frac{\\Gamma \\vdash t: T \\quad \\Gamma \\vdash p_i: T \\quad \\Gamma \\vdash e_i: R}{\\Gamma \\vdash \\text{match } t \\ \\{ \\ p_1 \\Rightarrow e_1 \\mid \\dots \\mid p_n \\Rightarrow e_n \\ \\} : R} \\] <p>Where:</p> <ul> <li>The term \\(t\\) being matched must have type \\(T\\).</li> <li>Each pattern \\(p_i\\) must correspond to a value of type \\(T\\).</li> <li>The expression \\(e_i\\) associated with each pattern must return the same type \\(R\\), ensuring uniformity across all branches.</li> <li>The patterns must be exhaustive, covering all possible values of the term \\(t\\). Failing to provide exhaustive patterns would result in a type error, as not all possible values would be handled.</li> </ul>"},{"location":"Terms/04-expr/#example-boolean-pattern-matching","title":"Example: Boolean Pattern Matching","text":"<p>In the following example, a boolean value is matched against two patterns: <code>true</code> and <code>false</code>:</p> <pre><code>def toInt(b: Bool): \u2124 = match b {\n    case true =&gt; 1\n    case false =&gt; 0\n}\n\neval true.toInt  // Result: 1\neval false.toInt // Result: 0\n</code></pre> Run Code <p>Here, the match-expression transforms a boolean value into an integer representation by explicitly handling both possible cases of a <code>Bool</code> type.</p>"},{"location":"Terms/04-expr/#pattern-matching-on-inductive-types","title":"Pattern Matching on Inductive Types","text":"<p>Pattern matching becomes particularly useful when working with inductive types, which may represent optional values, lists, or other recursively defined structures. Consider the following inductive type <code>Option</code>:</p> <pre><code>type Option[A: 'Type] = inductive {\n    None\n    Some(A)\n}\n\ndef getOrDefault[A: 'Type](opt: Option[A], default: A): A = match opt {\n    case Option[A]::Some(x) =&gt; x\n    case Option[A]::None =&gt; default\n}\n\neval Option[Int]::Some(114514).getOrDefault[Int](0) // Result: 114514\neval Option[Int]::None.getOrDefault[Int](0)         // Result: 0\n</code></pre> Run Code"},{"location":"Terms/05-sum/","title":"Sum Type","text":"<p>Sum types (also known as disjoint union types or variant types) are one of the key constructs in type theory for expressing a choice between different types. A sum type allows a value to be one of several distinct types. </p>"},{"location":"Terms/05-sum/#syntax","title":"Syntax","text":"<p>In Saki, sum types are written using the vertical bar (<code>|</code>) symbol to denote a disjoint union between two or more types:</p> <pre><code>SumTypeTerm     ::= Term \u2018|\u2019 Term\n</code></pre> <p>This means that a value of type \\((A \\mid B)\\) can be either a value of type \\(A\\) or a value of type \\(B\\). The sum type is closed and disjoint, meaning the value must belong to one of the specified types and not both simultaneously. This is distinct from intersection types where values must belong to all specified types.</p>"},{"location":"Terms/05-sum/#typing-rules-for-sum-types","title":"Typing Rules for Sum Types","text":"<p>In formal terms, the behavior of sum types is governed by subtyping relationships. The typing rules for sum types ensure that they can participate in subtyping relationships in a way that preserves soundness and flexibility.</p>"},{"location":"Terms/05-sum/#subtyping-rule-for-sum-types-covariant","title":"Subtyping Rule for Sum Types (Covariant)","text":"<p>The following rule describes subtyping for sum types in the covariant case:</p> \\[ \\frac{ \\forall i \\,.\\, \\exists j \\,.\\, (\\Gamma \\vdash A_i &lt;: B_j) }{ \\Gamma \\vdash \\bigsqcup_i A_i &lt;: \\bigsqcup_j B_j } \\] <p>This rule asserts that if for every component type \\(A_i\\) in the sum type \\(\\bigsqcup_i A_i\\), there exists a corresponding type \\(B_j\\) in the sum type \\(\\bigsqcup_j B_j\\), and \\(A_i\\) is a subtype of \\(B_j\\), then the sum of all \\(A_i\\) is a subtype of the sum of all \\(B_j\\). This reflects the covariance of sum types, meaning that they preserve subtyping relationships when their component types are related by subtyping.</p>"},{"location":"Terms/05-sum/#subtyping-rule-for-sum-types-contravariant","title":"Subtyping Rule for Sum Types (Contravariant)","text":"<p>There is also a corresponding rule for contravariant subtyping of sum types, where the direction of the subtyping relationship is reversed:</p> \\[ \\frac{ \\Gamma \\vdash \\forall i \\,.\\, \\exists j \\,.\\, (A_i &gt;: B_j) }{ \\Gamma \\vdash \\bigsqcup_i A_i &gt;: \\bigsqcup_j B_j } \\] <p>This means that if for every component type \\(A_i\\) in the sum type \\(\\bigsqcup_i A_i\\), there exists a corresponding type \\(B_j\\) in the sum type \\(\\bigsqcup_j B_j\\), and \\(A_i\\) is a supertype of \\(B_j\\), then the sum of all \\(A_i\\) is a supertype of the sum of all \\(B_j\\). This rule reflects the contravariant nature of certain contexts, such as function parameters, where subtypes behave in the opposite direction.</p>"},{"location":"Terms/05-sum/#intuition-behind-the-typing-rules","title":"Intuition Behind the Typing Rules","text":"<p>The subtyping rules for sum types are based on the notion of type containment and choice. A sum type \\(A | B\\) is essentially saying that a value belongs to either \\(A\\) or \\(B\\), but not both at the same time. Therefore:</p> <ul> <li>Covariance (first rule) applies when the subtypes on the left-hand side can be safely used as substitutes for the types on the right-hand side. This occurs when the sum type's components are subtypes of the corresponding components in the supertype sum.</li> <li>Contravariance (second rule) works in the opposite direction, often in contexts where the sum type appears as a function argument. In such cases, the supertype on the left-hand side can safely be used where the subtype on the right-hand side is expected.</li> </ul>"},{"location":"Terms/05-sum/#examples-of-sum-types","title":"Examples of Sum Types","text":""},{"location":"Terms/05-sum/#basic-sum-type","title":"Basic Sum Type","text":"<p>Consider a sum type representing a value that may either be an integer (\\(\\mathbb{Z}\\)) or a string:</p> <pre><code>(\u2124 | String)\n</code></pre> <p>The type \\((\u2124 \\mid String)\\) specifies that a value can either be an integer or a string. Valid values for this type include:</p> <pre><code>42 : (\u2124 | String)\n\"Hello\" : (\u2124 | String)\n</code></pre>"},{"location":"Terms/05-sum/#sum-type-with-subtyping","title":"Sum Type with Subtyping","text":"<p>Suppose <code>Dog</code> is a subtype of <code>Animal</code>. If we define a sum type:</p> <pre><code>(Dog | String)\n</code></pre> <p>Using the covariant subtyping rule, we conclude:</p> <pre><code>(Animal | String) &lt;: (Dog | String)\n</code></pre> <p>Since <code>Dog &lt;: Animal</code>, the sum type containing <code>Dog</code> is a subtype of one containing <code>Animal</code> in the corresponding position.</p>"},{"location":"Terms/05-sum/#covariance-in-function-return-types","title":"Covariance in Function Return Types","text":"<p>Sum types frequently appear as return types in functions. Consider a function that may return either a <code>Dog</code> instance or an error message (as a string):</p> <pre><code>def resultFunction(): (Dog | String) = { ... }\n</code></pre> <p>This function\u2019s return type can also be expressed as <code>Animal | String</code> since <code>Dog &lt;: Animal</code>. Replacing the return type with <code>Animal | String</code> is valid:</p> <pre><code>def resultFunction(): (Animal | String) = { ... }\n</code></pre> <p>Covariance permits the substitution of a subtype (<code>Dog</code>) for a supertype (<code>Animal</code>) in the return type.</p>"},{"location":"Terms/05-sum/#sum-types-in-pattern-matching","title":"Sum Types in Pattern Matching","text":"<p>Sum types are particularly advantageous in pattern matching. For example, consider a type representing a boolean, an integer, or a string:</p> <pre><code>(Bool | \u2124 | String)\n</code></pre> <p>In a function, we can match against this sum type:</p> <pre><code>def describeValue(value: (Bool | \u2124 | String)): String = match value {\n    case true =&gt; \"It's true!\"\n    case false =&gt; \"It's false!\"\n    case n: \u2124 =&gt; \"It's an integer: \" ++ n.toString ++ \"!\"\n    case s: String =&gt; \"It's \" ++ s ++ \"!!!!!\"\n}\n\neval describeValue 2024     // Output: \"It's an integer: 2024!\"\neval describeValue true     // Output: \"It's true!\"\neval describeValue \"mygo\"   // Output: \"It's mygo!!!!!\"\n</code></pre> Run Code <p>Here, the type \\((Bool \\mid \u2124 \\mid String)\\) allows the function to process each type individually, and we can handle each case appropriately with pattern matching.</p>"},{"location":"Terms/06-pair/","title":"Product Type (Pair)  and Dependent Sigma Type","text":""},{"location":"Terms/06-pair/#product-type-pair","title":"Product Type (Pair)","text":"<p>In type theory, the product type (often referred to as the pair type) is a type that combines two other types into a single type. This type is denoted by \\(A \\times B\\), where \\(A\\) and \\(B\\) are types. Formally, an element of the product type \\(A \\times B\\) is a pair \\((a, b)\\), where \\(a : A\\) and \\(b : B\\).</p>"},{"location":"Terms/06-pair/#syntax","title":"Syntax","text":"<pre><code>PairType        ::= (Term \u2018,\u2019 Term)\nPairValue       ::= \u2018'\u2019 \u2018(\u2019 Term \u2018,\u2019 Term \u2018)\u2019\n</code></pre>"},{"location":"Terms/06-pair/#dependent-sigma-type","title":"Dependent Sigma Type","text":"<p>In type theory, the dependent sigma type (often referred to as the dependent pair type) extends the notion of the product type by allowing the second component of a pair to depend on the first component. This type is denoted by \\(\\Sigma(x : A) . B(x)\\), where \\(A\\) is a type, and \\(B(x)\\) is a family of types indexed by elements of \\(A\\). Formally, for each \\(a : A\\), \\(B(a)\\) is a type, and \\(\\Sigma(x : A) . B(x)\\) represents the type of pairs \\((a, b)\\), where \\(a : A\\) and \\(b : B(a)\\).</p> <p>This construction generalizes the usual product type \\(A \\times B\\), which can be seen as a special case of the dependent sigma type where \\(B(x)\\) is constant (i.e., does not depend on \\(x\\)). In the case of a dependent sigma type, the second component is required to be a term of a type that is indexed by the first component. This reflects the central idea of dependency: the second component \\(b\\) is not an arbitrary element of some type but is constrained by the first component \\(a\\) through the type \\(B(a)\\).</p>"},{"location":"Terms/06-pair/#syntax_1","title":"Syntax","text":"<pre><code>SigmaTypeSymbol ::= \u2018exists\u2019 | \u2018\u03a3\u2019 | \u2018\u2203\u2019\nProdTypeTerm    ::= SigmaTypeSymbol Ident \u2018:\u2019 Term\nDepProdType     ::= \u2018(\u2019 ( PairTypeTerm \u2018,\u2019 )* Term \u2018)\u2019\n</code></pre>"},{"location":"Terms/06-pair/#formal-definition","title":"Formal Definition","text":"<p>Given: 1. A type \\(A\\), 2. A dependent type \\(B : A \\to \\text{Type}\\), a function that assigns a type \\(B(a)\\) to each element \\(a : A\\),</p> <p>the dependent sigma type \\(\\Sigma(x : A) . B(x)\\) is defined as the type of pairs \\((a, b)\\) where: - \\(a : A\\), - \\(b : B(a)\\).</p> <p>Thus, an element of \\(\\Sigma(x : A) . B(x)\\) is a dependent pair \\((a, b)\\), where the type of \\(b\\) depends on \\(a\\).</p>"},{"location":"Terms/06-pair/#projections-and-operations-on-dependent-sigma-types","title":"Projections and Operations on Dependent Sigma Types","text":"<p>The first projection \\(\\pi_1\\) for an element \\((a, b) : \\Sigma(x : A) . B(x)\\) extracts the first component, i.e., $$ \\pi_1 : \\Sigma(x : A) . B(x) \\to A, \\quad \\pi_1(a, b) = a. $$ The second projection \\(\\pi_2\\) extracts the second component, which depends on the first component, i.e., $$ \\pi_2 : \\Sigma(x : A) . B(x) \\to B(\\pi_1(a, b)), \\quad \\pi_2(a, b) = b. $$ These projections decompose a dependent pair into its components, respecting the dependency structure.</p>"},{"location":"Terms/06-pair/#introduction-and-elimination-rules","title":"Introduction and Elimination Rules","text":"<p>In type theory, the introduction and elimination rules for the dependent sigma type formalize how elements of \\(\\Sigma\\)-types are constructed and used.</p> <ol> <li> <p>Introduction Rule: If \\(a : A\\) and \\(b : B(a)\\), then \\((a, b) : \\Sigma(x : A) . B(x)\\). This corresponds to the pairing operation and constructs a term of the dependent sigma type from a term of \\(A\\) and a dependent term of \\(B(a)\\).</p> </li> <li> <p>Elimination Rule: Given \\(p : \\Sigma(x : A) . B(x)\\), we can project out its components:</p> <ul> <li>\\(\\pi_1(p)\\) gives the first component of the pair,</li> <li>\\(\\pi_2(p)\\) gives the second component, which is of type \\(B(\\pi_1(p))\\), ensuring that the dependency on the first component is preserved.</li> </ul> </li> </ol> <p>These rules allow the construction of dependent pairs and the decomposition of these pairs into their respective components.</p>"},{"location":"Terms/06-pair/#equivalence-with-product-types","title":"Equivalence with Product Types","text":"<p>When \\(B(x)\\) does not depend on \\(x\\), i.e., \\(B(x) = B\\) for some fixed type \\(B\\), the dependent sigma type \\(\\Sigma(x : A) . B(x)\\) reduces to the usual product type \\(A \\times B\\). This equivalence is expressed as: $$ \\Sigma(x : A) . B = A \\times B, $$ where \\(B\\) is constant with respect to \\(x\\). This shows that the dependent sigma type is a strict generalization of the product type, encompassing cases where the second type can vary with the first element.</p>"},{"location":"Terms/07-record/","title":"Record","text":"<p>Record terms in Saki represent structured data types that aggregate multiple named fields, each of which is associated with a specific type. They are similar to records or structs in other programming languages, providing a way to group related data under one composite type. The flexibility of records, along with the ability to organize fields with shared types concisely, makes them useful for modeling a wide variety of data structures.</p>"},{"location":"Terms/07-record/#syntax","title":"Syntax","text":"<p>The syntax for defining a record type in Saki is as follows:</p> <pre><code>FieldBinding ::= Ident+ ':' Term\nRecordTerm   ::= 'record' '{' FieldBinding ((NL+|',') FieldBinding)* '}'\n</code></pre> <ul> <li> <p>FieldBinding: The field declaration in a record, consisting of one or more field names (<code>Ident+</code>) followed by a colon (<code>:</code>) and the type (<code>Term</code>). The <code>Ident+</code> syntax indicates that multiple fields can share the same type, simplifying the declaration of records with fields of identical types.</p> </li> <li> <p>RecordTerm: The entire record type definition. The <code>record</code> keyword introduces the record, followed by a block <code>{}</code> containing one or more field declarations (<code>FieldBinding</code>). Field declarations can be separated by either newlines (<code>NL</code>) or commas.</p> </li> </ul>"},{"location":"Terms/07-record/#typing-rules","title":"Typing Rules","text":"<p>The formal typing rules for records in Saki specify how to type both the record term and the field access. The rules ensure that the types of fields are consistent with the declared record structure.</p>"},{"location":"Terms/07-record/#typing-a-record-term","title":"Typing a Record Term","text":"<p>The typing rule for constructing a record is given as:</p> \\[ \\frac{\\Gamma \\vdash \\overline{t_i : T_i}^i}{\\Gamma \\vdash \\{ \\overline{l_i = t_i}^i \\} : \\{ \\overline{l_i : T_i}^i \\}} \\] <p>This rule means that if each field <code>t_i</code> has type <code>T_i</code> in the typing context \\(\\Gamma\\), then the record <code>{ l_i = t_i }</code> is of type <code>{ l_i : T_i }</code>. In other words, if all fields are well-typed according to their declarations, the entire record is well-typed.</p>"},{"location":"Terms/07-record/#typing-field-access","title":"Typing Field Access","text":"<p>The rule for accessing a field from a record is as follows:</p> \\[ \\frac{\\Gamma \\vdash t: \\{ \\overline{l_i : T_i}^i \\}}{\\Gamma \\vdash t.f_i : T_i} \\] <p>This rule means that if a term <code>t</code> is a record with a field <code>f_i</code> of type <code>T_i</code>, then accessing the field <code>t.f_i</code> results in a value of type <code>T_i</code>. The field access operation is type-safe because it guarantees that the type of the field matches its declaration in the record.</p>"},{"location":"Terms/07-record/#record-subtyping","title":"Record Subtyping","text":"<p>Saki supports structural subtyping for records, meaning that a record with more fields can be a subtype of a record with fewer fields if the shared fields have matching types. This is formalized as:</p> \\[ \\forall S \\,.\\, \\forall (S' \\subseteq S) \\,.\\, \\{\\overline{l_i : T_i}^{i \\in S}\\} &lt;: \\{\\overline{l_i : T_i}^{i \\in S'}\\} \\] <p>This rule states that a record type with fields indexed by <code>S</code> is a subtype of a record type with fields indexed by <code>S'</code> if <code>S'</code> is a subset of <code>S</code>. This allows for flexibility when passing records to functions that only need to access a subset of the fields.</p>"},{"location":"Terms/07-record/#examples","title":"Examples","text":""},{"location":"Terms/07-record/#basic-record-declaration","title":"Basic Record Declaration","text":"<p>A simple record with fields <code>name</code> and <code>age</code>:</p> <pre><code>record {\n    name: String\n    age: \u2124\n}\n</code></pre> <p>This defines a record with two fields:</p> <ul> <li><code>name</code> of type <code>String</code></li> <li><code>age</code> of type <code>\u2124</code> (Integer)</li> </ul> <p>A record type like this can be used to represent an entity, such as a person, where each field holds specific data relevant to that entity.</p>"},{"location":"Terms/07-record/#nested-records-and-higher-level-universes","title":"Nested Records and Higher-Level Universes","text":"<pre><code>record {  \n    name: String\n    birthDate: record {\n        day month year: \u2124\n    }\n}\n</code></pre> <p>Here, the <code>birthDate</code> field is a nested record with fields for <code>day</code>, <code>month</code>, and <code>year</code>, all of type <code>\u2115</code>. </p>"},{"location":"Terms/07-record/#field-assignments-for-record-values","title":"Field Assignments for Record Values","text":"<p>Record terms not only define types but also support value instantiation. A record value can be created using field assignments. The syntax for record values is:</p> <pre><code>FieldAssignment   ::= Ident (\u2018:\u2019 Term)? \u2018=\u2019 Term\nRecordValueTerm   ::= (Term | 'record') \u2018^\u2019 \u2018{\u2019 (FieldAssignment ((NL+|\u2018,\u2019) FieldAssignment)*)? \u2018}\u2019\n</code></pre> <ul> <li>FieldAssignment: A field value assignment uses the <code>Ident = Term</code> syntax, where <code>Ident</code> is the field name and <code>Term</code> is the value assigned to that field.</li> <li>RecordValueTerm: The value instantiation uses the <code>Term ^ { ... }</code> syntax, where <code>Term</code> refers to the record type, and the braces <code>{}</code> enclose field assignments. In addition, anonymous record values are represented by <code>record ^ { ... }</code> syntax.</li> </ul> <p>Consider the following example of creating a <code>Point</code> record:</p> <pre><code>type Point = record {\n    x y z: \u211d\n}\n\neval Point '{\n    x = 1.0\n    y = 2.0\n    z = 3.0\n}\n</code></pre> Run Example <p>This code defines a record type <code>Point</code> with three fields (<code>x</code>, <code>y</code>, <code>z</code>) of type <code>\u211d</code> (real numbers). The value <code>point</code> is an instance of the <code>Point</code> record, where the fields are assigned values: <code>x = 1.0</code>, <code>y = 2.0</code>, and <code>z = 3.0</code>.</p>"},{"location":"Terms/07-record/#using-record-subtyping","title":"Using Record Subtyping","text":"<p>Suppose you have a function that operates on a subset of the fields in a record. Using Saki\u2019s structural subtyping, you can pass records with extra fields to functions that only expect a subset. For example:</p> <pre><code>type Person = record {\n    name: String\n    age: \u2124\n}\n\ndef getName(obj: record { name: String }): String = obj.name\n\neval {\n    let person = Person '{\n        name = \"Sakiko Togawa\"\n        age = 15\n    }\n    getName(person)\n}\n</code></pre> Run Example <p>Here, the <code>printName</code> function expects a record with only a <code>name</code> field. However, <code>person</code> is a record with both <code>name</code> and <code>age</code>. Thanks to structural subtyping, <code>person</code> can still be passed to <code>printName</code>, as the <code>name</code> field exists and has the correct type.</p>"},{"location":"Terms/07-record/#higher-level-universes-in-record-fields","title":"Higher-Level Universes in Record Fields","text":"<p>Saki\u2019s type system is based on Martin-L\u00f6f Type Theory (MLTT), which supports universes \u2014 hierarchical levels of types, where types themselves can belong to higher universes. This feature allows for contracts, dependent types, and abstract types to be embedded in records. Fields in records can be drawn from higher-level universes, allowing complex interactions between fields while preserving type safety. </p>"},{"location":"Terms/07-record/#examples-of-higher-level-universes-in-records","title":"Examples of Higher-Level Universes in Records","text":""},{"location":"Terms/07-record/#contract-universes-in-records","title":"Contract Universes in Records","text":"<p>Suppose we define a contract universe for printable objects, where any object that conforms to the <code>Printable</code> contract must implement a <code>print</code> method that returns a <code>String</code>. We can store such contract-bound objects in a record:</p> <pre><code>universe 'Printable = contract {\n    require print(self): String\n}\n\nrecord {\n    docType: 'Printable\n    content: String\n}\n</code></pre> <ul> <li><code>docType</code> is a field that must conform to the <code>'Printable</code> contract, ensuring that any object assigned to this field implements the <code>print</code> method. </li> <li><code>content</code> is a simple string field.</li> </ul>"},{"location":"Terms/07-record/#dependent-types-in-records","title":"Dependent Types in Records","text":"<p>Records can contain fields whose types depend on the values of other fields. For instance, consider a record that stores a vector and its size, where the size field determines the length of the vector:</p> <pre><code>record {\n    size: \u2115\n    elements: Vector(\u211d, size)\n}\n</code></pre> <ul> <li><code>size</code> is a natural number representing the length of the vector.</li> <li><code>elements</code> is a vector of real numbers, where the size of the vector is determined by the <code>size</code> field.</li> </ul>"},{"location":"Terms/07-record/#recursive-records-with-higher-level-universes","title":"Recursive Records with Higher-Level Universes","text":"<p>Higher-level universes enable recursive data structures. Consider a record that models a tree with operations defined at the universe level:</p> <pre><code>universe 'Tree(A: 'Type) = contract {\n    require insert(self, value: A): 'Tree(A)\n    require find(self, value: A): Option(A)\n}\n\nrecord {\n    elementType: 'Type\n    structure: 'Tree(elementType)\n}\n</code></pre> <ul> <li><code>elementType</code> is a type from the universe <code>'Type</code>, which allows for any valid type in the Saki type system.</li> <li><code>structure</code> is a tree that supports <code>insert</code> and <code>find</code> operations, constrained by the contract <code>'Tree(elementType)</code>.</li> </ul>"},{"location":"Terms/07-record/#abstract-operations-in-records","title":"Abstract Operations in Records","text":"<p>Higher-level universes allow fields in records to refer to abstract types and operations. For example, a record might represent a mathematical object with an associated operation:</p> <pre><code>universe 'Operation = contract {\n    require apply(self, x: A, y: A): A\n}\n\nrecord {\n    operandType: 'Type\n    operation: 'Operation\n}\n</code></pre> <ul> <li><code>operandType</code> is a field from the universe <code>'Type</code>, representing any valid type.</li> <li><code>operation</code> is a contract universe that ensures the field adheres to the <code>'Operation</code> contract, defining an <code>apply</code> method for performing operations on values of <code>operandType</code>.</li> </ul>"},{"location":"Terms/07-record/#complex-example-a-physics-model-with-higher-level-universes","title":"Complex Example: A Physics Model with Higher-Level Universes","text":"<p>Consider a model of a physical object, where the <code>material</code> and <code>physical</code> fields are abstract and enforced by higher-level universes:</p> <pre><code>universe 'PhysicalObject = contract {\n    require volume(self): \u211d\n}\n\nrecord {\n    material: 'Type\n    dimensions: record {\n        length width height: \u211d\n    }\n    physical: 'PhysicalObject\n}\n</code></pre>"},{"location":"Terms/08-adt/","title":"Algebraic Datatype","text":"<p>Algebraic Datatype (ADT) is a special kind of inductive types that are essential in functional programming and type theory. They are used to define composite types by combining other types using sum types (also known as variants) and product types. ADTs are particularly useful for modeling data that can take multiple distinct forms, and they are foundational in expressing complex structures such as trees, lists, and option types. In Saki, ADTs are defined using the <code>enum</code> keyword and can be parameterized by types and type classes, with the ability to incorporate contract universes for constrained types.</p>"},{"location":"Terms/08-adt/#syntax-of-algebraic-datatypes","title":"Syntax of Algebraic Datatypes","text":"<p>The syntax for defining ADTs in Saki follows a straightforward pattern:</p> <pre><code>InductiveCons     ::= Ident (\u2018(\u2019 Term (\u2018,\u2019 Term)* \u2018)\u2019)?\nInductiveTypeTerm ::= \u2018inductive\u2019 \u2018{\u2019 InductiveCons (\u2018,\u2019 InductiveCons)* \u2018}\u2019\n</code></pre> <ul> <li>EnumCons: Represents each constructor of the algebraic datatype. A constructor can either be a simple identifier (like <code>None</code>) or an identifier with parameters (like <code>Some(A)</code>).</li> <li>EnumTypeTerm: The ADT is introduced using the <code>inductive</code> keyword, followed by a list of constructors enclosed in braces <code>{}</code>. Multiple constructors can be defined, separated by commas.</li> </ul> <p>Each constructor defines a specific form that a value of the ADT can take, either as a simple tag or as a combination of different types. ADTs in Saki resemble sum types in type theory, where each constructor defines a possible variant of the type.</p> <p>Algebraic Data Types can be understood as sum types in type theory, which are defined using coproducts. A sum type, like <code>A + B</code>, represents a type that can hold either a value of type <code>A</code> or a value of type <code>B</code>. In the context of ADTs: - Each constructor of the ADT corresponds to an inclusion map into the coproduct. - The ADT represents the disjoint union of its constructors.</p> <p>For instance, the type <code>Option(A)</code> is defined as: $$ \\text{Option}(A) \\cong 1 + A $$ Where:</p> <ul> <li><code>1</code> represents the <code>None</code> constructor (the unit type), indicating absence.</li> <li><code>A</code> represents the <code>Some</code> constructor, indicating presence.</li> </ul> <p>Similarly, the tree type <code>Tree[A]</code> can be seen as: $$ \\text{Tree}(A) \\cong 1 + (\\text{Color} \\times A \\times \\text{Tree}(A) \\times \\text{Tree}(A)) $$ This reflects the two possible forms of the tree:</p> <ul> <li>A <code>Leaf</code> (represented by <code>1</code>).</li> <li>A <code>Node</code>, which holds a <code>Color</code>, a value of type <code>A</code>, and two subtrees of type <code>Tree[A]</code>.</li> </ul>"},{"location":"Terms/08-adt/#examples-of-adts-in-saki","title":"Examples of ADTs in Saki","text":""},{"location":"Terms/08-adt/#simple-algebraic-data-type-color","title":"Simple Algebraic Data Type: <code>Color</code>","text":"<p>The following is an example of a simple ADT called <code>Color</code>, which represents a type with no parameters and has two distinct values: <code>Red</code> and <code>Black</code>.</p> <pre><code>type Color = inductive { Red; Black }\n</code></pre> <p>In this case, <code>Color</code> is a sum type with two possible values, <code>Red</code> and <code>Black</code>. Each constructor defines a unique value of the <code>Color</code> type. This is a basic example of an ADT, where no additional parameters or data are required.</p>"},{"location":"Terms/08-adt/#parameterized-algebraic-data-type-option","title":"Parameterized Algebraic Data Type: <code>Option</code>","text":"<p>The <code>Option</code> type is a more complex example of an ADT. It represents a type that can either contain a value of type <code>A</code> or no value at all.</p> <pre><code>type Option(A: 'Type) = inductive {\n    None\n    Some(A)\n}\n</code></pre> <ul> <li><code>Option(A)</code>: A generic ADT parameterized by a type <code>A</code>.</li> <li><code>None</code>: A constructor representing the absence of a value.</li> <li><code>Some(A)</code>: A constructor representing the presence of a value of type <code>A</code>.</li> </ul>"},{"location":"Terms/08-adt/#nested-algebraic-data-type-list","title":"Nested Algebraic Data Type: <code>List</code>","text":"<p>The following example illustrates a recursive ADT that defines a list structure. The <code>List</code> type is parameterized by a type <code>A</code> and has two constructors: <code>Nil</code>, representing an empty list, and <code>Cons</code>, which constructs a new list by prepending an element of type <code>A</code> to an existing list of type <code>List[A]</code>.</p> <pre><code>type List[A: 'Type] = inductive {\n    Nil\n    Cons(A, List[A])\n}\n</code></pre> <ul> <li><code>Nil</code>: Represents an empty list.</li> <li><code>Cons(A, List[A])</code>: Represents a non-empty list, where the first element is of type <code>A</code> and the rest is a list of type <code>List[A]</code>.</li> </ul>"},{"location":"Terms/08-adt/#tree-structure-using-adts-tree","title":"Tree Structure Using ADTs: <code>Tree</code>","text":"<p>The following example defines a binary tree structure, where each node contains a color, a value of type <code>A</code>, and two subtrees of the same type <code>Tree[A]</code>.</p> <pre><code>type Tree[A: 'Type] = inductive {\n    Leaf\n    Node(Color, A, Tree[A], Tree[A])\n}\n</code></pre> <ul> <li><code>Leaf</code>: Represents a leaf node, which has no data.</li> <li><code>Node(Color, A, Tree[A], Tree[A])</code>: Represents an internal node that contains a value of type <code>A</code>, a <code>Color</code>, and two subtrees of type <code>Tree[A]</code>.</li> </ul>"},{"location":"Terms/08-adt/#adtinductive-constructor-access","title":"ADT/Inductive Constructor Access","text":"<p>In Saki, the constructors of inductive types (including ADTs) can be accessed using the <code>::</code> operator. For example:</p> <pre><code>type Option(A: 'Type) = inductive {\n    None\n    Some(A)\n}\n\neval Option(Int)::None\neval Option(String)::Some\n</code></pre> Run Code"},{"location":"Terms/09-inductive/","title":"Inductive Type with Indices","text":"<p>Warning</p> <p>This feature is not yet implemented or not fully supported in the current version of Saki interpreter/REPL.</p> <p>In type theory, inductive types are fundamental constructs that allow the definition of complex data structures by specifying their constructors.  In previous sections, we introduced algebraic data types (ADTs) as a special case of inductive types.  An extension of inductive types involves introducing indices, allowing the type to vary depending on certain parameters.  This leads to the concept of indexed families or inductive types with indices. This feature enable the encoding of rich invariants directly into the type system.</p>"},{"location":"Terms/09-inductive/#syntax-of-inductive-types","title":"Syntax of Inductive Types","text":"<p>The general form for defining inductive types in Saki is:</p> <pre><code>InductiveConsType       ::= InductiveConsTypeAtom (\u2018-&gt;\u2019 InductiveConsTypeAtom)*\nInductiveConsTypeAtom   ::= ( Term | (\u2018this\u2019 ImplicitArgList? ExplicitArgList?) )\nInductiveCons           ::= Ident \u2018:\u2019 InductiveConsType\nInductiveTypeTerm       ::= \u2018inductive\u2019 ExplicitArgList? \u2018{\u2019 InductiveCons (NL+ InductiveCons)* \u2018}\u2019\n</code></pre> <p>The syntax includes:</p> <ul> <li>InductiveConsType: Specifies the type of a constructor. It consists of zero or more parameter types, followed by a return type, which can be a <code>Term</code> or the inductive type itself, denoted by <code>this</code>.</li> <li>InductiveCons: Declares a constructor with an identifier (<code>Ident</code>), a colon, and its type (<code>InductiveConsType</code>). </li> <li>InductiveTypeTerm: Defines the inductive type, starting with the <code>inductive</code> keyword, optionally followed by explicit arguments (<code>ExplicitArgList</code>), and containing one or more constructors within braces <code>{}</code>.</li> </ul> <p>The parameters listed after the <code>inductive</code> keyword represent the index of the inductive type. Since the ultimate part of the index in Saki is always <code>'Type</code>, we do not explicitly write it. This mirrors the index definition in CIC, where inductive types can take parameters but always return a value in the universe of types (<code>Type</code>). For example, in Saki, <code>inductive(A)</code> corresponds to an index of <code>A -&gt; 'Type</code>.</p>"},{"location":"Terms/09-inductive/#general-form-of-inductive-types","title":"General Form of Inductive Types","text":"<p>An inductive type in Saki can be defined in the following general form:</p> <pre><code>inductive(&lt;IndexParams&gt;) {\n   Constructor\u2081 : &lt;ConstructorType\u2081&gt;\n   \u22ee\n   Constructor\u2099 : &lt;ConstructorType\u2099&gt;\n}\n</code></pre> <ul> <li> <p>IndexParams: Parameters or indices that the inductive type depends on. These can be types or values upon which the type varies.</p> </li> <li> <p>Constructor\u2081 \u2026 Constructor\u2099: Constructors that define how values of the inductive type can be constructed. Each constructor has a corresponding type <code>&lt;ConstructorType&gt;</code> that may involve the indices and the inductive type itself.</p> </li> </ul>"},{"location":"Terms/09-inductive/#algebraic-data-type-style-vs-inductive-style-definitions","title":"Algebraic Data Type Style vs. Inductive Style Definitions","text":"<p>Inductive types can be defined in different styles. The Algebraic Data Type (ADT) style is more concise and resembles traditional sum types, while the inductive style provides more explicit definitions with indices, providing greater expressiveness and control over the type system.</p> <p>Consider the <code>Option</code> type as an example.</p>"},{"location":"Terms/09-inductive/#adt-style-definition","title":"ADT Style Definition","text":"<pre><code>type Option(A: 'Type) = inductive {\n    None\n    Some(A)\n}\n</code></pre> <p>In this definition:</p> <ul> <li><code>Option</code> is parameterized by a type <code>A</code>.</li> <li><code>None</code> is a constructor representing the absence of a value.</li> <li><code>Some</code> is a constructor that takes a value of type <code>A</code>.</li> </ul>"},{"location":"Terms/09-inductive/#inductive-style-definition","title":"Inductive Style Definition","text":"<pre><code>type Option(A: 'Type) = inductive {\n    None : this         // 'this' refers to 'Option(A)'\n    Some : A -&gt; this    // 'Some' takes an 'A' and returns 'Option(A)'\n}\n</code></pre> <p>In this definition:</p> <ul> <li>The constructors explicitly specify their types.</li> <li><code>None</code> has type <code>Option(A)</code>, indicated by <code>this</code>.</li> <li><code>Some</code> is a function from <code>A</code> to <code>Option(A)</code>.</li> </ul> <p>Both definitions are functionally equivalent. The inductive style makes the types of the constructors explicit.  This is essential when defining inductive types with indices, as it allows for precise type-level information and reasoning.</p>"},{"location":"Terms/09-inductive/#examples-of-inductive-types-with-indices","title":"Examples of Inductive Types with Indices","text":""},{"location":"Terms/09-inductive/#vectors-with-length-indices","title":"Vectors with Length Indices","text":"<p>A classic example of an inductive type with indices is a vector whose length is part of its type.  This kind of vector definition ensures that operations on vectors respect their lengths at the type level.</p> <pre><code>def Vec(A: 'Type): Int -&gt; 'Type = inductive(Int) {\n    Nil : this(0)\n    Cons : A -&gt; \u2200(n: Int) -&gt; Vec(A, n) -&gt; this(n + 1)\n}\n</code></pre> <p>Where:</p> <ul> <li><code>Vec</code> is a function that, given a type (<code>A: 'Type</code>), returns an inductive type with index (<code>n: Int</code>) representing the length . (i.e. a function taking an integer (<code>n: Int</code>) and producing an inductive type <code>Vec(n) : 'Type</code>).</li> <li>The index is the integer specified in <code>inductive(Int)</code>.</li> <li>Constructors:<ul> <li><code>Nil</code> is a constructor of type <code>this(0)</code>, representing an empty vector of length 0.</li> <li><code>Cons</code> is a constructor that takes an element of type <code>A</code>, an integer <code>n</code>, and a vector <code>Vec(A, n)</code>, and returns a vector of length <code>n + 1</code>, indicated by <code>this(n + 1)</code>.</li> </ul> </li> </ul>"},{"location":"Terms/09-inductive/#equality-type","title":"Equality Type","text":"<p>Recall the propositional equality (Leibniz equality) defined as a function in the previous section:</p> <pre><code>def Eq(A: 'Type, a b: A): 'Type = \u2200(P: A -&gt; 'Type) -&gt; P(a) -&gt; P(b)\ndef refl(A: 'Type, a: A): A.Eq(a, a) = (P: A -&gt; 'Type, p: P(a)) =&gt; p\n</code></pre> <p>Besides this functional definition, equality can also be defined as an inductive type in Saki:</p> <pre><code>def Eq(A: 'Type, x: A): A -&gt; 'Type = inductive(A) {\n    EqRefl: this(x)   // `this(x)` is the same as `Eq(A, x, x)`\n}\n</code></pre> <p>In this example, \\(Eq_A\\) and \\(refl_x\\) are separately defined by the inductive type <code>Eq</code> and the constructor <code>EqRefl</code>:</p> <ul> <li>The <code>Eq</code> inductive type has index <code>A -&gt; A -&gt; 'Type</code>.</li> <li>The constructor <code>EqRefl</code> provides a proof that <code>x</code> is equal to itself (<code>this(x)</code>), which is equivalent to <code>Eq(A, x, x)</code>.</li> </ul>"},{"location":"Terms/09-inductive/#practical-example-verified-merge-sort","title":"Practical Example: Verified Merge Sort","text":"<pre><code>/**\n * Inductive type definition for natural numbers (\u2115).\n * This type is recursively defined using two constructors:\n * - `Zero`: The base case representing the natural number zero.\n * - `Succ`: The successor constructor, representing a natural number that is one greater than another.\n */\ntype \u2115 = inductive { Zero; Succ(\u2115) }\n\n/**\n * Boolean function to compare two natural numbers (\u2115) for less-than-or-equal-to relation (&lt;=).\n * \n * @param x The first natural number (\u2115).\n * @param y The second natural number (\u2115).\n * @return true if x is less than or equal to y, false otherwise.\n */\ndef (&lt;=)(x y: \u2115): Bool = match (x, y) {\n    case (\u2115::Zero, _) =&gt; true\n    case (\u2115::Succ(x'), \u2115::Succ(y')) =&gt; x' &lt;= y'\n    case (_, _) =&gt; false\n}\n\n/**\n * Inductive type definition for the proof of the less-than-or-equal-to (Leq) relation.\n * \n * The type provides a constructive proof for the relation `x &lt;= y`:\n * - `LeqZero`: A proof that `Zero &lt;= x` for any natural number x.\n * - `LeqSucc`: A proof that if `x &lt;= y`, then `Succ(x) &lt;= Succ(y)`.\n */\ndef Leq: \u2115 -&gt; \u2115 -&gt; 'Type = inductive(\u2115, \u2115) {\n    LeqZero : \u2200(x: \u2115) -&gt; this(\u2115::Zero, x)\n    LeqSucc : \u2200(x y: \u2115) -&gt; this(\u2115::Succ(x), \u2115::Succ(y))\n}\n\n/**\n * Inductive type definition for a vector (Vec) of fixed size.\n * This type is recursively defined using two constructors:\n * - `Nil`: An empty vector of length 0.\n * - `Cons`: A non-empty vector with length n + 1, consisting of a head element and a tail vector of size n.\n * \n * @param n The length of the vector (\u2115).\n */\ntype Vec(n: Int) = inductive {\n    Nil                // An empty list with length 0\n    Cons(\u2115, Vec(n))    // A list with length n+1, consisting of a head and a tail\n}\n\n/**\n * Inductive type definition for the proof that a vector (Vec) is sorted.\n * \n * The type provides a constructive proof that a vector of length n is sorted:\n * - `SortedNil`: A proof that an empty vector is always sorted.\n * - `SortedOne`: A proof that a vector with one element is always sorted.\n * - `SortedCons`: A proof that a vector with two or more elements is sorted if the head is less than or equal to\n *                 the next element, and the tail is also sorted.\n * \n * @param n The length of the vector (\u2115).\n * @param vec The vector of length n to be checked for sortedness.\n * @return A type-level proof that the vector is sorted.\n */\ndef Sorted(n: Int): Vec(n) -&gt; 'Type = inductive(Vec(n)) {\n    // An empty list is always sorted\n    SortedNil: this(Vec(0))\n    // A list with one element is always sorted\n    SortedOne: this(Vec(1))\n    // A list with two or more elements is sorted if the head is less than or equal \n    // to the next element, and the tail is also sorted\n    SortedCons: \u2200(x y: \u2115) -&gt; \u2200(xs: Vec(n)) -&gt; Leq(x, y) -&gt; this(Vec(n)) -&gt; this(Vec(n + 1))\n}\n\n/**\n * Function to merge two sorted vectors (Vec) and return a merged sorted vector with a proof of sortedness.\n * \n * @param n The length of the first vector (\u2115).\n * @param m The length of the second vector (\u2115).\n * @param xs The first sorted vector of length n.\n * @param ys The second sorted vector of length m.\n * @return A tuple containing the merged vector of length n + m and a proof that the merged vector is sorted.\n */\ndef merge(n m: Int, xs: Vec(n), ys: Vec(m)): (Vec(n + m), Sorted(n + m)) = match (xs, ys) {\n    case (Vec(n)::Nil, ys) =&gt; (ys, Sorted(m)::SortedNil)  // Merging with an empty list is sorted\n    case (xs, Vec(m)::Nil) =&gt; (xs, Sorted(n)::SortedNil)  // Merging with an empty list is sorted\n    case (Vec(n)::Cons(x, xsRest), Vec(m)::Cons(y, ysRest)) =&gt; {\n        if x &lt;= y then {\n            let (mergedRest, proofRest) = merge(xsRest, ys)\n            let proof = Sorted(n + m)::SortedCons(x, y, mergedRest, Leq::LeqZero, proofRest)\n            (Vec(n + m)::Cons(x, mergedRest), proof)\n        } else {\n            let (mergedRest, proofRest) = merge(xs, ysRest)\n            let proof = Sorted(n + m)::SortedCons(y, x, mergedRest, Leq::LeqSucc(x, y), proofRest)\n            (Vec(n + m)::Cons(y, mergedRest), proof)\n        }\n    }\n}\n\n/**\n * Function to perform merge sort on a vector (Vec) of length n, returning the sorted vector and a proof of sortedness.\n * \n * @param n The length of the input vector (\u2115).\n * @param list The input vector to be sorted.\n * @return A tuple containing the sorted vector and a proof that the vector is sorted.\n */\ndef mergeSort(n: Int, list: Vec(n)): (Vec(n), Sorted(n)) = match list {\n    // An empty list is trivially sorted\n    case Vec(0)::Nil =&gt; (Vec(0)::Nil, Sorted(0)::SortedNil)\n    // A single-element list is sorted\n    case Vec(1)::Cons(x, Vec(0)::Nil) =&gt; (list, Sorted(1)::SortedOne)\n    case _ =&gt; {\n        let (left, right) = split(n, list)  // Split the list into two halves\n        let (sortedLeft, proofLeft) = mergeSort(left)\n        let (sortedRight, proofRight) = mergeSort(right)\n        merge(sortedLeft, sortedRight)  // Merge the sorted halves with proof\n    }\n}\n\n/**\n * Function to split a vector of length n into two sub-vectors.\n * The first sub-vector has length n / 2, and the second has length n - n / 2.\n * \n * @param n The length of the input vector (\u2115).\n * @param list The input vector to be split.\n * @return A tuple containing the two sub-vectors after the split.\n */\ndef split(n: Int, list: Vec(n)): (Vec(n / 2), Vec(n - n / 2)) = {\n    // Start the recursion with initial accumulators and sizes\n    splitRec(n, n / 2, Vec(n / 2)::Nil, Vec(n - n / 2)::Nil, list)\n}\n\n/**\n * Recursive helper function to split a vector into two sub-vectors.\n * This function takes accumulators and sizes for the left and right sub-vectors, and iterates through the input vector.\n * \n * @param i The remaining size of the input vector (\u2115).\n * @param leftSize The size of the left sub-vector (\u2115).\n * @param leftAcc The accumulated left sub-vector (Vec(leftSize)).\n * @param rightAcc The accumulated right sub-vector (Vec(n - leftSize)).\n * @param rest The remaining part of the vector to be split (Vec(i)).\n * @return A tuple containing the two sub-vectors after the split.\n */\ndef splitRec(\n    i: Int, leftSize: Int, leftAcc: Vec(leftSize), \n    rightAcc: Vec(n - leftSize), rest: Vec(i),\n): (Vec(n / 2), Vec(n - n / 2)) = match (leftSize, rest) {\n    // No more elements for the left side, return the remaining as right\n    case (0, _) =&gt; (leftAcc, rest)\n    // Done splitting, return accumulators\n    case (_, Vec(i)::Nil) =&gt; (leftAcc, rightAcc)\n    // Add to the left\n    case (_, Vec(i)::Cons(x, xs)) =&gt; {\n        splitRec(i - 1, leftSize - 1, Vec(leftSize)::Cons(x, leftAcc), rightAcc, xs)\n    }\n}\n</code></pre>"},{"location":"Terms/10-constraint/","title":"Constraint Universe","text":"<p>Warning</p> <p>This feature is not yet implemented or not fully supported in the current version of Saki interpreter/REPL.</p> <p>In Saki, universes are used to organize types into hierarchies, particularly when dealing with contract universes, which enforce certain behaviors or constraints on types. A universe in Saki is essentially a type whose elements are themselves types, constrained by certain contracts or predicates. This design closely aligns with Martin-L\u00f6f Type Theory (MLTT), where universes are structured collections of types that satisfy specific conditions. Contract universes in Saki allow types to declare behaviors through contracts, enforcing rules and conditions on how types interact.</p>"},{"location":"Terms/10-constraint/#universe-structure-and-predicates","title":"Universe Structure and Predicates","text":"<p>In MLTT, a universe \\(\\mathcal{U}_P\\) is the collection of all types <code>T</code> that satisfy a given predicate <code>P(T)</code>. In Saki, this idea extends to contract universes, where types belong to universes by fulfilling contracts. These contracts specify behaviors (like implementing certain methods), which serve as predicates for inclusion in the universe.</p> <p>For instance, consider the following contract universe in Saki:</p> <pre><code>universe 'Printable = contract {\n    require print(self): String\n}\n</code></pre> <ul> <li>The <code>'Printable</code> universe contains all types that satisfy the contract by implementing a <code>print</code> method that returns a <code>String</code>.</li> </ul> <p>The relationship between types and the universe \\(\\mathcal{U}_P\\) can be expressed as follows: $$ T : \\mathcal{U}_P \\iff P(T) $$ Where \\(P(T)\\) is a predicate that holds for a type \\(T\\), meaning \\(T\\) satisfies the contract (or conditions) required by \\(P\\).</p>"},{"location":"Terms/10-constraint/#typing-rules-for-universes","title":"Typing Rules for Universes","text":"<p>The typing rule for contract universes ensures that types are included in the universe only if they satisfy the required contract. In Saki, this is reflected in the following general typing rule: $$ \\frac{\\Gamma \\vdash T : \\mathcal{U} \\quad P(T)}{\\Gamma \\vdash T : \\mathcal{U}_P} $$ This rule states that:</p> <ul> <li>If a type \\(T\\) belongs to a base universe \\(\\mathcal{U}\\) and satisfies the predicate \\(P(T)\\) (such as implementing required contract methods), then \\(T\\) belongs to the universe \\(\\mathcal{U}_P\\), where \\(P\\) represents the contract.</li> </ul>"},{"location":"Terms/10-constraint/#universe-hierarchy-and-subtyping","title":"Universe Hierarchy and Subtyping","text":"<p>Saki employs a hierarchical universe system similar to that of MLTT, where universes can be ordered by subtyping. One universe is a subtype of another if every type in the first universe satisfies the conditions of the second. This hierarchy is based on the predicates enforced by each universe.</p> <p>For instance, consider the following two contract universes:</p> <pre><code>universe 'Add = contract {\n    require add(lhs: Self, rhs: Self): String\n}\n\nuniverse 'Mul(A R: 'Type) = contract {\n    require mul(self, other: A): R\n}\n</code></pre> <ul> <li>The <code>'Add</code> universe includes all types that implement an <code>add</code> method, while the <code>'Mul</code> universe contains types that implement a <code>mul</code> method for multiplication.</li> </ul> <p>The subtyping relation between universes can be expressed as: </p> \\[ \\mathcal{U}_{P_1} &lt;: \\mathcal{U}_{P_2} \\iff \\forall T \\,.\\, (T : \\mathcal{U}_{P_1} \\implies T : \\mathcal{U}_{P_2}) \\] <p>This means that a universe \\(\\mathcal{U}_{P_1}\\) is a subtype of another universe \\(\\mathcal{U}_{P_2}\\) if every type in \\(\\mathcal{U}_{P_1}\\) also satisfies the predicate \\(P_2\\). In other words, if a type satisfies the conditions of universe \\(P_1\\), it must also satisfy the conditions of universe \\(P_2\\).</p>"},{"location":"Terms/10-constraint/#subtyping-properties-in-universes","title":"Subtyping Properties in Universes","text":"<p>The subtyping relation between universes follows several important properties, ensuring consistency in the hierarchy:</p> <ol> <li> <p>Reflexivity: Every universe is a subtype of itself: $$ \\mathcal{U}_P &lt;: \\mathcal{U}_P $$ This holds because \\(P(T) \\implies P(T)\\) for any predicate \\(P\\).</p> </li> <li> <p>Antisymmetry: If two universes \\(\\mathcal{U}_{P_1}\\) and \\(\\mathcal{U}_{P_2}\\) are mutually subtypes of each other, they are equal:</p> </li> </ol> \\[ (\\mathcal{U}_{P_1} &lt;: \\mathcal{U}_{P_2} \\land \\mathcal{U}_{P_2} &lt;: \\mathcal{U}_{P_1}) \\implies \\mathcal{U}_{P_1} = \\mathcal{U}_{P_2} \\] <ol> <li>Transitivity: If universe \\(\\mathcal{U}_{P_1}\\) is a subtype of \\(\\mathcal{U}_{P_2}\\), and \\(\\mathcal{U}_{P_2}\\) is a subtype of \\(\\mathcal{U}_{P_3}\\), then \\(\\mathcal{U}_{P_1}\\) is a subtype of \\(\\mathcal{U}_{P_3}\\):</li> </ol> \\[ (\\mathcal{U}_{P_1} &lt;: \\mathcal{U}_{P_2} \\land \\mathcal{U}_{P_2} &lt;: \\mathcal{U}_{P_3}) \\implies \\mathcal{U}_{P_1} &lt;: \\mathcal{U}_{P_3} \\]"},{"location":"Terms/10-constraint/#dependent-universes","title":"Dependent Universes","text":"<p>In Saki, universes can also be dependent types, where the universe's constraints (predicates) depend on a parameter. For example, in the contract universe <code>'Mul</code>, the multiplication contract depends on two parameters, <code>A</code> and <code>R</code>, where <code>A</code> is the type being multiplied and <code>R</code> is the result type:</p> <pre><code>universe 'Mul(A R: 'Type) = contract {\n    require mul(self, other: A): R\n}\n</code></pre> <p>This can be formalized as a dependent universe:</p> \\[ \\Pi_{R:\\mathcal{U}_1}. \\Pi_{A: \\mathcal{U}_0} \\,.\\, (A \\rightarrow R) \\] <p>Here, the universe for types satisfying the multiplication contract is dependent on the types <code>A</code> and <code>R</code>.</p>"},{"location":"Terms/10-constraint/#contract-universe-binding","title":"Contract Universe Binding","text":"<p>Just like types and values, contract universes in Saki can be bound to a <code>let</code> expression. For example:</p> <pre><code>let 'Mul: 'Type -&gt; 'Type -&gt; #Universe = |A R: 'Type| {\n    return contract {\n        decl mul(self, other: A): R\n    }\n}\n</code></pre> <p>In this case:</p> <ul> <li>The <code>let</code> expression binds a contract universe <code>'Mul</code> to a type-level function.</li> <li>The contract ensures that any type belonging to this universe implements a <code>mul</code> function, with the input type <code>A</code> and the result type <code>R</code>.</li> </ul>"},{"location":"Terms/10-constraint/#example-defining-functions-with-contract-universes","title":"Example: Defining Functions with Contract Universes","text":"<p>Once contract universes are defined, they can be used to enforce specific behaviors within functions. Consider the following example:</p> <pre><code>def square[R: 'Type, A: 'Mul(A, R)](self: A): R = self.mul(self)\n</code></pre> <ul> <li>This function takes a value <code>self</code> of type <code>A</code> that belongs to the <code>'Mul</code> contract universe, meaning <code>A</code> must implement the <code>mul</code> method.</li> <li>The function returns <code>R</code>, the result of multiplying <code>self</code> by itself using the <code>mul</code> method.</li> </ul>"}]}